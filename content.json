{"pages":[{"title":"关于","text":"关于我： 游戏迷，基本上什么都能玩，喜欢的游戏类型有RTS、ADV、SLG、RPG等。国单爱好者，很喜欢武侠/仙侠RPG，可能是小时候陪伴我长大的缘故吧，可惜这个类型已经式微多年。不太喜欢FPS，因为我手残打不到人且晕3D。 题材上最爱的是悬疑推理，其次是科幻。对我的吸引程度大致为：本格推理&gt;武侠&gt;蒸汽朋克&gt;赛博朋克&gt;太空歌剧&gt;克苏鲁。 喜欢的电影：星际穿越、银翼杀手、黑客帝国、大鱼、双旗镇刀客。 喜欢的游戏：428:被封锁的涩谷、弹丸论破系列、极限脱出系列、逆转裁判系列、ever 17、明星志愿系列、足球经理系列、绯夜传说。 如果有机会，大概会养一只布偶猫。 我永远支持皇家马德里！ 许愿墙： SCI 0/3 雅思 0/7.5 减肥 1/17 顺利毕业 0/1 互相喜欢的恋人 0/1 熟练使用JavaScript 0.1/1","link":"/about/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"标签","text":"","link":"/tags/index.html"}],"posts":[{"title":"2019年末的碎碎念","text":"好久没写正经文字了，读书也是断断续续的，来点流水账总结一下吧。 概述 总的来说，2019算是平淡的一年，就算是3、4月份的那段经历也差不多在我意料之中。这种波澜不惊的生活虽然并非我所愿，也所幸没有超出我承受范围的事件。 生活 上半年经历的外放大概还是挺开心的，特别是现在长沙的鬼天气让我尤为怀念深圳的气候，更怀念的是那种不用考虑任何杂事，只用做手中活的那种状态，本社恐还是很难习惯和人打交道。 略遗憾的是并没有去很多地方玩，香港去了几次，后面由于众所周知的的原因，也没机会再去那边玩了，想去的海洋公园终究也没去成，也没能和文同学碰面。不过和菜神终于面基成功，说起来也认识好多年了，在本科都没机会见面，没想到多年以后还能在深圳相见。五一一块去了香港，那天也算是我在香港体验最好的一天了。 抽空见了一次发小，从小在一起长大的交情，随着这些年的距离和圈子的变化，感觉也变的生分很多，看着他在深圳混的很好，又想着我现在的状态，还是略惆怅的。可能是我不太擅长维护友情吧，今年还失去了一个朋友，想想就更难过了。 学习 作为一条咸鱼，自律学习对我来说还是难度太大了。说到底也是因为我2、3月学习不认真才会有现在的境地。Python和机器学习已经进入吃老本状态了，被老弟拍死在沙滩上。Java从入门到放弃，JavaScript也停滞不前，希望明年能抽空搞定Vue或React吧。 科研方向上毫无进展，从之前的PPIs到肝癌样本再到HIF1-α，方向一直在换，现在又变成MSCs了，感觉老板对我很不满意了，明年的重点就是好好读文献，目标能做出预实验。 所谓生活不如意，开始记单词。由于多年以后又遭6级的毒打和转博无望，决心好好学英语，再不济也得刷个6级分数吧，从明天开始背。 娱乐 年纪大了精力就十分有限，几年前从来没想过我居然还有不玩DOTA的时候，转眼间上次玩都可以追溯到过年了。 小说 今年看的小说数目极其有限，其中我觉得有意思的有：《首无·作祟之物》、《密室收藏家》、《水母不会冻结》、《尸人庄谜案》，不分先后。 电影/电视剧 这两年日剧/日影基本上没有能提起我兴趣的，除了惯例要看的《世界奇妙物语》，唯一让我有兴趣追完的日剧唯有《轮到你了》，结果还虎头蛇尾。不过补了一点老剧，《古畑任三郎》意外的惊喜。 电影方面，今年上映的电影个人喜好度排名：《海市蜃楼》、《 复仇者联盟4:终局之战 》、《调音师》、《流浪地球》、《飞驰人生》。此外，其他渠道看的电影这几部我也觉得不错：《大河恋》、《岁月神偷》、《一一》、《我们天上见》、《和莎莫的500天》、《她》。草，真的是雅俗皆赏。 游戏 游戏方面，虽然鉴于碎片时间玩了2个垃圾手游过渡了一下，但还是以单机游戏为主。今年居然几乎没玩PC上的游戏，除了开年的《隐形守护者》，出于对《潜伏之赤途》的好感体验了一下，意外的感觉还不错，然后居然就没有特别能让我感兴趣的PC单机了，希望明年可以体验一下《极乐迪斯科》。 Switch方面，嫖了老弟的《塞尔达传说：旷野之息》，确实名不虚传，《AI：梦境档案》略有失望，觉得可以更好玩。此外，《宝可梦：盾》真香。最后，期待一下明年能有好的推理作。 最后 希望明年能开开心心。祝能看到本文的朋友们工作顺利/早日毕业。","link":"/2019/12/31/2019年末的碎碎念/"},{"title":"AirPods开箱","text":"懒癌发作，好久没更博客了，发一篇开箱（伪）凑数吧…… 一直挺想用蓝牙耳机的，之前在索尼的降噪豆和AirPods之间纠结，考虑到对于降噪需求并不是很大，所以最终还是选了AirPods，就是喜欢白色的，颜值即正义。 首先是盒子： 打开后来个全家福，正好之前的原装数据线坏了，可以做个备用。必须吐槽苹果的垃圾原装线，用久了要么就是一面不能充电，要么就是开胶，质量还不如几十块的。 盒子内： 拿出来： 说下使用体会吧，感觉上还是挺好用的，戴着很舒服，不容易掉。和IPhone完美契合，配对很方便，使用中拿下一边耳机自动暂停播放，放回去自动开始。虽然只能设置简单的控制，对我来说基本够用。连接电脑声音有点小，得调很大才行，这点不太好，勉强可以接受吧。至于音质，也就听个响的样子，不能指望有多强了~ 希望不会丢……","link":"/2018/05/29/AirPods开箱/"},{"title":"Aero15x开箱","text":"之前一直在gs65和aero15x中摇摆不定，在已经付了gs65的定金后还是选择了aero15x。主要原因就是aero15x比较好拆，实在不想装个内存、固态或者清灰都跑一趟售后，于是就损失了100定金~ \\ (╯-╰) / 16号凌晨下单，等了一天半到手。先来个箱子图： 全部部件，这个适配器真是大，跟块板砖差不多，另外这个光盘是闹哪样，这个本子有光驱吗？自家的AORUS都用U盘了，赢刃还没跟上，真是无力吐槽。 外观，整机是全金属的，感觉做工还算可以，也能单手开合，就是有点指纹收集器的感觉。个人不喜欢太浮夸的外观，这样感觉刚刚好。 下了个娱乐大师，看一眼配置： 之前看别人的拆机内存是芝奇，显示器是LG的，到我变成金士顿和友达，总有点被缩水的感觉…… 跑个分： 由于有后台，跑分比实际水平大概低一点。 来张正面图。 接下来是使用体验：确实和网上说的，有一些小毛病，比如右shift不是很亮，USB接口太紧，然后有时候键盘会双击，强迫症应该会很难受。关键是这些问题去年就有了，到现在也没能解决……至于散热，全靠暴力扇，跑个程序风扇起飞，噪音还是很大的。不过轻薄游戏本要什么自行车，对我来说还是可以接受了。也就不当摸摸党了~","link":"/2018/04/17/Aero15x开箱/"},{"title":"Flask学习笔记","text":"Django有点繁琐，俺打算转战Flask了。 初始化安装 在虚拟环境下安装。 12conda create -n flaskconda install flask Hello，Flask Flask 类的构造函数只有一个必须指定的参数，即程序主模块或包的名字。在大多数程序中，Python 的__name__变量就是所需的值。 12from flask import Flaskapp = Flask(__name__) 以上即为一个最简单的实例创建。","link":"/2019/11/14/Flask学习笔记/"},{"title":"NS开箱","text":"想买NS很久了，之前一直听说NS品控不好，还存在变弯风险。所以想等第二代，不过最近价格回落，正好把steam套了点现，就剁手了NS。感觉近来一直在放飞自我，没好好学习，十分惭愧，希望从今天开始好好复习…… 开箱 大概是周六晚上下的单，等了一天多点到货，盒子很朴素： 拆开就能看到主机和2个Joy-Con： 全家福，还有电源、2个腕带、握把、HDMI连接线和底座： 游戏买了个《异度神剑2》的卡带，以及一个《一起剪吧！剪纸狙击手！》，买完才意识到并没有小伙伴一块玩，肥宅留下了悲伤的眼泪。 上个卡带图： 听说卡带是苦的，并不敢去试…… 留个资料页，欢迎有缘人来加好友： 总结 相比于我的3DS，手感要强不少，但是总感觉按键很松。 充电口在下面，有点反人类。另外贴膜没贴好，果然不应该自己贴膜的……老任的做工确实很烂，希望我的NS不会弯吧~","link":"/2018/07/24/NS开箱/"},{"title":"临终歌","text":"庆祝博客开通，搬篇旧文凑个数： 大鹏飞兮振八裔，中天摧兮力不济。余风激兮万世，游扶桑兮挂左袂。后人得之传此，仲尼亡兮谁为出涕？ 李白临终歌 李白的好诗有很多，小时候背过的也不少，这里我要说的是《临终歌》。据说是李白死前所作，颇有几分墓志铭的味道——唐代李华于《故翰林学士李君墓铭序》载：“年六十有二不偶，赋临终歌而卒。” 提到大鹏，脑海里自然浮现出了庄子的《逍遥游》：“北冥有鱼，其名为鲲。鲲之大，不知其几千里也。化而为鸟，其名为鹏。鹏之背，不知其几千里也。怒而飞，其翼若垂天之云……”李白自小受道家影响颇深，自然对大鹏也有特别的情感。 年轻时的李白，便作了《大鹏遇希有鸟赋》，赋中李白仿佛化身大鹏，“簸鸿蒙，扇雷霆。斗转而天动，山摇而海倾。”此时的李白尚有“大济苍生，海内清一”的抱负。然而理想与现实终究是有差距的，虽然李白渴望建功立业，却一直不受重用，甚至被玄宗皇帝赐金还山，这时的他依然写下了“大鹏一日同风起，扶摇直上九万里”的诗句，激励自己穿过风浪，东山再起。安史之乱后，李白又受永王李璘叛逆案牵连，流放夜郎。虽然因大赦逃过一劫，但再也没有机会展示抱负了。 同李白的“天生我才必有用”、“吾辈岂是蓬蒿人”、”我本楚狂人，凤歌笑孔丘”等诗句相比，《临终歌》显得尤为悲怆。李白化身的大鹏老了，再也飞不动了，“冠盖满京华，斯人独憔悴”，绝望的大鹏在生命的最后长歌当哭，留下了最后的哀歌。","link":"/2018/01/31/临终歌/"},{"title":"一个生信挖掘的DEMO","text":"起源是海洋师兄让我复现一个公司做的生信分析，据说这样一个东西收费1w+，于是我开始尝试进行探索。 分析GEO数据miRNA表达情况 GSE106452是4种肝癌细胞的外泌体miRNA的微阵列分析数据，我们由于只有HepG2细胞，因此只拿该细胞数据，挑选表达较高的30个miRNA数据。甚至都用不到Python和R，Excel排序即可。 点评：开始俺还以为得用GEO2R做差异分析，事实上是俺想复杂了。 TCGA差异分析TCGA数据下载选择数据 访问GDC，在Cases里的Project选择TCGA-LIHC，Files里的Data Category选择transcriptome profiling，如果需要下载临床资料，类似地，Data Category选择Clinical即可。 原始方法 如果大小不超过50M，可以点击右边的Add All Files to Cart，然后再右上角的Cart里面选择Download即可下载。 使用GDC Data Transfer Tool 下载GDC Data Transfer Tool，并配置环境变量。 在之前的页面Data Category选择transcriptome profiling，Experimental Strategy选择RNA-Seq，然后在右边选择下载Manifest，文件命名为gdc_manifest.2020-01-17-LIHC-RNA-Seq.txt，此外Experimental Strategy选择miRNA-Seq，Data Type分别选择miRNA Expression Quantification和Isoform Expression Quantification分别得到另外两个文件gdc_manifest.2020-01-17-LIHC-miRNA-Seq.txt和gdc_manifest.2020-01-17-LIHC-miRNA-Isoform.txt。类似地，Data Category选择Clinical，Data Format选择bcr xml即可获取gdc_manifest.2020-01-17-LIHC-Clinical.txt。 新建一个LIHC文件夹，将上述Manifest拷进去，CMD下输入gdc-client download -m gdc_manifest.2020-01-17-LIHC-Clinical.txt -d Clinical/ --log-file Clinical.log即可下载临床数据，其他的操作同理。不过无力吐槽这个网络可连接性，下载起来比登天还难。 这里我采用了分割文件&amp;挂代理的策略才把RNA数据下完。 console下设置代理： set http_proxy=http://127.0.0.1:10809。 set https_proxy=http://127.0.0.1:10809。 此外，在下载上述manifest文件以外顺便应该下载json文件备用。 数据处理Clinical数据合并 主要是xml文件，利用R包来分析。以单个文件为例： 1234567library(\"XML\")library(\"methods\")result = xmlParse(file=\"D:/Bioinformatics/TCGA/LIHC/Clinical/00a9a7f4-06eb-40fb-8d3a-66f5f5d315f7/nationwidechildrens.org_clinical.TCGA-KR-A7K0.xml\")rootnode = xmlRoot(result)rootsize = xmlSize(rootnode)xmldataframe = xmlToDataFrame(rootnode[2])write.table(t(xmldataframe),'tmp') 当然具体数据有成百上千个，应该用循环来做。 1234567891011library(\"XML\")library(\"methods\")dir = \"D:/Bioinformatics/TCGA/LIHC/Clinical/\"cl = lapply(list.files(path=dir,pattern=\"*.xml$\",recursive=T),function(x){ result = xmlParse(file=file.path(dir,x)) rootnode = xmlRoot(result) xmldataframe = xmlToDataFrame(rootnode[2]) return(t(xmldataframe))})cl_df = t(do.call(cbind,cl))save(cl_df,file=\"D:/Bioinformatics/TCGA/LIHC/Process/GDC_TCGA_LIHC_clinical_df.Rdata\") miRNA-Seq数据合并 类似地，修改处理代码如下： 123456789dir = \"D:/Bioinformatics/TCGA/LIHC/miRNA-Seq/\"mi = lapply(list.files(path=dir,pattern=\"*.mirnas.quantification.txt$\",recursive=T),function(x){ result = read.table(file=file.path(dir,x),sep=\"\\t\",header=T)[,1:2] return(result)})mi_df = t(do.call(cbind,mi))colnames(mi_df) = mi_df[1,]mi_df = mi_df[seq(2,nrow(mi_df),by=2),]save(mi_df,file=\"D:/Bioinformatics/TCGA/LIHC/Process/GDC_TCGA_LIHC_miRNA-Seq_df.Rdata\") 这样可以得到一个表达矩阵。 Json数据解析 类似地，修改处理代码如下： 123456789library(\"rjson\")result = fromJSON(file = \"D:/Bioinformatics/TCGA/LIHC/TCGA-LIHC-miRNA-Seq.json\")fls = unlist(lapply(result,function(x){x$file_name}))cid = unlist(lapply(result,function(x){x$cases[[1]]$case_id}))id2fls = data.frame(cid=cid,fls=fls)save(id2fls,mi_df,fls,cl_df,file='D:/Bioinformatics/TCGA/LIHC/Rdata/GDC_TCGA_LIHC_miRNA-clinical.Rdata')# 相关数据的清除与读取rm(list=ls())load(file='D:/Bioinformatics/TCGA/LIHC/Rdata/GDC_TCGA_LIHC_miRNA-clinical.Rdata') 使用TCGAbiolinks包 感觉真的很方便，在BiocManager里面安装： 123456789101112# 安装BiocManager::install(\"TCGAbiolinks\")# 下载library(TCGAbiolinks)query = GDCquery(project = 'TCGA-LIHC', data.category = \"Transcriptome Profiling\", data.type = \"Gene Expression Quantification\", workflow.type = \"HTSeq - Counts\")GDCdownload(query, method = \"api\", files.per.chunk = 100)expdat = GDCprepare(query = query)count_matrix = assay(expdat) PS1：本来打算用RTCGA的，但是这个包N年不更新了，用着膈应~ PS2：R语言设置代理： Sys.setenv(“http_proxy”=”http://127.0.0.1:10809“)Sys.setenv(“https_proxy”=”http://127.0.0.1:10809“)","link":"/2020/01/17/一个生信挖掘的DEMO/"},{"title":"冰冻切片机操作流程","text":"由于要交一份电子版，所以修改一下顺便传上来了。 目的 为什么要做冰冻切片而不是石蜡切片，因为冰冻切片相对于石蜡切片相对简便快速，用时短， 多应用于手术中的快速病理诊断 ，缺点是不利于持久保存。 步骤开机 使用前最少2小时，按右侧电源键开机。但在实际情况下，一般为待机状态，长按待机键解除待机状态。 预冷 调节温度至-25℃，将刀片刷子样品等提前放进去预冷。等待仪器降至所需温度。 固定刀片及样品 在样本托上滴点蒸馏水，用来固定样品，如有需要可用蓝色速冻台降温，冷冻后将其固定在切片机样本头上。一般不需要动刀座的锁紧杆，只需要打开刀片的锁紧杆放入刀片。注意使用仪器左侧控制面板上的样本后退按键，将样本头调到最后方，防止安装样本时撞坏防卷板、刀片等 调节切片厚度 一般调节切片厚度为15或20μm，小心控制仪器的样本推进按键，使样本向刀架方向前进直到刀片快要接触样本时，此时再换用手轮控制。 切片 打开手轮柄锁，顺时针均力旋转手轮一圈，切好后将手轮锁定在12点位置，即样本头移动在最高位置以便于取出切片，掀开防卷板，用常温的针管弯头将切片粘附放入常温放置的蒸馏水或者PBS中，再用带毛针管头小心贴片。当然也有用常温载玻片往样本上靠的方法。如果刀上或防卷板粘有脏东西，用预冷过的刷子顺着刀刃方向刷干净。 清理 切片结束后收好刀片，锁定手轮，用冰冻台里面的刷子扫除多余组织碎片并清理出去，较小组织可以用常温放置的卫生纸擦拭。注意不能用水擦拭，应当用无水乙醇。 关机 一般情况下因为要经常使用，可不必关闭电源。用完将温度调到-10℃，然后长按待机键使时间中间的：消失，即为进入待机状态。 其他注意事项 环境温度应该在20℃下进行。 防卷板轻拿轻放，避免损坏。 切片完毕收好刀片，锁死手轮锁。 其他已设参数勿动，一般只调整切片厚度。 应保持切片机及周围区域清洁，机外废水壶满应及时倒掉。","link":"/2019/10/22/冰冻切片机操作流程/"},{"title":"一些可能用得上的点","text":"记录一下以后可能用得上的点。 MOE相关Lipinski的五倍律 满足下面标准中的至少两条，则该化合物的被动吸收能力或者膜渗透性将较差，难以通过口服吸收： Weight：相对分子质量大于500Da logP(o/w)：具有高亲脂性即clgP&gt;5 lip_don：氢键供体数大于5（—OH和—NH之和） lip_acc：氢键受体数大于10（O原子和N原子之和） b_rotN：含有多于5个可旋转键，以限制其构象柔性 此外，moe还有一项lip_violation，以提示Lipinski五倍律违反数。 以多mpu运行 CMD下运行，%MOE%为MOE根目录： 12%MOE%\\bin\\moe -mpu 2// 数字为调用mpu数目 计算cats描述符 SVL输入： 12db_cats [,3]// 后面为切片，以1为起始 RDKit相关计算Morgan指纹 当radius=2时，即为ECFP4 ，nBits为长度。 123from rdkit import Chemm1 = Chem.MolFromSmiles('Cc1ccccc1')fp1 = Chem.AllChem.GetMorganFingerprintAsBitVect(m1,2,nBits=1024)","link":"/2018/12/26/一些可能用得上的点/"},{"title":"尼氏染色操作流程","text":"理由同上。 原理 尼氏染色法(Nissl Staining)是用碱性染料染神经组织的一种方法。尼氏体是胞质内的一种嗜碱性物质，广泛见于各种神经元，不同神经元中的尼氏体形状、大小和数量则各有差异。用于尼氏染色的碱性染料主要有焦油紫、亚甲蓝、甲苯胺蓝和硫堇等。尼氏染色法可以染出尼氏体，用来观察神经元内的细胞结构；还可以通过尼氏染色后对尼氏体的观察来了解神经元的损伤情况 。 步骤 不同老师有方法略有区别，我们以熊鲲老师的方法为例。 将处理好的样本放入尼氏染色液，时间可根据切片厚度等，结合染色情况调整，一般在10分钟-30分钟左右。 蒸馏水洗涤数次，每次几秒。 用无水乙醇分色，每次浸入几秒拿出观察脱色情况，到变蓝或者浅紫色为止。 轻磕载玻片，将水甩干，注意避免组织被甩掉，时间允许则风干。 用无水乙醇脱水3分钟。 （水洗，并甩干）。 二甲苯脱脂3-5分钟。 换新鲜二甲苯再脱脂3-5分钟。 封片：用棉签屁股挑去少许中性树脂到盖玻片上，手持载玻片压下去，注意避免气泡产生。如果产生，可以将气泡挤出。 观察染色情况。","link":"/2019/10/25/尼氏染色操作流程/"},{"title":"将SMILES转成InChiKey","text":"最近在项目中需要将SMILES转成InChiKey，通常可以在OpenBabelGUI中操作完成，但是对于大量数据在OpenBabelGUI中操作就有些不方便且容易失误。这里记录一下我解决这个问题的过程。 安装相关包 先建立一个虚拟环境，安装RDKit： 1conda create -c rdkit -n my-rdkit-env rdkit 然后在虚拟环境下安装OpenBabel： 1conda install -n my-rdkit-env -c openbabel openbabel 出现的问题 最初想用Pybel实现，然而发现Pybel并不支持输出格式为InChiKey，既然这条路走不通，就换个方案吧。于是想查看OpenBabel的文档看看能不能实现，然而发现这玩意的python接口只是寥寥几言，也没有具体的文档。不过Google到了一个轮子写了如何将SMILES转成InChiKey，代码如下： 1234567import openbabel as obconv = ob.OBConversion()conv.SetInAndOutFormats(\"smi\", \"inchi\")conv.SetOptions(\"K\", conv.OUTOPTIONS)mol = ob.OBMol()conv.ReadString(mol, \"CC(=O)Cl\")inchikey = conv.WriteString(mol): 本想着问题解决了，不过试了一下发现并不能用。而且可耻的找不到原因…… 不过也问题不大，RDKit可以把SMILES转成InChi，然后再把InChi变成InChiKey就行了，于是写了个函数实现: 1234567from rdkit import Chemfrom rdkit.Chem.inchi import rdinchidef smiletoinchikey(smile): mol = Chem.MolFromSmiles(smile) inchi = rdinchi.MolToInchi(mol) inchikey = rdinchi.InchiToInchiKey(inchi[0]) return inchikey 然而在处理项目文件时发现，有些SMILES式RDKit不能识别，导致程序出错。如Clc1c([C@@H]2[C@@H]([N+H3])CC(CN3CCC(C(=O)O)CC3)=CC2)ccc(Cl)c1，于是写了个函数利用Pybel将其转成Canonical SMILES。最后还是有一些剩余问题，比如Oc1ccc([C+2]2345[B-2]678[B-3]9%10%11([C-3])[C+]%12%13%14[B-2]%15%169[B-2]26%10[B-2]23%15[B-2]364[B-2]457[B-2]8%11%12[B-2]%1334[B-2]%14%1626)cc1转成Canonical SMILES依然无法读取，又或者O=BOB(OB(OB=O)[O-])[O-]没转换前能读取，转换后不能读取，只能按例外处理。 最后代码如下： 123456789101112131415161718192021222324#!/usr/bin/env python3# -*- coding: utf-8 -*-# @Time : Thu Apr 20 16:12:41 2018# @Author : Catkin# @Website : blog.catkin.moeimport pybelfrom rdkit import Chemfrom rdkit.Chem.inchi import rdinchidef smitosmile(smi): mol = pybel.readstring(\"smi\", smi) smile = mol.write('can') smile = smile.replace('\\t\\n', '') return smile def smiletoinchikey(smile): mol = Chem.MolFromSmiles(smile) if mol is None: smi = smitosmile(smile) mol = Chem.MolFromSmiles(smi) inchi = rdinchi.MolToInchi(mol) inchikey = rdinchi.InchiToInchiKey(inchi[0]) return inchikey 用OpenBabel同样也可以把SMILES转成Canonical SMILES： 12345678910import openbabel as obdef obsmitosmile(smi): conv = ob.OBConversion() conv.SetInAndOutFormats(\"smi\", \"can\") conv.SetOptions(\"K\", conv.OUTOPTIONS) mol = ob.OBMol() conv.ReadString(mol, smi) smile = conv.WriteString(mol) smile = smile.replace('\\t\\n', '') return smile","link":"/2018/04/21/将SMILES转成InChiKey/"},{"title":"数字切片扫描仪操作流程","text":"理由同上上。 步骤开启设备设备通电 先开电脑，再开扫描仪。 开启软件 运行桌面的NDP.Scan程序，初始化后选择扫描模式，即单张模式或批量模式。 放置切片 稍用力向里推压切片舱门，使舱门弹出。 标签向上，盖玻片向外放入切片槽。 开始扫描单张模式 选择模式，点击载入切片。 输入文件名。 如有需要，手动调整区域。 如有需要，手动调整聚焦位置。 开始扫描。 扫描完成后可以浏览图像。 批量模式 大部分与单张模式一样，值得注意的是输入文件名，可以在Excel或记事本中预设文件名，然后载入。 图像操作 通过NDP.View2操作，可以根据需要缩放、拖动、放大、添加标注以及截图输出，也可以调节图片的γ值、亮度、对比度及锐化程度。","link":"/2019/11/13/数字切片扫描仪操作流程/"},{"title":"相似度计算的python实现","text":"在数据挖掘中有很多地方要计算相似度，计算相似度有欧几里德距离、曼哈顿距离、皮尔逊相关度、Jaccard系数和Tanimoto系数等等，这里暂时列出以下几种计算方法。 欧几里得距离 欧几里得距离（Euclidean distance）是一个通常采用的距离定义，指在m维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离），在二维和三维空间中的欧氏距离就是两点之间的实际距离。 在Python中，可以调用scikit-learn中现成的轮子实现： 12from sklearn.metrics.pairwise import euclidean_distancesdistance = euclidean_distances(i1,i2) 因为计算是基于各维度特征的绝对数值，所以欧氏距离需要保证各维度指标在相同的刻度级别，比如对身高（cm）和体重（kg）两个单位不同的指标是不适用于欧氏距离的。 此外，欧几里得距离是数据上的直观体现，在处理一些受主观影响很大的评分数据时，效果则不太明显；比如，person1对item1,item2 分别给出了2分，4分的评价;person2则给出了4分，8分的评分。通过分数可以大概看出，二个人口味相同，但是第二个人评价稍高。在逻辑上，是可以给出两用户兴趣相似度很高的结论。如果此时用欧式距离来处理，则不能得到这样的结论。即评价者的评价相对于平均水平偏离很大的时候欧几里德距离不能很好的揭示出真实的相似度。 曼哈顿距离 曼哈顿距离（Manhattan Distance）又叫出租车距离或者马氏距离，是由十九世纪的赫尔曼·闵可夫斯基所创词汇 ，是种使用在几何度量空间的几何学用语，用以标明两个点在标准坐标系上的绝对轴距总和。 对于空间向量(x1,x2,x3,…,xn)和(y1,y2,y3,…,yn)，曼哈顿距离的定义为： 同样可以调用scikit-learn中函数： 12from sklearn.metrics.pairwise import manhattan_distancesdistance = manhattan_distances(i1,i2) 余弦相似度 余弦相似度，是用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小的度量。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫”余弦相似性”。余弦相似度衡量的是维度间取值方向的一致性，注重维度之间的差异，不注重数值上的差异，而欧氏度量的正是数值上的差异性。 调用scikit-learn中函数: 12from sklearn.metrics.pairwise import cosine_similaritysimilarity = cosine_similarity(i1,i2) 也可以使用cosine_distances函数，他们的关系是：余弦距离= 1 - 余弦相似度。 皮尔逊相关系数 Pearson相关系数是用协方差除以两个变量的标准差得到的，虽然协方差能反映两个随机变量的相关程度（协方差大于0的时候表示两者正相关，小于0的时候表示两者负相关），但其数值上受量纲的影响很大，不能简单地从协方差的数值大小给出变量相关程度的判断。为了消除这种量纲的影响，于是就有了相关系数的概念。 当两个变量的方差都不为零时，相关系数才有意义，相关系数的取值范围为[-1,1]。当相关系数为1时，成为完全正相关；当相关系数为-1时，成为完全负相关；相关系数的绝对值越大，相关性越强；相关系数越接近于0，相关度越弱。 可以使用scipy中现有轮子： 12from scipy.stats import pearsonrcor = pearsonr(i1,i2) 返回为一个元组，第一项为Pearson相关系数，第二项为p-value。 Jaccard系数 Jaccard系数用于比较有限样本集之间的相似性与差异性。当数据集为二元变量时，我们只有两种状态：0或者1，这时候可以使用它来表征相似度。Jaccard系数值越大，样本相似度越高。 在Python中构建函数如下： 1234567891011def getJaccardCoefficient(p1,p2): x1 = p1[p1&gt;0] x2 = p2[p2&gt;0] si = {} for item in list(x1.index): if item in list(x2.index): si[item] = 1 n = len(si) if n == 0: return 0 return n/(len(x1)+len(x2)-n) Tanimoto系数 Tanimoto系数，又称为广义Jaccard系数，Jaccard系数是xy都是二值向量时的特殊情况，在这种情况下Tanimoto系数就等同Jaccard系数。 在Python中构建函数如下： 1234567891011121314def getTanimotoCoefficient(p1,p2): x1 = p1[p1&gt;0] x2 = p2[p2&gt;0] si = {} for item in list(x1.index): if item in list(x2.index): si[item] = 1 n = len(si) if n == 0: return 0 sum1 = sum([pow(it,2) for it in x1]) sum2 = sum([pow(it,2) for it in x2]) sumco = sum([x1[it]*x2[it] for it in si]) return sumco/(sum1+sum2-sumco)","link":"/2019/01/03/相似度计算的python实现/"},{"title":"江湖夜雨十年灯：武侠游戏记忆","text":"新坑，我挖。 前言 本文说是武侠游戏推荐，不过也会把现在意义上认为是仙侠的部分游戏也放在一块讲。私以为仙侠只是武侠的延伸，本质上都是源自传统侠义小说。事实上很多小说也没有进行严格的分割，比如《蜀山剑仙传》中仍有江湖门派的描述，或者黄易、温瑞安里面的部分神乎其神的武功，把它们放进《鹿鼎记》之流里面也是神仙事迹了。所以本质上来讲，这两类体裁都是承载我们仗剑江湖、白马青衫、 美酒佳肴、佳人相伴、且行且啸乃至国仇家恨种种元素的成人童话。 上面扯远了，小说的话要写起来就太多了，而且恐怕也写不出什么新意，以后有功夫再考虑吧，这里就从现已过气的武侠游戏写起吧。 如果说这类游戏的由盛转衰有个分界点，应该在2000年初，国内单机深陷盗版、价格战的泥潭，网络游戏方兴未艾，传统单机游戏厂商要么倒闭，要么转型网游，一时颇有万马齐喑的感觉。随后十多年也只有新三剑勉力支撑，让人不胜唏嘘。 念往昔，繁华竞逐 pass 六朝旧事随流水 pass 但寒烟衰草凝绿 pass","link":"/2020/05/28/江湖夜雨十年灯：武侠游戏记忆/"},{"title":"记录一些可能有用的网站","text":"存链接用，图文无关 学习综合Medium：美国的一个内容平台，有些类似中国的简书。对于一些不懂的技术可能会在上面找到科普。 机器学习Papers with Code：上面可以找到一些机器学习的论文，优点是代码也一并提供了，方便从代码中体会。 英语词根词缀Online Etymology Dictionary：提供词根词缀的查询学习，本来可以用优词的，但是截至我写这篇文章的时候都不能正常查询，若是以后恢复可以考虑。 写作LaTeXOverleaf：在线LaTeX写作，如果不想在本地安装巨大的TeXLive并配置TeX写作环境的话这个网站提供了一个可靠的解决方案。 近义词替换Thesaurus：输入词语即可找到该词的近义词，用不同程度的橙色显示。 短语搭配Academic Phrasebank：提供了一些学术报告中的常用搭配，比如描述趋势、数量变化等。 Ludwig：整句的搜索引擎，可以从可靠的资源库通常是一些专业的英文网站的文章里来找符合语境的表达。 Linggle：找正确搭配的网站，对于一些介词的使用可以看大部分人是如何选择的。 润色Grammarly ：名气很大的语法校正网站，不过貌似是收费的，反正俺没试过。 微软爱写作：微软出品的写作检查网站，需要微信扫码注册，大致瞄了眼感觉很不错。 Hemingway Editor：用来检查有问题的词句，如过于冗长、用词错误和重复等。 NounPlus：对语法拼写错误会注释并给出建议，目前没测试是否好用。 画图配色Colorgorical：用来生成配色，看起来不明觉厉。 实验细胞小鼠原代肝细胞protocol：提供了小鼠原代肝细胞分离培养的详细步骤，还非常贴心地附上了Q&amp;A、图片和小视频，此外他还提供了一些肝细胞代谢实验的详细步骤 ，对于初次涉及这个实验的是一个很好的入门教程。","link":"/2019/12/12/记录一些可能有用的网站/"},{"title":"类似“超强智商”之类的答题游戏作弊思路","text":"今年年初时答题游戏比较火，对于一些比较热门的游戏，已经有不少成熟的辅助程序了。然而这个实验室同学转给我的这个小程序，似乎热度还达不到做辅助的标准，而题目又比较恶心，自己答起来比较费劲，所以在这里探讨一下作弊的思路。 利用图像识别的思路 很容易想到的一个思路就是把手机屏幕投射到屏幕，这里可以用模拟器/ADB/TeamViewer等方案，然后截图，利用tesseract-ocr将图片识别成文字，最后调用百度搜题。 安装必要库就不赘叙了，有需要日后再补。我是采用了模拟器的方案，简单写出代码如下： 12345678910111213141516171819202122import win32gui, win32ui, win32con, win32apifrom PIL import Imageimport pytesseractimport webbrowserdef window_capture(filename): hwnd = 0 hwndDC = win32gui.GetWindowDC(hwnd) mfcDC = win32ui.CreateDCFromHandle(hwndDC) saveDC = mfcDC.CreateCompatibleDC() saveBitMap = win32ui.CreateBitmap() w = 480 h = 120 saveBitMap.CreateCompatibleBitmap(mfcDC,w,h) saveDC.SelectObject(saveBitMap) saveDC.BitBlt((0,0),(w,h),mfcDC,(50,320),win32con.SRCCOPY) saveBitMap.SaveBitmapFile(saveDC,filename)window_capture('cqzs.jpg')text=pytesseract.image_to_string(Image.open('cqzs.jpg'),lang='chi_sim')new_text =''.join(text.split())url = 'http://www.baidu.com/s?wd=%s' % new_textwebbrowser.open(url) 其中w，h为截图框大小参数，还需要根据实际情况调整定位，以便完整截图。 实际使用情况图片识别大致能让人满意，然而效率上有点低，整个过程大概要3-5秒，只剩一半左右的时间答题，所以希望有更好的方案。 利用抓包的思路 通过Fiddler抓包发现，每次12道题以json的形式一次性直接传递过来，因此可以在答题倒计时时就直接把12道题一块搜，这样每道题基本上有10秒时间作答，比上面的方案充裕了不少。 安装的过程略，需要修改FiddlerScript使其输出题目。代码如下： 123456789101112131415161718import jsonimport webbrowserstat = Truewhile stat == True: try: file = open(\"d:\\\\python\\\\temp\\\\cqzs.txt\",\"r\",encoding=\"utf-8\") j = json.loads(file.read()) if 'game' in j['data']: question_list = j['data']['game']['question_list'] for q in question_list: title = q['title'] url = 'http://www.baidu.com/s?wd=%s' % title webbrowser.open(url) stat = False file.close() except: pass 进一步改进方案 这样只是把每道题用百度搜了一下，还需要人工判断，可以考虑用通过词频比对选择答案，或者多平台搜索集合之类的方案。以后有机会再补。 结局 奖品虽然最低只需要通关5次，但是不包邮，强烈怀疑奖品价值够不上邮费。想免邮费最低需要通关25次，考虑到麻烦程度，溜了溜了~","link":"/2018/05/08/类似“超强智商”之类的答题游戏作弊思路/"},{"title":"金缕曲","text":"搬运的旧文之二： 今日看微博，居然还有人拿汪精卫的诗词才情给他翻案。其中举了汪的《金缕曲·别后平安否》，原词如下： 别后平安否？便相逢、凄凉万事，不堪回首。国破家亡无穷恨，禁得此生消受。又添了离愁万斗。眼底心头如昨日，诉心期夜夜常携手。一腔血，为君剖。泪痕料渍云笺透。倚寒衾循环细读，残灯如豆。留此馀生成底事，空令故人僝僽。愧戴却头颅如旧。跋涉关河知不易，愿孤魂缭护车前后。肠已断，歌难又。 说实在话，这首词还是写的挺好的，难怪陈壁君见词倾心。汪另一首著名的诗便是“慷慨歌燕市，从容做楚囚；引刀成一快，不负少年头。”据说当年作出“砍头不要紧，只要主义真；杀了夏明翰，还有后来人。”的革命烈士夏明翰死前是引用了这首诗的，可惜涉及到了大汉奸汪精卫，只能在教科书上删去此段。钱钟书先生读过汪精卫的诗词也不禁叹到：“扫叶吞花足胜情，鉅公难得此才清。”只可惜，汉奸就是汉奸，若是才华便能给人品洗地，那么秦桧的书法也不错，也该给秦桧翻翻案了。 言归正传，汪的《金缕衣·别后平安否》借鉴了顾贞观的《金缕曲二首》： 季子平安否？便归来，平生万事，那堪回首。行路悠悠谁慰藉，母老家贫子幼。记不起、从前杯酒。魑魅搏人应见惯，总输他、覆雨翻云手。冰与雪，周旋久。泪痕莫滴牛衣透，数天涯，依然骨肉，几家能够？比似红颜多命薄，更不如今还有。只绝塞、苦寒难受。廿载包胥承一诺，盼乌头马角终相救。置此札，君怀袖。 我亦飘零久。十年来，深恩负尽，死生师友。宿昔齐名非忝窃，试看杜陵消瘦，曾不减、夜郎潺僽。薄命长辞知己别，问人生、到此凄凉否？千万恨，为君剖。兄生辛未吾丁丑，共些时，冰霜摧折，早衰蒲柳。词赋从今须少作，留取心魂相守。但愿得、河清人寿。归日急翻行戍稿，把空名料理传身后。言不尽，观顿首。 顺治十四年，顾贞观的好友吴兆骞参加江南乡试中举，却不幸被牵涉入丁酉江南乡试科场案。顺治帝大怒遂于次年将该科已考中的江南举子押解至北京，由福临在中南海瀛台亲自复试，复试合格者保留举人资格，不合格者治罪。两名主考官被斩，17名同考官处绞。 据载，吴兆骞少年得志，放诞不羁，简傲礼法，曾对江东名士汪琬曰：“江东无我，卿当独步”，当是时汪琬年长他七岁，文名早著，所以引得众人侧目。还有个故事是，他在私塾里念书时，常拿桌上同学们除下来的帽子来小便。同学们告诉先生，他竟有回答：“与其放在俗人头上，还不如拿来盛小便。”先生也不由叹息：“此子必以名大惹祸。”吴兆骞之狂可见一斑。 所以有种说法是因为他太狂傲，故意在复试中交了白卷，因而下狱。于顺治十五年，流放宁古塔（位于今黑龙江省）。 在吴兆骞出关之时，好友顾贞观曾发下誓言，要救他归来。（《无锡金匮县志-文苑》载：“兆骞戍宁古塔，贞观洒涕，要言曰：‘必归季子。‘ ”）然而他奔波近二十年，仍然徒劳无功。康熙十五年冬，离居北京千佛寺，于冰雪中感念良友的惨苦无告，为之作《金缕曲》二首寄之以代书信。纳兰性德读过这两首词，泪下数行，说：“河粱生别之诗，山阳死友之传，得此而三！”当即担保援救兆骞，并回赠一首《金缕曲·赠梁汾》。​ 德也狂生耳！偶然间、淄尘京国，乌衣门第。有酒惟浇赵州土，谁会成生此意？不信道、遂成知己。青眼高歌俱未老，向尊前、拭尽英雄泪。君不见，月如水。共君此夜须沉醉。且由他、娥眉谣诼，古今同忌。身世悠悠何足问，冷笑置之而已！寻思起、从头翻悔。一日心期千劫在，后身缘恐结他生里。然诺重，君须记！ 在纳兰父子的帮助下，吴兆骞终于在康熙二十年后归来。自此他已在塞外生活了二十三年。 注1：我见过有说法，顾的两首《金缕曲》是对吴在塞外写的《戊午二月十一日寄顾舍人书》：“塞外苦寒，四时冰雪，鸣镝呼风，哀笳带雪，一身飘寄，双鬓渐星。妇复多病，一男两女，藜藿不充，回念老母，茕然在堂，迢递关河，归省无日……”的回信，但是该信写于康熙十七年，晚于金缕曲成作日，暂不采纳。 注2：吴伟业在吴兆骞出关时作了一首《悲歌赠吴季子》，我也觉得写的挺好的： 白璧青蝇见排诋。一朝束缚去，上书难自理。绝塞千里断行李，送吏泪不止，流人复何倚。彼尚愁不归，我行定已矣。八月龙沙雪花起，橐驼垂腰马没耳，白骨皑皑经战垒，黑河无船渡者几，前忧猛虎后苍，土穴偷生若蝼蚁，大鱼如山不见尾，张耆为风沫为雨，日月倒行入海底，白昼相逢半人鬼。噫嘻乎悲哉!生男聪明慎莫喜，仓颉夜哭良有以，受患只从读书始，君不见，吴季子!","link":"/2018/01/31/金缕曲/"},{"title":"记录实用的python库","text":"本文专门用来记录一下python中一些好用方法/库，可以在日常使用中提高效率。 进度条 在爬虫和机器学习等工作中，可能需要有一个进度条能够反馈当前程序运行速度或者进度，可以考虑用以下方法实现： ShowProcess类 在网上找到别人写的一个方法如下： 1234567891011121314151617181920212223242526# 建立一个ShowProcess类class ShowProcess(): i = 0 max_steps = 0 max_arrow = 50 def __init__(self, max_steps): self.max_steps = max_steps self.i = 0 def show_process(self, i=None): if i is not None: self.i = i else: self.i += 1 num_arrow = int(self.i * self.max_arrow / self.max_steps) num_line = self.max_arrow - num_arrow percent = self.i * 100.0 / self.max_steps process_bar = '[' + '&gt;' * num_arrow + '-' * num_line + ']'\\ + '%.2f' % percent + '%' print('\\r',process_bar,end='',flush=True) def close(self, words='done'): print('') print(words) self.i = 0 使用示例： 12345678910111213if __name__=='__main__': max_steps = 100 process_bar = ShowProcess(max_steps) for i in range(max_steps): process_bar.show_process() time.sleep(0.05) process_bar.close()# 效果如下 &gt;&gt;&gt; [&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;]100.00%&gt;&gt;&gt; done 在命令窗口下使用正常，但是在IDLE和Spyder中显示存在问题，考虑使用其他方法。 tqdm安装1pip install tqdm 使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 最基本的用法import timefrom tqdm import tqdmfor i in tqdm(range(9)): time.sleep(0.1)# 效果如下&gt;&gt;&gt; 100%|██████████| 10/10 [00:01&lt;00:00, 9.79it/s]# trange类似于tqdmimport timefrom tqdm import trangefor i in trange(10): time.sleep(0.1)# 效果如下&gt;&gt;&gt; 100%|██████████| 10/10 [00:01&lt;00:00, 9.79it/s]# 传入listimport timefrom tqdm import tqdmpbar = tqdm([1,2,3,4,5,6,7,8,9,10]) for char in pbar: pbar.set_description(\"Processing %s\" % char) time.sleep(0.1)# 效果如下&gt;&gt;&gt; Processing 10: 100%|██████████| 10/10 [00:01&lt;00:00, 9.49it/s] # 手动控制更新import timefrom tqdm import tqdmwith tqdm(total=10) as pbar: for i in range(10): pbar.update(1) time.sleep(0.1)# 效果如下&gt;&gt;&gt; 100%|██████████| 10/10 [00:00&lt;00:00, 10.10it/s]# 也可以这样import timefrom tqdm import tqdmpbar = tqdm(total=10) for i in range(10): pbar.update(1) time.sleep(0.1)pbar.close() # 效果如下&gt;&gt;&gt; 100%|██████████| 10/10 [00:00&lt;00:00, 10.10it/s] 在Spyder下正常了，然而在命令窗口有问题。 重试 进行爬虫的时候，很容易因为网络问题导致失败，这里有2个库可以很轻松地实现这个功能。 retry安装1pip install retry 使用 只需要在函数定义前加上@retry就行了。 1234567891011121314151617from retry import retry@retry()def make_trouble(): '''重试直到成功'''@retry(ZeroDivisionError, tries=3, delay=2)def make_trouble(): '''出现ZeroDivisionError时重试, 重试3次，每次间隔2秒'''@retry((ValueError, TypeError), delay=1, backoff=2)def make_trouble(): '''出现ValueError或TypeError时重试, 每次间隔1, 2, 4, 8, ...秒'''@retry((ValueError, TypeError), delay=1, backoff=2, max_delay=4)def make_trouble(): '''出现ValueError或TypeError时重试, 每次间隔1, 2, 4, 4, ...秒，最高间隔为4秒'''@retry(ValueError, delay=1, jitter=1)def make_trouble(): '''出现ValueError时重试,每次间隔1, 2, 3, 4, ... 秒''' Tenacity 使用类似于retry。同样只需要在函数定义前加上@retry就行了。 安装1pip install tenacity 使用12345678910111213141516171819from tenacity import retry, retry_if_exception_type, wait_fixed, stop_after_attempt, stop_after_delay,@retry()def make_trouble(): '''重试直到成功'''@retry(retry=retry_if_exception_type(ZeroDivisionError), wait=wait_fixed(2), stop=stop_after_attempt(3))def make_trouble(): '''出现ZeroDivisionError时重试, 重试3次，每次间隔2秒'''@retry(stop=(stop_after_delay(10) | stop_after_attempt(5)))def make_trouble(): '''重试10秒或者5次''' @retry(wait=wait_random(min=1, max=2))def make_trouble(): '''重试间隔在随机1-2秒'''@retry(wait=wait_chain(*[wait_fixed(3) for i in range(3)] + [wait_fixed(7) for i in range(2)] + [wait_fixed(9)]))def make_trouble(): '''前三次重试每次间隔3秒，接下来2次间隔7秒，之后重试间隔9秒''' 超时 很多任务特别是多线程时，为了防止程序卡死，需要设定一个超时。 func_timeout 由于windows下signal的支持问题，选择使用第三方包，func_timeout就是一个给函数添加超时的包。 安装1pip install func_timeout 使用123456789101112131415161718192021222324import timefrom func_timeout import func_set_timeout,FunctionTimedOut# 基本用法try: doitReturnValue = func_timeout(5, doit, args=('arg1', 'arg2'))except FunctionTimedOut: print ( \"doit('arg1', 'arg2') could not complete within 5 seconds and was terminated.\\n\")except Exception as e: # 其他Exception# 装饰器用法@func_set_timeout(2)def task(): time.sleep(5)# 效果如下FunctionTimedOut: Function task (args=()) (kwargs={}) timed out after 2.000000 seconds.# 捕获异常from func_timeout.exceptions import FunctionTimedOuttry: task()except FunctionTimedOut: print('task func_timeout') 此外它还有一个重试的函数FunctionTimedOut，就不赘述了。 异步 待填坑……","link":"/2018/02/03/记录实用的python库/"},{"title":"Django学习笔记","text":"最近在学习一些WEB相关知识，这篇博文用于记录一些知识点，基于Django2.2来编写。 初始化新建虚拟环境 安装virtualenv： 1pip install virtualenv virtualenv使用： 123456# 创建virtualenv &lt;虚拟环境名称&gt;# 启动activate# 退出deactiavte 一键导出/安装扩展 命令提示符下： 12pip freeze &gt; requirements.txtpip install -r requirements.txt 基础知识新建项目 CMD下输入：django-admin startproject &lt;项目名&gt; 初始化数据库 CMD下输入：python manage.py migrate 启动本地项目 CMD下输入：python manage.py runserver 创建管理员 CMD下输入：python manage.py createsuperuser 创建应用 CMD下输入：python manage.py startapp &lt;应用名&gt; 在app目录下定义models.py，例如： 123class Article(models.Model): title = models.CharField(max_length=30) content = models.TextField() 保存后在项目目录下，settings.py注册该应用： CMD下执行： basic12python manage.py makemigrationspython manage.py migrate 在应用目录下，编辑admin.py： 12from .models import Articleadmin.site.register(Article) 绑定url 在项目目录下，编辑urls.py，参考注释： 12Add an import: from my_app import viewsAdd a URL to urlpatterns: path(&apos;&apos;, views.home, name=&apos;home&apos;) 注意事项 公用全局设置可放在settings中，统一管理 12from django.conf import settingssettings.XXX 进阶知识定制admin后台 在应用目录下，models.py中的类中，增加__str__方法，例如： 123456789from django.db import models# Create your models here.class Article(models.Model): title = models.CharField(max_length=30) content = models.TextField() def __str__(self): return \"&lt;Article: %s&gt;\" % self.title 项目目录下的admin.py： 1234567891011from django.contrib import adminfrom .models import Article# Register your models here.@admin.register(Article)class ArticleAdmin(admin.ModelAdmin): list_display = ('id','title','content') ordering = ('id',) # 倒序：('-id',)# admin.site.register(Article, ArticleAdmin) 修改模型 模型修改后要重新执行 12python manage.py makemigrationspython manage.py migrate 增加其他参数 修改models.py，增加如下内容： 1234567from django.utils import timezoneclass Article(models.Model):...... created_time = models.DateTimeField(auto_now_add=True) last_updated_time = models.DateTimeField(auto_now=True) author = models.ForeignKey(User, on_delete=models.DO_NOTHING,default=1) 相应的应于admin中的list_display增加字段。 给类增加默认排序，在父类中增加子类，形如： 12345678910111213141516171819202122from django.db import modelsfrom django.contrib.auth.models import Userclass BlogType(models.Model): type_name = models.CharField(max_length=15) def __str__(self): return self.type_nameclass Blog(models.Model): title = models.CharField(max_length=50) blog_type = models.ForeignKey(BlogType,on_delete=models.DO_NOTHING) content = models.TextField() author = models.ForeignKey(User, on_delete=models.DO_NOTHING) created_time = models.DateTimeField(auto_now_add=True) last_updated_time = models.DateTimeField(auto_now=True) def __str__(self): return \"&lt;Blog: %s&gt;\" % self.title class Meta: ordering = ['-created_time'] 使用Shell命令 命令提示符下输入： 1python manage.py shell 管理博文12345678910111213141516171819202122232425&gt;&gt;&gt;from blog.models import Blog&gt;&gt;&gt;from blog.models import BlogType&gt;&gt;&gt;from django.contrib.auth.models import User# 常用&gt;&gt;&gt;Blog.objects.all()&gt;&gt;&gt;BlogType.objects.all()&gt;&gt;&gt;User.objects.all()# 实例化&gt;&gt;&gt;blog = Blog()&gt;&gt;&gt;blog.title = 'shell下第1篇'&gt;&gt;&gt;blog.content = 'xxxxxxxxxxxxxxx'&gt;&gt;&gt;blog_type = BlogType.objects.all()[0]&gt;&gt;&gt;blog.blog_type = blog_type&gt;&gt;&gt;user = User.objects.all()[0]&gt;&gt;&gt;blog.author = user# 保存&gt;&gt;&gt;blog.save()#批量添加&gt;&gt;&gt;for i in range(1,31):... blog = Blog()... blog.title = \"for %s\" % i... blog.content = 'xxxx:%s' % i... blog.blog_type = blog_type... blog.author = user... blog.save() 网页搭建使用模版 应用目录下创建文件夹templates，然后创建html文件，编辑view.py，类似以下编辑： 1234567891011from django.shortcuts import renderfrom article.models import Articledef article_detail(request, article_id): try: article = Article.objects.get(id=article_id) context = {} context['article_obj'] = article return render(request, \"article_detail.html\", context) except Article.DoesNotExist: raise Http404('不存在') 也可以使用render_to_response方法： 123from django.shortcuts import render_to_response...... return render_to_response(\"article_detail.html\", context) 还有get_object_or_404方法： 12345678from django.shortcuts import render_to_response,get_object_or_404from article.models import Articledef article_detail(request, article_id): article = get_object_or_404(Article, pk=article_id) context = {} context['article_obj'] = article return render_to_response(\"article_detail.html\", context) html文件类似： 123456789&lt;html&gt; &lt;head&gt; &lt;body&gt; &lt;h2&gt;{{ article_obj.title }}&lt;/h2&gt; &lt;hr&gt; &lt;p&gt;{{ article_obj.content }}&lt;/p&gt; &lt;/body&gt; &lt;/head&gt;&lt;/html&gt; 创建目录 创建目录html页面，在urls里绑定，使用循环来遍历文章id，使用pk而不是id是更保险的写法。 123456789&lt;html&gt; &lt;head&gt; &lt;body&gt; {% for article in articles %} &lt;a href=\"/article/{{ article.pk }}\"&gt;{{ article.title }}&lt;/a&gt; {% endfor %} &lt;/body&gt; &lt;/head&gt;&lt;/html&gt; 超链接部分也可以用这种写法： 1&lt;a href=\"{% url 'article_detail' article.pk %}\"&gt;{{ article.title }}&lt;/a&gt; url合并 如果有很多应用，按之前的写法，url会太臃肿，因此可以在应用下新建urls.py： 1234567from django.urls import pathfrom . import viewsurlpatterns = [ path('&lt;int:article_id&gt;', views.article_detail, name='article_detail'), path('', views.article_list, name='article_list'),] 相应的，项目下url可改为： 123456789from django.contrib import adminfrom django.urls import include,pathfrom . import viewsurlpatterns = [ path('admin/', admin.site.urls), path('',views.index), path('article/',include('article.urls')),] 使用html模版 为了减少重复html代码的使用，可以使用block块来标记可替代内容，首先在项目根目录下创建templates文件夹，创建base.html并写入以下内容： 123456789101112131415&lt;!-- {% block &lt;别名&gt;%}{% endblock %} --&gt;&lt;!DOCTYPE html&gt;&lt;html lang=\"zh-cn\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;{% block title %}{% endblock %}&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;a href=\"{% url 'home' %}\"&gt;&lt;h3&gt;个人博客网站&lt;/h3&gt;&lt;/a&gt; &lt;/div&gt; &lt;hr&gt; {% block content %}{% endblock %}&lt;/body&gt;&lt;/html&gt; 与之相应地，可以在其他的html文件中，省略这些内容，只需要用extends引用，再到block块中填充即可，例如blog_list.html： 123456789101112131415161718192021&lt;!-- {% extends 'base.html' %} --&gt;&lt;!-- {% block &lt;别名&gt;%}{% endblock %} --&gt;{% extends 'base.html' %}{# 页面标题 #}{% block title %} 我的网站{% endblock %}{# 页面内容 #}{% block content %} {% for blog in blogs %} &lt;a href=\"{% url 'blog_detail' blog.pk%}\"&gt; &lt;h3&gt;{{ blog.title }}&lt;/h3&gt; &lt;/a&gt; &lt;p&gt;{{ blog.content|truncatechars:30 }}&lt;/p&gt; {% empty %} &lt;p&gt;-- 暂无博客，敬请期待 --&lt;/p&gt; {% endfor %} &lt;p&gt;一共有{{ blogs|length}}篇文章&lt;/p&gt;{% endblock %} 然后在项目文件夹中的setting.py中编辑TEMPLATES的DIRS列表，加入os.path.join(BASE_DIR, 'templates')。 使用css 在项目目录下新建static文件夹，写入base.css文件： 123456789101112131415161718* { margin: 0; padding: 0;}div.nav { background-color: #eee; border-bottom: 1px solid #ccc; padding: 10px 5px}div.nav a{ text-decoration: none; color:black; padding: 5px 10px;}div.nav a.logo { display: inline-block; font-size: 120%;} 然后在项目文件夹中的setting.py中加入： 123STATICFILES_DIRS = [ os.path.join(BASE_DIR, 'static'),] 引用方法： 1234567&lt;!-- head中写入 --&gt;&lt;link rel=\"stylesheet\" href=\"/static/base.css\"&gt; &lt;!-- 也可以用django自带方法，在html顶部写入 --&gt;{% load staticfiles %}&lt;!-- 再到head中写入 --&gt;&lt;link rel=\"stylesheet\" href=\"{% static 'base.css'%}\"&gt; 使用css框架Bootstrap基础 访问官网，下载新版Bootstrap，保留以下文件，放在项目static的新建的Bootstrap文件夹中： 1234567css bootstrap.min.css bootstrap.min.css.mapfont alljs bootstrap.min.js 参考文档，如果需要导入，可按如下代码： 12345678910111213141516171819{% load staticfiles %}&lt;!DOCTYPE html&gt;&lt;html lang=\"zh-cn\"&gt;&lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\"&gt; &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"&gt; &lt;title&gt;{% block title %}{% endblock %}&lt;/title&gt; &lt;link rel=\"stylesheet\" href=\"{% static 'base.css' %}\"&gt; &lt;link rel=\"stylesheet\" href=\"{% static 'bootstrap-3.3.7/css/bootstrap.min.css' %}\"&gt; &lt;script type=\"text/javascript\" src=\"{% static 'jquery-1.12.4.min.js' %}\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\" src=\"{% static 'bootstrap-3.3.7/js/bootstrap.min.js' %}\"&gt;&lt;/script&gt; {% block header_extends %} &lt;!-- 此处可以被其他html文件继承，用于加载css文件 --&gt; {% endblock %}&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 栅格系统 类前缀从超小到大分别为.col-xs-、.col-sm-、.col-md-、.col-lg-，也可以使用类如.visible-xs-block、.hidden-xs来显示或者隐藏，使用 例如.col-md-offset- 1类可以将列向右侧偏移。 1234&lt;div class=\"row\"&gt; &lt;div class=\"col-md-8\"&gt;.col-md-8&lt;/div&gt; &lt;div class=\"col-md-4\"&gt;.col-md-4&lt;/div&gt;&lt;/div&gt; 分页基础 shell中可以大致了解分页器的功能： 1234567891011&gt;&gt;&gt;from django.core.paginator import Paginator&gt;&gt;&gt;from blog.models import Blog&gt;&gt;&gt;blogs = Blog.objects.all()&gt;&gt;&gt;paginator = Paginator(blogs, 10)# 常用&gt;&gt;&gt;paginator.count&gt;&gt;&gt;paginator.num_pages&gt;&gt;&gt;paginator.page_range# 赋值&gt;&gt;&gt;page1 = paginator.page(1)&gt;&gt;&gt;page1.object_list 修改views.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455def blog_list(request): blogs_all_list = Blog.objects.all() paginator = Paginator(blogs_all_list, settings.EACH_PAGE_BLOGS_NUMBER) # 每10篇为1页 page_num = request.GET.get(\"page\", 1) # 获取url页码参数（GET请求） page_of_blogs = paginator.get_page(page_num) current_page_num = page_of_blogs.number #获取当前页码 # 获取当前页码前后各两位的范围 # page_range = list(range(max(current_page_num - 2, 1), current_page_num)) + \\ # list(range(current_page_num, min(current_page_num + 2, paginator.num_pages) + 1)) page_range = [x for x in range(current_page_num-2, current_page_num+3) if (x&gt;0 and x&lt;paginator.num_pages + 1)] # 加上首页和尾页以及省略页码标记 if page_range[0] - 1 &gt;= 2: page_range.insert(0,'...') if paginator.num_pages - page_range[-1] &gt;= 2: page_range.append('...') if page_range[0] != 1: page_range.insert(0,1) if page_range[-1] != paginator.num_pages: page_range.append(paginator.num_pages) context = {} context['blogs'] = page_of_blogs.object_list context['page_of_blogs'] = page_of_blogs context['page_range'] = page_range context['blog_types'] = BlogType.objects.all() # context['blogs_count'] = Blog.objects.all().count() return render_to_response('blog/blog_list.html',context)def blogs_with_type(request, blog_type_pk): blog_type = get_object_or_404(BlogType, pk=blog_type_pk) blogs_all_list = Blog.objects.filter(blog_type=blog_type) paginator = Paginator(blogs_all_list, settings.EACH_PAGE_BLOGS_NUMBER) # 每10篇为1页 page_num = request.GET.get(\"page\", 1) # 获取url页码参数（GET请求） page_of_blogs = paginator.get_page(page_num) current_page_num = page_of_blogs.number #获取当前页码 # 获取当前页码前后各两位的范围 # page_range = list(range(max(current_page_num - 2, 1), current_page_num)) + \\ # list(range(current_page_num, min(current_page_num + 2, paginator.num_pages) + 1)) page_range = [x for x in range(current_page_num-2, current_page_num+3) if (x&gt;0 and x&lt;paginator.num_pages + 1)] # 加上首页和尾页以及省略页码标记 if page_range[0] - 1 &gt;= 2: page_range.insert(0,'...') if paginator.num_pages - page_range[-1] &gt;= 2: page_range.append('...') if page_range[0] != 1: page_range.insert(0,1) if page_range[-1] != paginator.num_pages: page_range.append(paginator.num_pages) context = {} context['blog_type'] = blog_type context['blogs'] = page_of_blogs.object_list context['page_of_blogs'] = page_of_blogs context['page_range'] = page_range context['blog_types'] = BlogType.objects.all() # context['blogs_count'] = Blog.objects.all().count() return render_to_response('blog/blogs_with_type.html',context) 修改blog_list.html: 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;div class=\"paginator\"&gt; &lt;ul class=\"pagination\"&gt; &lt;!-- 上一页 --&gt; &lt;li&gt; {% if page_of_blogs.has_previous %} &lt;a href=\"?page={{ page_of_blogs.previous_page_number }}\" aria-label=\"Previous\"&gt; &lt;span aria-hidden=\"true\"&gt;&amp;laquo;&lt;/span&gt; &lt;/a&gt; {% else %} &lt;span aria-hidden=\"true\"&gt;&amp;laquo;&lt;/span&gt; {% endif %} &lt;/li&gt; &lt;!-- 全部页码 --&gt; {% for page_num in page_range %} {% if page_num == page_of_blogs.number %} &lt;li class='active'&gt;&lt;span&gt;{{ page_num }}&lt;/span&gt;&lt;/li&gt; &lt;!-- &lt;li class='active'&gt;&lt;a href=\"?page={{ page_num }}\"&gt;{{ page_num }}&lt;/a&gt;&lt;/li&gt; --&gt; {% else %} {% if page_num == '...' %} &lt;li&gt;&lt;span&gt;{{ page_num }}&lt;/span&gt;&lt;/li&gt; {% else %} &lt;li&gt;&lt;a href=\"?page={{ page_num }}\"&gt;{{ page_num }}&lt;/a&gt;&lt;/li&gt; {% endif %} {% endif %} {% endfor %} &lt;!-- 下一页 --&gt; &lt;li&gt; {% if page_of_blogs.has_next %} &lt;a href=\"?page={{ page_of_blogs.next_page_number }}\" aria-label=\"Next\"&gt; &lt;span aria-hidden=\"true\"&gt;&amp;raquo;&lt;/span&gt; &lt;/a&gt; {% else %} &lt;span aria-hidden=\"true\"&gt;&amp;raquo;&lt;/span&gt; {% endif %} &lt;/li&gt; &lt;/ul&gt; &lt;p&gt; 共有{{ page_of_blogs.paginator.count}}篇博客， 当前第{{ page_of_blogs.number }}页，共{{ page_of_blogs.paginator.num_pages }}页 &lt;/p&gt;&lt;/div&gt; 上一页/下一页 编辑views.py，其中__gt表示大于，同理lt为小于： 1234567def blog_detail(request,blog_pk): context = {} blog = get_object_or_404(Blog, pk=blog_pk) context['next_blog'] = Blog.objects.filter(created_time__gt=blog.created_time).last() context['previous_blog'] = Blog.objects.filter(created_time__lt=blog.created_time).first() context['blog'] = blog return render_to_response('blog/blog_detail.html',context)","link":"/2019/04/12/Django学习笔记/"},{"title":"k-近邻算法","text":"最近打算系统的回顾一下机器学习算法，所以以《机器学习实战》为依据，这次就由k-近邻算法开始回顾。 k-近邻算法概述 k-近邻算法（K-Nearest Neighbor ）的工作原理是：存在一个样本数据集合，也称为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类对应的关系。输入没有标签的新数据后，将新数据中的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。 以使用k-近邻算法分类爱情片和动作片，有人统计过很多电影的打斗镜头和接吻镜头如下表，假如有一部未看过的电影，以？来表示，如何确定它是爱情片和动作片呢？ 电影名称 打斗镜头 接吻镜头 电影类型 Califoria Man 3 104 爱情片 He’s Not Really into Dudes 2 100 爱情片 Beautigul Woman 1 81 爱情片 Kevin Longblade 101 10 动作片 Robo Slayer 3000 99 5 动作片 Amped II 98 2 动作片 ? 18 90 未知 在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离： 我们用欧氏距离来得到如下距离值： 电影名称 与未知电影的距离 Califoria Man 20.5 He’s Not Really into Dudes 18.7 Beautigul Woman 19.2 Kevin Longblade 115.3 Robo Slayer 3000 117.4 Amped II 118.9 按照距离递增排序，可以找到k个距离最近的电影。假设k=3，则三个最靠近的电影依次是He’s Not Really into Dudes、Beautigul Woman和Califoria Man。k-近邻算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全是爱情片，因此我们判定未知电影是爱情片。 准备：使用Python导入数据 首先，创建名为KNN.py的python模块： 1234567import numpy as npimport operatordef createDataSet(): group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]]) labels = ['A','A','B','B'] return group, labels 这里我们准备了4组数据，每组数据有两个我们已知的属性或者特征值。接下来我们将完成分类任务。 实施KNN分类算法 定义函数classify0()如下： 1234567891011121314151617def classify0(inX, dataSet, labels, k): dataSetSize = dataSet.shape[0] #用于计算欧氏距离 #将intX在纵向重复dataSetSize次 diffMat = np.tile(inX, (dataSetSize,1)) - dataSet sqDiffMat = diffMat**2 sqDistances = sqDiffMat.sum(axis=1) distances = sqDistances**0.5 #返回从小到大的索引值 sortedDistIndicies = distances.argsort() classCount={} for i in range(k): voteIlabel = labels[sortedDistIndicies[i]] classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1 #按第二个元素的次序，对元组进行逆序排序，即从大到小排序，返回发生频率最高的元素标签 sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True) return sortedClassCount[0][0] 至此，我们构建了第一个分类器。 示例：使用k-近邻算法改进约会网站的配对效果 海伦一直使用在线约会网站寻找自己的约会对象，她把自己交往过的对象分为以下三类： 不喜欢的人 魅力一般的人 极具魅力的人 因此，她希望更好地将她匹配的对象分类。 准备数据：从文本文件中解析数据 她把数据存放在文本文件datingTestSet2.txt中，每个样本数据占据一行，主要包含以下3种特征： 每年获得的飞行常客里程数 玩视频游戏所耗时间百分比 每周消费的冰淇淋公升数 创建名为file2matrix的函数，把数据转变为分类器可以接受的格式。 1234567891011121314151617def file2matrix(filename): fr = open(filename) arrayOlines = fr.readlines() # 得到文件行数 numberOfLines = len(arrayOlines) # 创建返回的NumPy矩阵 returnMat = np.zeros((numberOfLines,3)) classLabelVector = [] index = 0 # 解析文件数据到列表 for line in arrayOlines: line = line.strip() listFromLine = line.split('\\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(int(listFromLine[-1])) index += 1 return returnMat,classLabelVector 接下来图形化展示数据内容。 分析数据：使用Matplotlib创建散点图 定义一个scatterPlot函数进行可视化。 12345678import matplotlibimport matplotlib.pyplot as pltdef scatterPlot(): fig = plt.figure() ax = fig.add_subplot(111) p = ax.scatter(datingDateMat[:,1], datingDateMat[:,2], 15.0*np.array(datingLabels), 15.0*np.array(datingLabels)) plt.show() 得到了玩视频游戏所耗时间百分比和每周消费的冰淇淋公升数的关系散点图： 同理也能得到每年获得的飞行常客里程数和玩视频游戏所耗时间百分比的关系散点图，可以得到更好的展示效果： 可以知道具有不同的爱好的人其类别区域也不同。 准备数据：归一化数值 玩视频游戏所耗时间百分比 每年获得的飞行常客里程数 每周消费的冰淇淋公升数 样本分类 1 0.8 400 0.5 1 2 12 134000 0.9 3 3 0 20000 1.1 2 4 67 32000 0.1 2 上表给出提取的四组数据，要计算样本3和4的距离，使用以下方法： 容易发现，上面方程中数值差值最大的属性对计算结果的影响最大，也就是说，每年获取的飞行常客里程数对于计算结果的影响将远远大于该表其他两个特征的影响。而三种特征是同等重要的，因此需要把数值归一化。 增加函数autoNorm用于归一化： 123456789def autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals normDateSet = np.zeros(np.shape(dataSet)) m = dataSet.shape[0] normDateSet = dataSet - np.tile(minVals, (m,1)) normDateSet = normDateSet/np.tile(ranges, (m,1)) return normDateSet, ranges, minVals 在机器学习框架scikit-learn中，有封装好的标准化函数： 1234567891011# 归一化from sklearn.preprocessing import MinMaxScalerss = MinMaxScaler()X = ss.fit_transform(X)# 标准化from sklearn.preprocessing import StandardScalerss = StandardScaler()X = ss.fit_transform(X)#归一化其实就是标准化的一种方式，只不过归一化是将数据映射到了[0,1]这个区间中。#标准化则是将数据按照比例缩放，使之放到一个特定区间中。标准化后的数据的均值＝0，标准差＝1，因而标准化的数据可正可负。 测试算法：作为完整程序验证分类器 创建函数datingClassTest以测试分类器效果： 123456789101112def datingClassTest(): hoRatio = 0.10 datingDataMat,datingLabels = file2matrix('datingTestSet2.txt') normMat, ranges, minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errorCount = 0.0 for i in range(numTestVecs): classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) print(\"the classifier came back with: %d, the real answer is: %d\" % (classifierResult, datingLabels[i])) if (classifierResult != datingLabels[i]): errorCount += 1.0 print(\"the total error rate is: %f\" % (errorCount/float(numTestVecs))) 通过分类器可得错误率为5%，结果还不错，也可以改变hoRatio和k来得到不同结果。 这个例子表明我们可以得到较好的分类结果，海伦可以输入未知对象的属性，由分类软件来帮助她判定某一对象的可交往程度：讨厌、一般喜欢、非常喜欢。 示例：手写识别系统 上面的例子使用的数据比较容易理解，如何在人不太容易看懂的数据上使用分类器呢？我们将使用k-近邻分类器用于手写数字识别。 准备数据：将图像转换为测试向量 首先把图像格式化处理为一个向量。即将32×32的二进制文本。如果要使用我们的分类器，就将其变成1×1024的向量。 编写函数实现： 12345678def img2vector(filename): returnVect = np.zeros((1,1024)) fr = open(filename) for i in range(32): lineStr = fr.readline() for j in range(32): returnVect[0,32*i+j] = int(lineStr[j]) return returnVect 测试算法：使用k-近邻算法识别手写数字 使用以下代码测试分类器： 1234567891011121314151617181920212223hwLabels = []trainingFileList = os.listdir('trainingDigits') # 读取训练集m = len(trainingFileList)trainingMat = np.zeros((m,1024))for i in range(m): fileNameStr = trainingFileList[i] fileStr = fileNameStr.split('.')[0] # 从文件名解析分类数字 classNumStr = int(fileStr.split('_')[0]) hwLabels.append(classNumStr) trainingMat[i,:] = img2vector('trainingDigits/%s' % fileNameStr)testFileList = os.listdir('testDigits') # 载入测试集errorCount = 0.0mTest = len(testFileList)for i in range(mTest): fileNameStr = testFileList[i] fileStr = fileNameStr.split('.')[0] classNumStr = int(fileStr.split('_')[0]) vectorUnderTest = img2vector('testDigits/%s' % fileNameStr) classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3) print(\"the classifier came back with: %d, the real answer is: %d\" % (classifierResult, classNumStr)) if (classifierResult != classNumStr): errorCount += 1.0print(\"\\nthe total number of errors is: %d\" % errorCount)print(\"\\nthe total error rate is: %f\" % (errorCount/float(mTest))) 本函数是将trainingDigits目录中的文件内容存储在列表中，然后得到目录中有多少文件，并将其存储到变量m中。接着，创建m行1024列的训练矩阵，该矩阵的每行数据存储一个图像。我们可以从文件名中解析出分类数字。该目录下的文件按照规则命名，如文件9_45.txt的分类是9，它是数字9的第45个实例。然后我们可以将类代码存储到hwLabels向量中，使用前面讨论的img2vector函数载入图像。在下一步中，我们对testDigits目录中的文件执行相似的操作，不同之处是我们并不将这个目录下的文件载入矩阵中，而是使用classify0()函数测试该目录下的每个文件。由于文件中的值已经在0和1之间，并不需要进行标准化。 通过测试本分类器，发现有相对理想的结果。 实际使用本算法时，算法的执行效率并不高。因为算法需要为每个测试向量做2000次距离计算，每个距离计算包括了1024个维度浮点运算，总计要执行9000次，此外还得为测试向量准备2MB的存储空间。是否存在一种算法减少存储空间和计算时间的开销呢？k决策树就是k-近邻算法的优化版，可以节省大量计算开销。 本章小结 k-近邻算法是分类数据最简单最有效的算法，本章通过两个例子蒋旭了如何使用k-近邻算法构造分类器。k-近邻算法是基于实例的学习，使用算法时我们必须有接近实际数据的训练样本数据。k-近邻算法必须保存全部数据集，如果训练数据集很大，必须使用大量的存储空间。此外由于必须对数据集中的每个数据计算距离值，实际使用时可能非常耗时。 k-近邻算法的另一个缺陷是它无法给出任何数据的基础结构信息，因此我们也无法知晓平均实例样本和典型实例样本具有什么特征。可以通过概率测量方法处理分类问题以解决此问题。 参考资料：《机器学习实战》","link":"/2018/12/25/k-近邻算法/"},{"title":"悬疑推理向游戏记录","text":"记录一下玩过的悬疑推理向游戏，排名按照个人喜好，分先后。 428:被封锁的涩谷 严格意义上讲，这个不能算推理游戏，应该归为悬疑游戏。不过叙事上非常优秀，而且结局众多，众多情节都很合乎逻辑，相互照应。是Fami通唯一一个满分的音像小说。 这个游戏以涉谷一天中5个不同主角的不同行为来推演结果，其中一个主角无厘头的行为有可能就决定了另外一个主角的生死，当最后所有人的剧本交织在一起的时候，那种美妙的感觉实在是让人感叹。 本作是我最喜欢的ADV，个人评分：9.6分。 Ever 17 meta类的游戏，它并不是第一个，诡叙类的游戏，它也不是第一个，不过把这些核心诡计藏到最后，直到最后一刻才揭晓，难怪大部分玩过这部作品都要称为“神作”。作为一部02年的作品，它的地位大概可以类比《占星术杀人魔法》在推理小说中的地位，属于开创性的。 由于我不喜欢Galgame中冗长的日常，所以觉得前面四条线日常有点偏多，而这游戏属于必须通完五条线才能看到真结局的，觉得有点拖沓。但是通关后会有豁然开朗之感，之前的一些伏线基本上全部收回。只能佩服打越钢太郎的布局和脑洞。 总结而言，本作是打越钢太郎的巅峰之作，他后面的作品都未能再有突破，个人评分：9.5分。 幽灵诡计 巧舟的另一部封神之作，主角开场就死了，然后灵魂状态的他拥有附体和回到死前4分钟的能力，要在一夜之间一步步找回记忆并发现死亡真相的故事。剧情全程无尿点，浑然天成，各种反转让人欲罢不能。和巧舟所做的逆转裁判比这个更像是一个小品级的作品，剧情又因为已经形成闭环大概也不可能有续作了，可惜受限于平台在国内只能是小众。 个人评分：9.2分。 大逆转裁判系列 合并在一块是因为这个作品单看第一部并不够出色，很多线没收，只有一二部合在一起才算构成了闭环。逆转裁判系列在我心目中尚且不如这部外传。 整个作品设定在十九世纪末二十世纪初的英国，音乐和画风确实很还原，用了不少细节刻画当时的风土人情，而且我喜欢的福尔摩斯也在里面出场，就推理质量而言，整体案件二比一强了不少，而且二基本上把一里面挖的坑填完了，硬生生挽回了大逆转裁判一几乎崩掉的口碑。 个人而言更喜欢这个系列，逆转裁判本作更类似于设定系推理，我是不太喜欢推理作品里面有超自然因素的，相对而言大逆转裁判更加古典一点。 个人评分：大逆转裁判一8分，大逆转裁判二9.2分，合起来可以算9.1分。 诡计×逻辑 非常硬核的本格推理游戏，推理短篇合集，作者包括麻耶雄蒿、我孙子武丸、大山诚一郎、绫辻行人、有栖川有栖等，都是在本格推理界鼎鼎大名的作者了。唯一的问题是没有完整汉化，这也算是遗憾了。 另外也要碎碎念这个系统，就算你知道Trick了也得慢慢穷举把闪现凑出来，结果无限拉长游戏时间，很容易劝退玩家。而且有些闪现很不合理，根本就很难理解为什么能组合，事实上不看攻略的情况下想凑齐全闪现和解答是非常困难的，逼死本强迫症。 单案评价详见诡计x逻辑案件盘点。 个人评分：短篇集是我最喜欢的推理小说体裁，这个游戏深得我心，可惜模式确实很不人性化，非常降低游戏乐趣。9.1分。 神林家杀人事件 由于没中文只能看实况云通关了，题材是我非常喜欢的暴风雪山庄，在推理小说里面有时候会有书中书的模式，比如《首无·作祟之物》、《匣中失乐》和《喜鹊谋杀案》等等，这也是很容易作为诡计和多重解答的一种表现方式。游戏里则比较少见，作者在这个架构上做了类似设定，很有意思。 作者在游戏里面埋了很多推理梗，当然由于我不懂日语不能一一get，up主似乎也略过了很多没翻。总体来说还是挺有趣的，虽然作者自己借游戏角色之口吐槽了诡叙，但是依然使用了这个技巧，真香警告？ 值得一提的是，和《恐怖惊魂夜》类似，伪结局最后是一个输入凶手名字的设定，输入各种角色名都有正经亦或是胡说八道的推理，差点没笑死我，作者脑洞真大，恶搞了无数小说或者游戏，当然也可能会因此被剧透不少经典推理作品。至于真结局伏笔也埋的很深，可惜涉及日本地理知识没办法识破。 个人评分：非常有意思的小品游戏，9.0分。 去月球 这个也不能被当做推理游戏，在众多RPG Maker作品中可以排进总统山级别了，尤其是里面的《for river》我一度单曲循环。这个世界有借由改变记忆为弥留之际的人们完成愿望的公司，其中的两个医生准备为约翰完成这个服务，却发现并没有容易奏效，通过不断发掘他的记忆从而揭开了他过去的秘密。 个人感受就是好的故事不会受限于表达形式与技术水平，虽然是很简单的一个RM游戏，但是也让人感动万分。 作者有意做一个“去月球宇宙”，但《鸟的故事》和《寻找天堂》还是没给我带来相比于《去月球》的体验的。 PS：给我带来深刻印象的RM游戏，还有《黑暗圣剑传说》、《雨血》系列。 个人评分：9.0分，《鸟的故事》&amp;《寻找天堂》8.5分。 命运石之门 这部作品比Ever 17强在动画化了，而且人设更加讨喜，因此名气大了不少。不过就我个人而言，一方面觉得这种LOOP类的游戏已经珠玉在前，创新性扣分，此外日常部分就更多，玩起来就更觉得拖沓了。 但是这部游戏作为科学幻想系列作品，世界观的设定更为严谨一点，谜面解答也很公平，称得上是佳作。 个人评分：9.0分。 弹丸论破系列 这个游戏系列的名气还是很高的，毕竟也有过动画化。个人而言比较喜欢这个系列的题材，暴风雪山庄的设定加上水平尚可的案件，量大管饱，而且比逆转裁判系列代入感和推理性要更强一点，逆转裁判的问题稍后再说。 案件质量而言应该是2&gt;1&gt;V3，V3的问题一方面人设感觉没之前有亮点，另一方面后期有点放飞自我，直接变meta了，感觉把系列的路全堵死了，不过中间玩的Trick还算有点意思，扣住了主题“谎言”。 总体来说还是相当推荐的，毕竟推理性很强，比起《逆转裁判》这类的更本格一点。在《诡计×逻辑》的汉化出来之前（恐怕也不太可能出来）似乎也就这个更符合我的审美了。 个人评分：弹丸论破1为8.8分，弹丸论破2为9.0分，弹丸论破V3为8.6分，综合来看系列分大概在8.9左右。 极限脱出系列 打越钢太郎的代表作之一了，第一部《极限脱出:9小时9个人9之门》是该系列的巅峰之作，最终的Trick配合NDS特有的双屏给人的震撼无以复加。当然核心诡计抄了打越自己的《Ever 17》，这就是传说中的我抄我自己。 从第二部《极限脱出:善人死亡》开始，就开始一部比一部扑，诡计上也一部不如一部，第三部还是在欧美粉丝的支持下才出来的，不过建模岂是一个崩字了得，可见经费捉襟见肘。估计也不会有续作了，还是挺遗憾的。不过要说到密室脱逃，个人感觉手机上爆火的《Room》远不如这个。 个人评分：极限脱出1为9.2分，极限脱出2为8.8分，极限脱出3为8.4分，综合来看系列分估计也就给个8.8左右。 逆转裁判系列 这里把逆转裁判1-6和逆转检事1-2以及雷顿教授vs逆转裁判拉一块说。 逆转裁判的切入点确实很好，在那个年代的游戏基本上都是侦探视角的破案游戏，巧舟把观念逆转过来，弄了个法庭辩论游戏，当然法庭辩论在侦探小说界也算不上新梗，毕竟卡尔的名作《犹大之窗》早就涉及相关题材，但是这个游戏也算是开辟了推理ADV的新道路。 个人觉得在逆转裁判1-3和逆转检事1-2之后这个系列已经露出了疲态，该写的已经都写了，按理说应该可以完结了。卡普空为了继续捞钱，强行开续作，而之后的增加的主角王泥喜和心音完全撑不起逆转裁判这个IP，案件乏善可陈，玩下去已经成为一种惯性，我猜大概也是巧舟要重新开大逆转裁判系列的目的吧。 《雷顿教授vs逆转裁判》这一作联动完全对不住两个IP的名头，剧情也有点扯淡，亮点恐怕就是有配音的逆转裁判了。 个人评分：逆转裁判三部曲8.7分，逆转检事两部曲8.8分，剩下的4-6大致在8.4-8.6分左右，雷逆8.0分，综合评价8.7分。 恐怖惊魂夜 鼎鼎大名的作品，脚本我孙子武丸，在日系AVG里面有着不可忽视的地位。从1994年推出第一部就获得了不俗的销量和口碑，也在后面的时间里多次移植与重制。 主线设计是典型的暴风雪山庄设定，主人公和女友因为暴风雪被困在旅馆里，结果遭遇连环杀人事件。虽然现在这种游戏已经没什么新意了，不过考虑到是90年代的作品，还是挺不错的。游戏会根据不同的选择进入不同分支，或全灭或全员存活取决于你的选择以及推理，还有不少脑洞打开的结局，玩起来趣味十足。而且不同于《方根书简》那种生硬的掰扯，本作的铺垫会更自然一点，逻辑相对完整。 个人评分：非常有趣的作品，虽然放在现在可玩性没那么高，但是考虑到其开创性，8.6分。 AI：梦境档案 打越新作，这次国庆肝了3天全通了。不得不说，现在的推理悬疑向游戏太少了，连一年一部都很难保证。 本来是期待一部超越《Ever 17》或者《极限脱出》的作品，不过看上去打越对市场妥协了，做了一部相对比较讨喜市场的作品。游戏里有非常多玩梗的地方，看到会给人会心一笑的感觉，相对于他之前的作品，整体氛围也轻松了不少。不同支线埋的坑，基本上都在最后回收了，还是可以见到打越的功力的。然而这部作品的谜面并不出众，基本上玩到中途就能猜到结尾了，给我的惊喜不够。 另外本作的Psync感觉没《极限脱出》系列的密室逃脱有意思，大概还是对市场的妥协吧，毕竟不能再承受一次《善人死亡》的暴死了吧。 更新：听说这次在日本销量又暴死了，这次可能是里面黄段子太多了吧哈哈哈。 个人评分：8.5分。 G弦上的魔王 同样是诡叙性的作品，而且游戏一直在刻意误导玩家，然而最后的反转会让人感觉铺垫不足，不够严谨。优点在于是斗智类剧情，能够吸引人一直玩下去，BGM也是其中的亮点，基本上全部是世界古典名曲或变奏。 总的来说，是一部主线强而支线较弱的作品，值得一口气玩下去，但是核心诡计不够完美应该扣分。 个人评分：8.0分。 柯南/金田一系列 从GB到3DS有众多柯南/金田一主题的游戏，姑且放在一类吧。当然远古作品很多没有汉化无法玩到，我就挑有汉化的几部来说吧，总的来说这些系列作品的质量还算稳定，但也没什么惊喜。 《名侦探柯南&amp;金田一少年事件薄：交错的两位名侦探》：剧本是小高和刚，总的来说质量不差，算是这堆作品里面最靠谱的一个了。两大著名死神携手作战，双线叙事，诡计也有点意思，被怪异君扑街的大电影借用了hhh，而且当初玩的时候还年轻，没现在这样身经百战。评分：8.5分。 《金田一少年事件簿：恶魔之杀人航海》：推理性一般，故事相对比较无聊，有恶心的拆炸弹游戏。评分：7分。 《金田一少年事件簿：星见岛悲哀的复仇鬼》 ：土星上的游戏，受限于平台没有汉化，不过还好有up主做实况，于是云通关了。这个游戏主要是视角独特，是从犯人的角度来描绘的，目的为了实现完美谋杀。如果失败了还有金田一里面的经典角色告诉你要注意的地方，其实是看各种花式失手23333。评分：7.5分。 《名侦探柯南：苍蓝宝石的轮舞曲》：其实还行，比上一个作品好点。玩这个的时候我还丢了一次存档，重打的时候真痛苦。评分：7.5分。 《名侦探柯南：来自过去的前奏曲》：比苍蓝宝石好玩一点，至少是一个连成线的故事，可惜毫无惊喜感。评分：7.7分。 《名侦探柯南：木偶交响曲》：推理性不咋地，不过表现系统还行，画面嘛，玩过NDS的作品，感觉3DS贼亲切hhh，平庸之作。评分：7.5分。 《名侦探柯南：幻影狂诗曲》：3DS汉化第二作，比第一作有意思一点，整了个多重反转，尚可一玩。评分：7.9分。 个人总结：作为粉丝向作品，主要还是看喜欢的人物，就故事性而言，各个案件水平参差不齐，无聊的时候可以玩玩。综合评价：7.8分。 端木斐异闻录 国产推理游戏，本来都快忘了玩过这玩意的，结果前段时间看到个盘点想起来了，顺手添进来吧。 总的来说相对平庸，人物刻画也很扁平，只能当一个半推理半Galgame来玩，而且有一些超自然元素了，对于本格来说还是挺不公平的。撇开剧情来看，游戏里面有些细节还是挺有意思的，比如iPad系统，可以拍照解锁表情什么的，体现出Ren’py制作Galgame的强大之处。 个人总结：国产推理游戏，人设尚可，给个友情分7.0分。 方根书简 本来是冲着岳父人设来玩的，结果没想到首发入了没多久就打骨折，游戏体验还挺一般的，简直是双倍打击。 其实多重解答在推理游戏里也不算很少见，比如《恐怖惊魂夜》系列，又比如我一直念念不忘的《流行之神》系列，只不过本作实在表现拙劣，完全看不出铺垫，感觉就是口胡硬拽出个结局，让人有种智商被愚弄的感觉。此外，游戏的剧情也注水严重，几个重要角色个个像弱智，全靠主角嘴炮致胜，脚本作者还需要好好修炼修炼，不然还是别挂这个推理悬疑名号了，太丢人了。 当然优点还是有的，比如画风讨喜，岛根的景点特产介绍用心，让我有种去那边旅游的冲动。 最扯淡的是，居然还有钱做个真人版，嫌亏得不够多嘛？ 个人总结：推理游戏×，旅游宣传游戏√，给个及格分6.0是看在俺岳父份上。","link":"/2020/05/11/悬疑推理向游戏记录/"},{"title":"诡计x逻辑案件盘点","text":"⊙﹏⊙b汗，本来只是想扔到推理游戏合集里面的，结果越写越长，干脆独立出来，这样也不会显得喧宾夺主。 前言 这个游戏算是非常硬核的本格推理游戏，推理短篇合集，作者包括麻耶雄蒿、我孙子武丸、大山诚一郎、绫辻行人、有栖川有栖等，堪称本格推理全明星阵容。唯一的问题是没有完整汉化，目前仅第一季有部分汉化，所以我就着兔碳的实况和落樱时节的文本翻译完成了本作游玩。 另外也要碎碎念这个系统，就算你知道Trick了也得慢慢穷举把闪现凑出来，结果无限拉长游戏时间，很容易劝退玩家。而且有些闪现很不合理，根本就很难理解为什么能组合，事实上不看攻略的情况下想凑齐全闪现和解答是非常困难的，逼死本强迫症。 【泄底警告】虽然我已经尽可能避免泄底了，不过如果你对推理小说有一定阅读量可能会被我有意无意的泄底，所以往下阅读请慎重。 主线 没错，这个游戏也是有主线的！男主角有点像御剑怜侍，连背景设定都很像，父亲也是个律师hhhhh。这里讲的是男主在阎魔和女主等帮助下完成自我救赎，不再是一个偏激且不择手段的检察官的故事，逆转粉会心一笑好吧。 分集尸体所指 作为初始教程的谜题，相对来说比较简单，结果受限于系统设定试了好久才把线索凑齐。 被盗的手办 作者我孙子武丸，没有凶案，剧情让俺想到了某师弟，四斋蒸鹅心啊。Trick依然很简单，在某著名作品里面用过了，不过在80多页里面找关键词来凑闪现还是花了我一下午时间，搞的网课也没怎么听，血亏！ 光线消失的房间 作者竹本健治，写过四大奇书之一的《 匣中失乐》，平心而论《匣中失乐》有点故弄玄虚，相对而言这篇给我的感觉还行。难度不大，基本上凭直觉就知道凶手了，然后Trick也不难猜到，就是那个闪现太难凑了，居然要尸僵和“ 运动神经看起来相当不错的阳光青年 ”组合，让人不明所以，也有可能是翻译问题，反正本日文苦手就没法深究了。 飘雪的女生宿舍 作者麻耶雄嵩！虽然麻神的作品相当放飞自我，结果这个谜题的设计还是挺精巧的。死亡信息也是本格推理中很常见的元素，不过也仅仅是在作品中很常见， 现实生活中留下那种需要人猜的信息还是挺少见的。这篇也是和死亡信息有关，重点是为什么凶手要在早上返回消除死亡信息，想明白这点就能经过逻辑排除推出凶手了。只能说细节还是埋的挺巧妙的，但是小说越来越长了，这次是在200页里面翻关键词，我要吐了。 被斩断的五首 作者大山诚一郎！他的短篇集《密室收藏家》和《赤色博物馆》都是我很喜欢的作品，所以对这篇我也报以很大期望。然而这个故事真的很难，还是诡叙，强烈怀疑和上篇麻神的名字弄混了hhh。 回到本篇，这篇里面出现了无面尸元素，读的时候我第一感觉是身份互换，没想到后面作者亲自在剧情里驳斥了这个观点把我打脸了。反正俺是没想出来答案，只能看了提示才解出来，但是最后的答案真的把我气笑了，有种看《消失！》的感觉。不过细想一下该给的线索也给了，就是不知道有没有大佬凭自己本事推理出来。 亡灵哈姆雷特 作者黑田研二，他最出名的作品是《婚纱》，不过我还没读23333，这个作者最牛的地方还是能把《逆转裁判》和《极限脱出》等游戏IP都拿到改编权出书，有点东西，虽然质量似乎挺一般的。围绕监控器做文章也是近些年科技进步对古典推理的冲击吧。扯一嘴，这方面的文给我印象深刻的有《全部成为F》、《玻璃之锤》以及日剧《上锁的房间》的SP（因为俺没看贵志祐介的其他小说，不确定是否有原著改编）等等。 说回来这个故事，再次说明画时刻表和示意图在本格推理阅读的重要性！如果对比示意图，大概也能理解凶手交换的目的所在了，然后也不难猜出手法。总的来说还是挺公平的推理了，该埋的伏笔都有了。 血腥玛丽之谜 作者竹本健治。这篇怎么说呢，感觉挺一般的。虽然逻辑上行得通，也可以推导出来，但是我觉得有点浪费时间，也没什么惊喜。我不太喜欢Trick被限定到极其局限的地步，这篇恰恰如此，只能在很特定的情况下实现，感觉有点欺负被害者的感觉hhhh。当然内容很点题，大概就是为了这个题目设计的Trick？话说我这样是不是算泄底了。 来复线的谋杀 作者麻神。这篇有岛田流的风格，在一个湖中的小岛——高丽岛上，著名幻想作家被射杀，桌上留下了Dying Message：“奇迹”，奇怪的是，窗外正对着的却是悬崖……Trick倒是有点像某《三星馆杀人事件》（大雾），好像又泄底了。但是我还是觉得有点雷人，至少森博嗣那篇还能让我觉得有点道理，而在这里的话真的能那么巧嘛？可能要归结于大自然的鬼斧神工吧。貌似作者也用了日语梗暗示了，可惜俺没法get到。 所以就这点而言我觉得这个故事设计的挺失败的。而且这篇的流程设计也不是很合理，正推的话必须依赖犯人的误解来判断凶手，反推的话，在你预设了一个凶手然后系统会硬给你塞线索，闪现直接就把Trick点出来了，又有点强行降低难度了的感觉。反正就很迷，大概也是因为这个故事的Trick立意不好带来的后果吧。 视线铁壁的密室 大山诚一郎，永远滴神！感觉这篇是本季质量最高的了。本篇是一个看似不可能完成的视线密室，通过不同人的视角来描述案件过程，似乎还用到了一点叙述性诡计。里面细节非常多，而且很有逻辑性，列出时间线并从一一击破游戏里的谜题，最终推导出结论的感觉非常爽快，非常值得一玩。 Y的目标 绫辻行人、有栖川有栖携手打造大型生草剧本，拜阳教教主被石头砸死在中庭，文本非常非常的长，渲染很多，感觉全是废话。不过确实把我给难住了，可能是我也没想到还能设计这种手法吧，真是太耍流氓了！总之是我举手投降的岛田流剧本，难怪敢直接标题泄底的，我看到标题第一印象还以为是致敬奎因，害。 完美无缺的不在场证明 作者我孙子武丸。第一眼看上去感觉是时刻表诡计，时刻表诡计在日系推理中还是很常见的，代表作松本清张的《点与线》、岛田庄司的《出云传说7/8杀人事件》等，大山诚一郎的《伪证破解家》也可以作为不在场证明讲义来看。虽然是很讲逻辑性的推理小说套路，但是个人感觉解起来没那些不可能犯罪有意思。 这篇作为压轴感觉弱了点，列完时间线后就感觉每个人都不足以犯案，那么就只有一种可能了！感觉有点像阿婆的某不朽名作hhh，替店长点根蜡烛。 暴走的朱丽叶 番外篇，和主线没有关联，算是一个独立的小说。作者黑田研二，Trick和上面的某篇有一点点像，感觉有点雷人，不过既然是番外篇也就不计较那么多了。 结局 到最后又接上了主线，揭示了主角和父亲的案件的真凶，也正是主角一直给他们提供帮助，才让事件发展到最后真相大白，有一种善恶有报的因果论的感觉，最后一段动画还挺帅的。 总的来说，游戏质量还是挺高的，私以为必玩的有《视线铁壁的密室》、《飘雪的女生宿舍》，有争议的有《被斩断的五首》，其他的也算基本上水准在线，是本格推理迷应玩的佳作了~","link":"/2020/05/25/诡计x逻辑案件盘点/"},{"title":"FP-growth算法","text":"你用过搜索引擎吗？输入一个单词或者一个单词的一部分，搜索引擎就会自动补全查询词项。用户甚至事先都不知道搜索引擎推荐的东西是否存在，反而会去查找推荐词项。那么这些推荐词项是如何被搜索引擎找到的？那是因为研究人员使用了FP-growth算法，它是基于Apriori构建的，但完成相同任务时将数据集存储在一个特定的称作FP树的结构之后发现频繁项集或频繁项对，即常在一起出现的元素项的集合FP树。这是一种比Apriori执行速度更快的算法，能高效地发现频繁项集，但不能用于发现关联规则。 FP-growth算法只需要对数据库进行两次扫描，而Apriori算法对于每个潜在的频繁项集都会扫描数据集判定给定模式是否频繁，因此FP-growth算法的速度比Apriori算法快。在小规模数据上，这不是什么问题，但当处理更大数据集时，就会产生较大问题。FP-growth算法只会扫描数据集两次，它不会生成候选项集，其发现频繁项集的基本过程如下： 构建FP树 从FP树中挖掘频繁项集 FP-growth原理 FP-growth算法将数据存储在一种成为FP树的紧凑数据结构中。FP代表频繁模式（Frequent Pattern）。一颗FP树与计算机科学中其他树结构类似，但它通过链接（link）来连接相似元素，被连起来的元素可以看成一个链表。 下面用一个例子来说明，给出一组数据如下： 事物ID 事物中的元素项 001 r,z,h,j,p 002 z,y,x,w,v,u,t,s 003 z 004 r,x,n,o,s 005 y,r,x,z,q,t,p 006 y,z,x,e,q,s,t,m 由此可以生成一棵FP树： 仔细来看这棵FP树，同搜索树不同，一个元素项可以在一棵FP树中出现多次。FP树会存储项集的出现频率，而每个项集会以路径的方式存储在树中。存在相似元素的集合会共享树的一部分。只有当集合之间完全不同时，树才会分叉。树节点上给出集合中单个元素及其在序列中的出现次数，路径会给出该序列的出现次数。相似项之间的链接，即节点链接（node link），用于快速发现相似项的位置。 上图中，元素项z出现了5次，集合{r, z}出现了1次。于是可以知道：z一定是自己本身或者和其他符号一起出现了4次。再看看其他可能，集合{t, s, y, x, z}出现了2次，集合{t, r, y, x, z}出现了1次。元素项z的右边是5，表示z出现了5次，其中刚才已经给出了4次出现，所以它一定单独出现过1次。005号记录是{y, r, x, z, q, t, p}，那么q、p去哪儿了呢？ 这里使用第11章给出的支持度定义，该指标对应一个最小阈值，低于最小阈值的元素项被认为是不频繁的。若将最小支持度设为3，然后应用频繁项分析算法，就会获得出现3次或3次以上的项集。图中FP树的最小支持度是3，因此p、q并没有出现在树中。 FP-growth算法的工作流程：首先构建FP树，然后利用它来挖掘频繁项集。为了构建FP树，需要对原始数据集扫描两遍。第一遍对所有元素项的出现次数进行计数。记住Apriori原理：如果某元素是不频繁的，那么包含该元素的超集也是不频繁的，所以就不需要考虑超集。数据库的第一遍扫描用来统计出现的频率，第二遍扫描中只考虑那些频繁元素。 构建FP树 首先先用一个容器来保存FP树。 创建FP树的数据结构 创造一个类保存树的每个节点，创建文件fpGrowth.py并加入以下代码： 123456789101112131415161718192021class treeNode : def __init__(self, nameValue, numOccur, parentNode) : # 节点名称 self.name = nameValue self.count = numOccur # 用于链接相似的元素项 self.nodeLink = None # 当前节点的父节点 self.parent = parentNode # 用于存放节点的子节点 self.children = {} # 对count变量增加给定值 def inc(self, numOccur) : self.count += numOccur # 将树以文本的形式显示 def disp(self, ind=1) : print(' '*ind, self.name, ' ', self.count) for child in self.children.values() : child.disp(ind+1) 上面的程序给出了FP树中节点的类定义。类中包含用于存放节点名字的变量和1个计数值，nodeLink变量用于链接相似的元素项（参考上图中的虚线）。类中还使用了父变量parent来指向当前节点的父节点。通常情况并不需要这个变量，因为通常是从上往下迭代访问节点的。如果需要根据给定叶子节点上溯整棵树，这时候就需要指向父节点的指针。最后，类中还包含一个空字典变量，用于存放节点的子节点。 运行一下如下代码： 1234567891011121314&gt;&gt;&gt; import fpGrowth&gt;&gt;&gt; rootNode = fpGrowth.treeNode('pyramid',9,None)# 已创建一个单节点，接下来增加一个子节点&gt;&gt;&gt; rootNode.children['eye'] = fpGrowth.treeNode('eye',13,None)# 显示子节点&gt;&gt;&gt; rootNode.disp() pyramid 9 eye 13# 再添加一个节点&gt;&gt;&gt; rootNode.children['phoenix']=fpGrowth.treeNode('phoenix',3,None)&gt;&gt;&gt; rootNode.disp() pyramid 9 eye 13 phoenix 3 构建FP树 除上图给出的FP树之外，还需要一个头指针表来指向给定类型的第一个实例。利用头指针表，可快速访问FP树中一个给定类型的所有元素。下图给出了一个头指针表的示意图。 这里使用一个字典作为数据结构来保存头指针表。除了存放指针外，头指针表还可以用来保存FP树中每类元素的总数。 第一次遍历数据集会获得每个元素项的出现频率。接着去掉不满足最小支持度的元素项，再来构建FP树。在构建时，读入每个项集并将其添加到一条已经存在的路径中。如果该路径不存在，则创建一条新路径。每个事务就是一个无序集合。假设有集合{z, x, y}和{y, z, r}，那么在FP树中，相同项会只表示一次。为了解决此问题，在将集合添加到树之前，需要对每个集合进行排序。排序基于元素项的绝对出现频率来进行。使用上图中头指针节点值，对前表中数据进行过滤、重排序后的数据显示如下。 事务ID 事务中的元素项 过滤及重排序后的事务 001 r, z, h, j, p z, r 002 z, y, x, w, v, u, t, s z, x, y, s, t 003 z z 004 r, x, n, o, s x, s, r 005 y, r, x, z, q, t, p z, x, y, r, t 006 y, z, x, e, q, s, t, m z, x, y, s, t 在对事务记录过滤和排序之后，就可以构建FP树了。从空集（符号为∅）开始，向其中不断添加频繁项集。过滤、排序后的事务依次添加到树中，如果树中已存在现有元素，则增加现有元素的值；如果现有元素不存在，则向树添加一个分枝。对上表前两条事务进行添加的过程显示如下。 接下来通过代码实现上述过程。在fpGrowth.py加入以下代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# FP树构建函数# 使用数据集以及最小支持度作为参数来构建FP树，树构建过程会遍历数据集两次def createTree(dataSet, minSup=1) : headerTable = {} # 第一次遍历扫描数据集并统计每个元素项出现的频度，这些信息被保存在头指针中 for trans in dataSet : for item in trans : headerTable[item] = headerTable.get(item, 0) + dataSet[trans] # 接着扫描头指针表删除那些出现次数小于minSup的项，由于字典不能在遍历中修改，转成集合 for k in list(headerTable.keys()): if headerTable[k] &lt; minSup : del(headerTable[k]) freqItemSet = set(headerTable.keys()) # 如果所有项都不频繁，无需下一步处理 if len(freqItemSet) == 0 : return None, None # 对头指针表稍加扩展以便可以保存计数值及指向每种类型第一个元素项的指针 for k in headerTable : headerTable[k] = [headerTable[k], None] # 创建只包含空集合的根节点 retTree = treeNode('Null Set', 1, None) for tranSet, count in dataSet.items() : localD = {} # 根据全局频率对每个事务中的元素进行排序 for item in tranSet : if item in freqItemSet : localD[item] = headerTable[item][0] if len(localD) &gt; 0 : orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p : p[1], reverse=True)] # 排序后，调用updateTree()方法 updateTree(orderedItems, retTree, headerTable, count) return retTree, headerTable# 为了让FP树生长，需调用updateTree函数。def updateTree(items, inTree, headerTable, count) : # 该函数首先测试事务中的第一个元素项是否作为子节点存在。 if items[0] in inTree.children : # 如果存在，则更新该元素项的计数 inTree.children[items[0]].inc(count) else : # 如果不存在，则创建一个新的treeNode并将其作为一个子节点添加到树中，这时，头指针表也要更新以指向新的节点。 inTree.children[items[0]] = treeNode(items[0], count, inTree) if headerTable[items[0]][1] == None : headerTable[items[0]][1] = inTree.children[items[0]] else : # 更新头指针表需要调用函数updateHeader updateHeader(headerTable[items[0]][1], inTree.children[items[0]]) # updateTree()完成的最后一件事是不断迭代调用自身，每次调用时会去掉列表中的第一个元素 if len(items) &gt; 1 : updateTree(items[1::], inTree.children[items[0]], headerTable, count)# 确保节点链接指向树中该元素项的每一个实例，从头指针的nodeLink开始，一直沿着nodeLink直到到达链表末尾。# 当处理树的时候，一种自然的反应就是迭代完整每一件事。当以相同方式处理链表时可能会遇到一些问题，# 原因是如果链表很长可能会遇到迭代调用的次数限制def updateHeader(nodeToTest, targetNode) : while (nodeToTest.nodeLink != None) : nodeToTest = nodeToTest.nodeLink nodeToTest.nodeLink = targetNode# 载入数据集def loadSimpDat() : simpDat = [ ['r', 'z', 'h', 'j', 'p' ], ['z', 'y', 'x', 'w', 'v', 'u', 't', 's' ], ['z' ], ['r', 'x', 'n', 'o', 's' ], ['y', 'r', 'x', 'z', 'q', 't', 'p' ], ['y', 'z', 'x', 'e', 'q', 's', 't', 'm' ] ] return simpDat# 从列表向字典的类型转换def createInitSet(dataSet) : retDict = {} for trans in dataSet : retDict[frozenset(trans)] = 1 return retDict 运行结果： 123456789101112131415161718192021222324&gt;&gt;&gt; import fpGrowth&gt;&gt;&gt; simpDat = fpGrowth.loadSimpDat()&gt;&gt;&gt; simpDat[['r', 'z', 'h', 'j', 'p'], ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'], ['z'], ['r', 'x', 'n', 'o', 's'], ['y', 'r', 'x', 'z', 'q', 't', 'p'], ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]&gt;&gt;&gt; initSet = fpGrowth.createInitSet(simpDat)&gt;&gt;&gt; initSet{frozenset({'j', 'z', 'h', 'p', 'r'}): 1, frozenset({'u', 's', 'x', 'w', 'y', 'v', 'z', 't'}): 1, frozenset({'z'}): 1, frozenset({'s', 'x', 'o', 'n', 'r'}): 1, frozenset({'q', 'x', 'y', 'z', 't', 'p', 'r'}): 1, frozenset({'s', 'e', 'q', 'x', 'y', 'z', 'm', 't'}): 1}&gt;&gt;&gt; myFPtree, myHeaderTab = fpGrowth.createTree(initSet, 3)&gt;&gt;&gt; myFPtree.disp() Null Set 1 z 5 r 1 x 3 s 2 y 2 t 2 y 1 t 1 r 1 x 1 s 1 r 1 上面给出的是元素项及其对应的频率计数值，其中每个缩进表示所处的树的深度。 从一棵FP树中挖掘频繁项集 有了FP树之后，就可以抽取频繁项集了。这里的思路与Apriori算法大致类似，首先从单元素项集合开始，然后在此基础上逐步构建更大的集合。当然这里将利用FP树来做实现上述过程，不再需要原始数据集了。从FP树中抽取频繁项集的三个基本步骤如下： 从FP树中获得条件模式基； 利用条件模式基，构建一个条件FP树； 迭代重复步骤1、2，直到树包含一个元素项为止。 重点关注第1步，即寻找条件模式基的过程。之后，为每一条件模式基创建对应的条件FP树。最后需构造少许代码来封装上述两个函数，并从FP树中获得频繁项集。 抽取条件模式基 首先从之前保存在头指针中的单个频繁元素项开始。对于每一个元素项，获得其对应的条件模式(conditional pattern base)。条件模式基是以所查找元素项为结尾的路径集合。每一条路径其实都是一条前缀路径(prefix path)。简而言之，一条前缀路径是介于所查找元素项与树根节点之间的所有内容。 回到图2中，符号r的前缀路径是{x, s}、{z, x, y}和{z}。每条前缀路径都与一个计数值关联。该计数值等于起始元素项的计数值，该计数值给了每条路径上r的数目。下表列出了上例当中每一个频繁项的所有前缀路径： 频繁项 前缀路径 z {}5 r {x, s}1, {z, x, y}1, {z}1 x {z}3, {}1 y {z, x}3 s {z, x, y}2, {x}1 t {z, x, y, s}2, {z, x, y, r}1 前缀路径被用于构建条件FP树，但是暂时先不需要考虑这件事。为了获得这些前缀路径，可以对树进行穷举式搜索，直到获得想要的频繁项为止，或使用一个更有效的方法来加速搜索过程。可以利用先前创建的头指针来得到一种更有效的方法。头指针表包含相同类型元素链表的起始指针。一旦到达了每一个元素项，就可以上溯这棵树直到根节点为止。下面代码给出了如何发现前缀路径，将其添加到文件fpGrowth.py中。 1234567891011121314151617def ascendTree(leafNode, prefixPath) : # 迭代上溯整棵树 if leafNode.parent != None : prefixPath.append(leafNode.name) ascendTree(leafNode.parent, prefixPath)# 遍历链表直到到达结尾。每遇到一个元素项都会调用ascendTree()来上溯FP树，并收集所有遇到的元素项的名称。# 该列表返回之后添加到条件模式基字典condPats中def findPrefixPath(basePat, treeNode) : condPats = {} while treeNode != None : prefixPath = [] ascendTree(treeNode, prefixPath) if len(prefixPath) &gt; 1 : condPats[frozenset(prefixPath[1:])] = treeNode.count treeNode = treeNode.nodeLink return condPats 运行结果 123456&gt;&gt;&gt; fpGrowth.findPrefixPath('x', myHeaderTab['x'][1]){frozenset({'z'}): 3}&gt;&gt;&gt; fpGrowth.findPrefixPath('z', myHeaderTab['z'][1]){}&gt;&gt;&gt; fpGrowth.findPrefixPath('r', myHeaderTab['r'][1]){frozenset({'z'}): 1, frozenset({'s', 'x'}): 1, frozenset({'z', 't', 'y', 'x'}): 1} 创建条件FP树 对于每个频繁项，都要创建一棵条件FP树。我们会为z、x以及其他频繁项构建条件树。可以使用刚才发现的条件模式基作为输入数据，并通过相同的建树代码来构建这些树。然后，我们会递归地发现频繁项、发现条件模式基，以及发现另外的条件树。举个例子，假定为频繁项 t 创建一个条件FP树，然后对{t, y}、{t, x}、……重复该过程。元素项t的条件FP树的构建过程如下所示。 上图中最初树以空集作为根节点，接着，原始的集合{y, x, s, z}中的集合{y, x, z}被添加进来。因为不满足最小支持度要求，字符s并没有加入进来。类似地，{y, x, z}也从原始集合{y, x, r, z}中添加进来。 元素项s、r是条件模式基的一部分，但它们并不属于条件FP树。单独来看它们都是频繁项，但是在t的条件树中，它们却不是频繁的，也就是说{t, r}、{t, s}是不频繁的。 接下来，对集合{t, z}、{t, x}、{t, y}来挖掘对应的条件树。这会产生更复杂的频繁项集。该过程重复进行，直到条件树中没有元素为止，然后就可以停止了。实现代码很直观，使用一些递归加上之前写的代码即可。具体如下： 12345678910111213141516171819def mineTree(inTree, headerTable, minSup, preFix, freqItemList) : # 对头指针表中元素项按照其出现频率进行排序，默认是从小到大 bigL = [v[0] for v in sorted(headerTable.items(), key=lambda p:p[1][0])] # 默认是从小到大，下面过程是从头指针的底端开始 for basePat in bigL : newFreqSet = preFix.copy() newFreqSet.add(basePat) # 将每个频繁项添加到频繁项集列表freqItemList中 freqItemList.append(newFreqSet) # 使用findPrefixPath()创建条件基 condPattBases = findPrefixPath(basePat, headerTable[basePat][1]) # 将条件基condPattBases作为新数据集传递给createTree()函数 # 这里为函数createTree()添加足够的灵活性，确保它可以被重用于构建条件树 myCondTree, myHead = createTree(condPattBases, minSup) # 如果树中有元素项的话，递归调用mineTree()函数 if myHead != None : print('conditional tree for: ', newFreqSet) myCondTree.disp() mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList) 效果如下： 123456789101112131415161718192021222324252627282930313233&gt;&gt;&gt; freqItems = []&gt;&gt;&gt; fpGrowth.mineTree(myFPtree, myHeaderTab, 3, set([]), freqItems)conditional tree for: {'s'} Null Set 1 x 3conditional tree for: {'y'} Null Set 1 z 3 x 3conditional tree for: {'y', 'x'} Null Set 1 z 3conditional tree for: {'t'} Null Set 1 z 3 y 3 x 3conditional tree for: {'t', 'y'} Null Set 1 z 3conditional tree for: {'t', 'x'} Null Set 1 y 3 z 3conditional tree for: {'z', 't', 'x'} Null Set 1 y 3conditional tree for: {'x'} Null Set 1 z 3# 检查返回的项集是否与条件树匹配&gt;&gt;&gt; freqItems[{'r'}, {'s'}, {'s', 'x'}, {'y'}, {'y', 'z'}, {'y', 'x'}, {'z', 'y', 'x'}, {'t'}, {'t', 'z'}, {'t', 'y'}, {'t', 'y', 'z'}, {'t', 'x'}, {'t', 'y', 'x'}, {'z', 't', 'x'}, {'z', 't', 'y', 'x'}, {'x'}, {'z', 'x'}, {'z'}] 示例：从新闻网站点击流中挖掘 下列文件kosarak.dat中包含了将近100万条记录。该文件中的每一行包含某个用户浏览过的新闻报道。一些用户只看过一篇报道，而有些用户看过2498篇报道。用户和报道被编码成整数，所以查看频繁项集很难得到更多的东西，但该数据对于展示FP-growth算法的速度十分有效。 数据前几行如下： 12345678910111213141 2 314 5 6 71 89 1011 6 12 13 14 15 161 3 717 1811 6 19 20 21 22 23 241 25 326 311 27 6 3 28 7 29 30 31 32 33 34 35 36 376 2 3839 11 27 1 40 6 41 42 43 44 45 46 47 3 48 7 49 50 51 运用FP-growth算法： 123456789101112131415161718192021222324252627# 导入数据&gt;&gt;&gt; parsedDat = [line.split() for line in open('kosarak.dat').readlines()]# 初始化数据&gt;&gt;&gt; initSet = fpGrowth.createInitSet(parsedDat)# 构建FP树，寻找至少被10万人浏览过的新闻报道&gt;&gt;&gt; myFPtree, myHeaderTab = fpGrowth.createTree(initSet, 100000)# 创建空列表保存频繁项集&gt;&gt;&gt; myFreqList = []&gt;&gt;&gt; fpGrowth.mineTree(myFPtree, myHeaderTab, 100000, set([]), myFreqList)conditional tree for: {'1'} Null Set 1 6 107404conditional tree for: {'3'} Null Set 1 6 186289 11 117401 11 9718conditional tree for: {'11', '3'} Null Set 1 6 117401conditional tree for: {'11'} Null Set 1 6 261773&gt;&gt;&gt; len(myFreqList)9&gt;&gt;&gt; myFreqList[{'1'}, {'1', '6'}, {'3'}, {'11', '3'}, {'11', '6', '3'}, {'6', '3'}, {'11'}, {'11', '6'}, {'6'}] 小结 FP-growth算法是一种用于发现数据集中频繁模式的有效方法。FP-growth算法利用Apriori原则，执行更快。Apriori算法产生候选项集，然后扫描数据集来检查它们是否频繁。由于只对数据集扫描两次，因此FP-growth算法执行更快。在FP-growth算法中，数据集存储在FP树中。FP树构建完成后，可以通过查找元素项的条件基及构建条件FP树来发现频繁项集。该过程不断以更多元素作为条件重复进行，直到FP树只包含一个元素为止。 可以使用FP-growth算法在多种文本文档中查找频繁单词。对Twitter源上的某个话题应用FP-growth算法，可以得到一些有关该话题的摘要信息。频繁项集生成还可以用于购物交易、医学诊断和大气研究等。","link":"/2018/02/06/FP-growth算法/"},{"title":"五月英语单词","text":"开辟一个新栏目，记录一些学英语过程中认识的单词。这个标题就泛着一股咕咕的气息~ May 13Deputise[‘depjutaɪz]指担任代表，充当代理人。 Mr Raab, who is deputising for the prime minister while he recovers from his Covid-19 illness, said allowing a second peak of infections would be “the worst outcome not just for public health but for the economy”, adding: “Let’s not give coronavirus a second chance.” 其他Goodwill：善意；在商业话语体系下，也可以是一个专有名词，即商誉。 Neutrality：中立，比如政治方面的中立就可以说political neutrality。 undaunted：就是无所畏惧、不屈不挠的意思。女王的父亲乔治六世在1939年的演讲中这样说：If it brings us continuing struggle, we shall remain undaunted. tribalism：部落主义，就是名词部落tribe，的形容词tribal，加后缀ism，表示某某主义，是一个社会学概念，可以讨论到现代文明的社会结构走向崩溃这样更高的层面，但通常我们只是用它来表达对社会分裂的不满，是个贬义词，表示人们分成了对不同社群的高度忠诚，从而导致了他们之间的对抗情绪。 propensity for good：“善”的天性，A propensity to do something或者a propensity for something，举个例子可以说Mr. Robinson has a propensity to put off decisions to the last minute.罗宾森先生习惯拖到最后一分钟再做决定。 The Commonwealth：英联邦。 May 14Bailout[‘beɪlaʊt]意为紧急财政援助，也就是给面临财政问题的公司或外国政府提供资金救助。Bailout也可以做形容词，意为用于应对紧急状况的。 The loan portions of the bailout have to be repaid within 10 years and the Treasury will also receive warrants to buy shares in return for the funds, giving the US taxpayer exposure to any share price recovery across the industry. 其他tabloid：是小报的意思，它的报道通常不太严谨，追求眼球效应和花边新闻，有时可能比较没节操。比如在英国，太阳报（the Sun）或每日镜报（Daily Mirror）都属于小报。它的反义词就是broadsheet，指内容更为严肃且更有公信力的大报，比如泰晤士报（The Times）和我们金融时报（Financial Times）、还有卫报（the Guardian）等，美国的有比如纽约时报（The New York Times)、华盛顿邮报(Washington Post)等。所以，小报不一定是那些只报道八卦娱乐新闻的刊物，比如中国的《环球时报》也经常被西方主流媒体称作Tabloid。 blackmail：敲诈勒索，由黑色与邮件两个词组合而成，它可以做名词也可以作为动词使用；但是这个意思的动词，有另外一个是大家经常使用的，extort，勒索，它的意思是强权、威胁或者其他不公平的手段获取某物，也有榨取的意思。可以记下这个词组extort something from somebody，从某人身上勒索或者榨取得到某物。 crosshairs：也很形象，两根毛发一横一竖组成了一个十字形状，你一定在望远镜瞄准器或者手机镜头上能找到这个标记，十字的交叉点就是靶子对准的对象，所以经常用介词in the crossharis，或者into someone’s crosshairs来形容某人成了靶心瞄准的猎物。 taken down：就是拿下的意思，这个词组有三重意思，包括从高处取下来take down that painting，拆除障碍，take down the barricade，或者用笔记下来，take the pretty girl’s number down（记下那个漂亮姑娘的电话号码）。 complexifier：我们都知道形容词complex是复杂的意思，后面加-fy就能变成动词，再加-ier就能变成名词，意思是让事情变复杂的东西。比如我一直在考虑午餐点外卖吃什么，但外卖突然都停了，只能去外面店里吃，那又得重新考虑一遍吃哪家，这就是一个complexifier吧。 salacious gossip：荤段子，桃色绯闻。如果作者用salacious来形容一本书或者一个笑话，就说明他认为内容里面牵扯了很多没必要的桃色细节描写。名词是Salaciousness。 taking feuds online：就是feud即积怨或者世仇，比如a family feud，也可以作动词。 on food stamps：亚马逊因为低薪酬问题被指责为剥削劳动力，近期引发了很多抗议。媒体用这个词组来形容亚马逊对员工有多吝啬，因为在美国，政府会给低收入者发放一些可以定向兑换食物的票券，称为food stamp，有点类似中国在计划经济时期推出的粮票，但性质完全不一样。 extol：动词，赞颂的意思，变形有名词extoller, extolment. 有个形容词也表示赞美本身这个行为，即laudatory，比如David Pecker的小报就曾经给特朗普写了很多laudatory stories。这不用多说，我们中国人都懂。 no small feat：用来形容某事是了不起的行为，你说到的某个人取得的成绩很伟大，一点儿也不渺小。比如，我觉得我儿子1岁时学会站立，一定是no small feat。Feat有两层意思，指功绩或者某种技艺。 AMI is walking at the precipice：美国媒体公司正在走向绝壁。是的，那就是悬崖峭壁。 sleazy：贝索斯说那家小报用隐私照片敲诈勒索，这种行为就是这个词的意思——卑鄙龌龊。不过，这不一定构成犯罪。 vying with someone：微软和甲骨文公司都在和亚马逊竞争美国国防部的一个100亿美元的大单。它的原形动词vie，就是争夺的意思，比如vie with other kids for attention。 May 15Anachronistic[əˌnækrə’nɪstɪk]形容词，意为不合时宜的、过时的、落伍的。 A more fundamental consequence would be a rethinking of that anachronistic dichotomy to include approaches drawing on values beyond compliance with government and individual gain. 其他rambling announcement：就是《漫步华尔街》的那个ramble，但这里指没完没了、东拉西扯的演讲，同学们可以用来形容校长或者领导讲话：） incoherent:语无伦次，形容言语上的不连贯，混乱。如果一个人incoherent，那他的讲话⼀定让人感到很困惑并且不清晰。 undercut：低于正常价格售出，可以引申为削弱。 in a nutshell：简言之 smoke and mirrors：烟雾弹，irrelevant or misleading information serving to obscure the truth of a situation 混淆视听。 impasse：僵局，等同于gridlock call the muster：点名 combative:好斗的，好争斗的。如果说⼀个⼈是combative，就说明他好斗，有点类似aggressive，并且很有欲望去战斗或者争辩。 embolden a future：⿎舞未来，embolden v.使有胆量;使有信心;鼓励。 May 16Apocalyptic[ə.pɒkə’lɪptɪk]意为像世界末日的，用来描述历史大动乱，或预示未来大灾变，名词形式为apocalypse。 The market sell-off would spread to other eurozone members. This is the apocalyptic scenario Mr Macron fears. May 17Scapegoat[ˈskeɪpˌɡəʊt]指代人受过者，也就是我们常说的“替罪羊”。也可以做动词，意为使某人成为替罪羊。 The facts of the crisis may finally overcome sentiment but, if scapegoats are needed, he is unlikely to be among them. 其他Nominee: 被提名者。A nominee is someone who is nominated for a job, position, or award. 关于honor 获奖的一些用法： 授予荣誉：confer honor; bestow honor; award (sb) honor; 接受荣誉: accept honor, pick up honor, receive honor, scoop honor, take honor, win honor; 获得荣誉：grab the honor To give the old story some new oomph: 这是形容LadyGaga给那部电影带来了某种新的魅力，oomph经常形容与性感有关的魅力。 accolade: 就是荣誉、赞誉和奖项，所以不只有prize或者award能表达这个意思，还有一个英式表达win a top gong，可以翻译成拔得头筹。 plaster: 是醒目地刊登和张贴的意思。 drum up: 这个词组就有三重含义，可以说drum up support争取支持，也可以说drum up excitement激起兴趣，还可以说drum up customers招揽顾客。 scoop: 它原本的意思是用来盛饭的那种比较深的勺子或者铲子，也可以作动词，但这里用的意思就是win，指赢得奖项；在新闻行业，它还有独家新闻的意思，scoop-getter就是那些能挖来独家新闻的记者。 homophobic: 恐同，phobic组在一个词里面，就表示害怕的意思，比如claustrophobic幽闭恐惧症，arachnophobic蜘蛛恐惧症等。 a star-studded ceremony: 星光闪耀的典礼。stud本身就是一种用来装饰的钉子，比如a silver stud in his ear，他那银色的耳钉；而studded可以用作形容词，表示装饰布满了某物，比如the clear sky is studded with stars。 May 18Silver lining[ˌsɪl.və ˈlaɪ.nɪŋ]字面意思是“银边”。英语里有一句谚语是”Every cloud has a silver lining”，意思是由于云朵背后会透出些许光线，所以每朵乌云的边缘都有一条银边。这句话用来比喻任何坏事背后，都有美好的一面，消极事件可能也有积极的一面。所以，silver lining多用于指失望或不幸中的一线希望、一线慰藉。 If we are to glimpse any silver lining in the current collapse in output, this human capital windfall is one. 其他echo：与……相似 erroneous：错误的 cushion：缓冲物 come to a standstill：停下来 in extremis：紧要关头；临终之时 rarity：罕见 in light of：鉴于，考虑到。eg. 中国停飞Max，出于安全考虑 malfunction：故障 flaw, faulty, deficiency：缺陷，缺陷，缺陷。eg. If that sensor is faulty and the information is therefore flawed. too sketchy to draw a conclusion：过于粗略而无法得出结论 eerily similar：诡异地相似。 get into stall：就是失速、失控，用在引擎上就是熄火，用在汽车上就是指抛锚。 linchpin和pillar都是说“中流砥柱”更常用的表达；但不少中国学者写论文或者翻译论文时，特别喜欢用stanchion这个词，意思是立起来的柱子，偶尔也有支点的意思，但要表达某件事的顶梁柱或者关键这个意思时，stanchion就属于很少用的那种了。 May 19Telemedicine[‘telɪˌmedɪsɪn]远程医疗，也就是医生借助视频、电话、邮件等电子通讯工具，来为患者提供远程医疗服务，这种方式多用于术后随访、后续配药和慢性病管理等等。 Telemedicine works “for most medication refills . . . urinary tract infections, colds and rashes, diabetes and hypertension follow-ups, lab results, post-op visits, birth control and fertility, and mental health,” says the website Medicaleconomics.com. May 20Forgive[fər’ɡɪv]动词，多用于指原谅、宽恕，或请求别人的原谅，还有一个意思是免除债务。 Chinese policy advisers and bankers told the Financial Times that Beijing was considering a number of responses, including the suspension of interest payments on loans from the country’s financial institutions. But they also warned against expectations that China would forgive debts outright. 其他conspire：密谋串通 collusion：也是勾结的意思，in collusion with sb hem and haw：支支吾吾，吞吞吐吐，边说边在想用什么词 ad infinitum：一遍遍永无止境地重复 push the envelope：以前所未有的方式挑战极限 summation：总结陈词（法律上的） vindicate：证明清白，或（在被指责错误后）正名 partisan：党羽（名词），或者党羽那种盲目拥护和追随的行为（形容词）。 wooden：变木头？其实就是说比较笨拙，约等于clumsy。 hemorrhage：内出血 kumbaya moment：指一种认为一切“都挺好”的天真的乌托邦感觉，通常说这话的人有点讽刺的意思 wage a feud over sth：就是因某事结怨 tooth and nail：用牙咬，用指甲挠，看上去要拼尽全力打架，对了，这就是tooth and nail的意思，动用自己全部的资源和力量，get better of you，打败你 chafe at something：是对某事恼怒；女生穿新鞋把脚给磨破皮了，这个磨也是chafe的常用含义 obstruct：本意是挡路，比如妨碍交通就是obstruct traffic May 21Furlough[ˈfɜːləʊ] 名词，指休假，尤指公职人员的无薪休假，或因发不出工资而给的准假。 The Treasury has indicated that universities should first avail themselves of the government furlough and continuity loan schemes before seeking any further bailout, in keeping with the message communicated to airlines this month. 其他 单词 释义 pathogen 病原 stress test 压力测试 exogenous 外生的 churn out 搅动，产出 gauge 量规 pandemic 大流行 plateau 高原 negligence 疏忽 tally 相符 abhor 痛恨 philanthropist 慈善家 unrivalled 无与伦比 flunk 不及格 sinuous 弯曲的 galvanise 镀锌，刺激 scapegoats 替罪羊 May 22Mercenary[ˈmɜːsənəri] 形容词，指唯利是图的，也可以做名词，用来指雇佣兵，也就是那些以金钱为目的去参战的武装人士。 The detentions come a day after the government said security forces killed eight “terrorist mercenaries” and arrested two more as they tried to steal ashore before dawn. 其他clocking in：打卡，考勤 go viral：突然火爆、流行 stern：严厉的、严苛的 perk：补贴 advocate: 倡议者 stricture：限制 nudge：轻推，好言说服 stipulate：规定 take heed：注意 tread a fine/delicate/narrow line/path：小心翼翼地在两种对立势力之间寻求平衡，避免犯错 usher in：引入 May 23Flop[flɑːp]作名词时，意为（电影、戏剧、聚会等）彻底失败、不成功。作动词时，flop指（表演者、演出）彻底失败，或者意为沉重下坠、笨拙移动或疲劳时猛然坐下。 A potential antiviral drug for the coronavirus has flopped in its first randomised clinical trial, disappointing scientists and investors who had high hopes for remdesivir, according to draft documents published accidentally by the World Health Organization and seen by the Financial Times. 其他predicament：困境 water-cooler：办公室里的谈资 put your feet up: 劳累工作后休息一下 a protracted battle：一场旷日持久的战争 to be out of kilter with something: 与某事物不一致； out of kilter / off kilter：有点紊乱，状态不好，不正确，比如用于形容某个人的body clock时。 analogy:我们在讨论一部文艺作品时，总是会不断地采用“类比”手法 zeitgeist :时代精神或者思潮，来自于德语，例如the Google Zeitgeist May 24Ferocity[fəˈrɒsəti]名词，指“残暴、凶猛、凶恶”，也可以指某事物的“猛烈”程度。 Mohamed El-Erian, chief economic adviser at Allianz, said Thursday’s data highlighted “the ferocity of the sudden stop hitting the US economy”. May 25Placebo[pləˈsiːbəʊ]名词，指安慰剂，也就是没有药物治疗作用的片、丸或针剂。安慰剂会使病人虽然获得了无效的治疗，但由于他们预料或相信治疗是有效的，这种心理作用最终可能使他们的症状得到舒缓。在进行药物试验时，使用安慰剂可以排除心理效应对药物客观效果的影响。 The NIAID trial, which has yet to be peer reviewed, showed a 31 per cent improvement in patients taking the drug compared with a placebo, Dr Fauci said, with victims recovering in 11 days on average rather than 15 days for the control group. 其他amassed a wealth of data ： 积累大量数据 reprimand：谴责 eg. He has been fined five thousand dollars and given a severe reprimand.他被罚款5000美元，并且受到严厉的训斥 mesmerizing： 有吸引力的 prank： 恶作剧，戏谑 debauchery：骄奢淫逸 falling foul of： 违规 rigorously：严厉地；残酷地 dislodge: 取代；eg. Xiaomi has dislodged Samsung with the top selling smartphone in India.小米取代三星成为印度最畅销的智能手机 dotcom bubble：互联网泡沫，特指起于90年代初、2000年时在美国破灭的那个泡泡 beef up：加强（增援，充实）；补充（人数， 兵力）等 algorithmic：算法的 time-mongers： 时间贩子 M&amp;A(Mergers and Acquisitions)： 并购，英文是acquire；合并，英文是merge; 所以你经常可以看到这个缩写——并购 May 26Emancipation[ɪˌmænsɪˈpeɪʃn]意思为解放、释放、解脱。 “Anything that can take us away from a preoccupation with our pathetic selves is an emancipation,” says Chris Oakley, a London psychoanalyst who wrote Football Delirium. 其他transgression 越界，违反规则 exogamy 异族通婚 sexual conduct 性行为 misperception 误解，错觉 at a very basic level 通常情况下 prejudice against sth. 对某事的偏见 criminal action 刑事诉讼 civil action 民事诉讼 burden of proof 举证责任 preponderance of evidence 证据优势 rape/sexual assault 前者本身就有强奸的意思，但所有当事人不想要的性接触都可以叫做sexual assault，比如说被迫的亲吻。 reckoning 清算，反省 allegation 指控 consent/assent 都是“同意”的意思，好像没什么区别。可实际上，这两个词还是有相当大差别的。Consent means “freely given, knowledgeable and informed agreement.” 可以理解为准许，并且是在有知情权的情形下，自由选择的行为。然而，Assent means “agreement on the face of it.”只是表面同意的意思。比如你被骗了，那就只能说你assent坏人的要求，但绝对不是consent，因为如果你知道自己上当，或许也就不会同意了。 elevate 提升…的职位 May 27Sublimation[sʌblɪˈmeɪʃn]名词，既可以表示物理学上的升华，也可以指心理学中的升华，高尚化。 Eventually, in the interest of furthering my own dubious project of sublimation, I decided to stand up from my laptop and go out into the world in search of manifestations of those apocalyptic anxieties. 其他Public persona：公众形象 Stay at the helm：掌舵 Wholesome：健康、有益 Aw-shucks：质朴 Sensible：结实耐用的 Quip：妙语 Trounce：彻底打败 Perennial：长期的，反复出现的 Lore：全部知识，传说 Unperturbed：泰然自若，镇定 Congregation：集会 Pan out：结果，或结果令人满意 Peddle：兜售，散播 Spin-off：意外收获 Interlocutor：对话者 Touch wood (British) / knock on wood (American)：但愿走好运 May 28Egalitarianism[ɪˌɡælɪ’teərɪənɪzəm]名词，指平等主义或平均主义。 Whether it was Hollywood star Tom Hanks or Britain’s Prince Charles, the initial impression was of the pathogen’s blind egalitarianism. 其他endowment：资助 alma mater：母校 alumni：校友，alumnus的复数 scandal：丑闻 deeply ingrained：根深蒂固 a parental link：家长人脉 influence-peddling：权势贩卖 a cultural gulf：文化鸿沟 garner：获得 penalize：对……不公平 social mobility：社会流动 the moral high grounds：道德高地 shun：避开，回避 wince：龇牙咧嘴 prospects：前途 in a quandary：陷入困窘，左右为难 tap alums for cash：如果你tap某种资源或者处境的话，就意味着你想要通过运用这些资源，获取自己所需。举个例子：He owes his election to having tapped deep public disillusion with professional politicians. 他将自己赢得选举这个结果，归功于利用了民众内心深处对职业政客不再抱有幻想的情况。 vehement：等于forceful，猛力的、强烈的，such as a vehement wind一阵强风吹过；不过，vehement所表达的这种强烈，主要与情感相关，可以指代一个人情绪很激烈、很激动的意思。比如，强烈的爱国主义感vehement patriotism；强烈怀疑，a vehement suspicion。 May 29Carpe diem[ˌkɑː.peɪˈdiː.em]拉丁短语，意为“seize the day”，指只争朝夕、抓住机遇，也指把握当下、及时行乐。 Starting from here, the managers might even be happy to have had LVMH in their portfolio: spending on luxury goods is already recovering nicely in China and they expect an element of carpe diem spending as the rest of the world reopens.","link":"/2020/05/13/每日英语单词/"},{"title":"推理小说记录","text":"谨以此文记录看过的推理小说。 前言 还记得我小学前几年，为了上学方便寄住在舅妈家，由于我又没有午睡的习惯，中午的时间一般都是看电视或者看书。舅妈家有全套的《福尔摩斯探案集》，某天我打开了《血字的研究》，自此推开了推理小说的大门。 以下将我读过的尚有印象的推理小说列出，权当记录与吐槽了。 正文日本东野圭吾 名气实在太大了，感觉没有必要靠俺推荐，太知名作品就不写了，写点小众一点的。 《假面山庄》 这部小说最大的问题就是看起来是暴风雪山庄，结果最后的结果又全推翻了，看起来想打人。 《名侦探的守则》 本格推理讲义，把常见推理小说核心全用戏说手法表现出来了，读起来让人会心一笑。 岛田庄司 作为新本格的代表人物，岛田庄司的作品很多，有名的有：《占星术杀人魔法》、《斜屋犯罪》、《奇想天动》、《异邦骑士》、《北方夕鹤2/3杀人事件》、《螺丝人》，惭愧的是大部分我都看不下去，所以就提2部。 《占星术杀人魔法》 很遗憾，读到这篇小说的时候，我已经看过金田一和少年包青天的类似案件了，知道了核心诡计，小说的魅力大减，不过作为首个用出该核心诡计的小说，被抄袭不是它的错，只能说这个诡计设计太精妙了。 《斜屋犯罪》 很有意思的密室杀人，宏大的场面，就诡计而言确实瞒过我了，而且那个建筑物有点复杂，看的时候来来回回研究了半天。当然动机觉得有点弱，总的来说值得一读。 绫辻行人 绫辻行人的主要作品就是馆系列，值得一提的是其中的一位侦探主角的名字岛田洁就是来源于岛田庄司和他笔下的侦探御手洗洁。馆系列的作品质量良莠不齐，也就如下几部值得一看。 《钟表馆事件》 公认的馆系列最高作，双线叙事，暴风雪山庄模式+ 时间诡计，加上作者的叙述性诡计，整体看下来是相当精彩的，不过得对照地图来看。 《十角馆事件》 感觉是日本版的《无人生还》，当然没有童谣杀人的设定，由于是伪暴风雪山庄，主要是看凶手制造不在场证明的手法，配合作者的诡叙，还是值得一看的，动机设定就emmm了。 《迷宫馆事件》 这个系列看下来，就是觉得作者为了一个故事就设定一个建筑确实很敬业。就这本书而已，还是惯用的诡叙，事件本身很吸引人，但解答看起来有种被愚弄的感觉。 《咚咚吊桥坠落》 文笔是真的不太行。但是作为看多了本格推理之余的小菜还是值得一提的，把叙述性诡计玩花了。另外在取名上把知名推理作家都唰了一通，特别是我孙子武丸，每条狗都要取这名hhh。 森博嗣 森博嗣是因为之前看过小说同名电视剧《全部成为F》，毕竟单元推理剧并不是很多，看完后对他的小说有点兴趣，又翻出来看。不过他的小说还是很有特点的，有种特有的理工科的浪漫。 《全部成为F》 应该是在大陆名气最高的作品了，不过也有可能是其他作品不在大陆出版的缘故。当然小说内容本身就在电视剧里被改编过了，得知了谜底的情况下，也就只剩下对比细节了。 《不会笑的数学家》 看过的感觉就是《三星馆事件》？和斜屋犯罪或者馆系列一样的建筑推理，核心诡计有点意思，当然这类推理都这样，反正森博嗣的S&amp;M系列看的是教授和学生的恋爱日常23333。 《死亡幻术的门徒》 听说这部在日本评价很高，看完后感觉一般，总共有3起案件，谜设看起来挺华丽的，不过解谜感觉都挺一般的，反正我觉得有点扯淡，感觉这种诡计侮辱我智商。 三津田信三 风格有点特色，民俗/恐怖与推理结合，暂时觉得还不错。 《首无·作祟之物》 怪异君评价为“本格神作”，不过我拖了很久才开始读。读过觉得还是挺惊喜的， 叙事结构很精巧，采用了书中书的模式。把一个简单的无头尸诡计写到了极致，最后的三重反转十分精彩。当然其中首无的制造有点扯淡，算是瑕不掩瑜吧。 《山魔·嗤笑之物》 这部的硬伤较多，看点是童谣/比拟杀人，之前一家人消失给人的错愕，最后的解答虽然是我没想到的，但是是很低级的解答，并没有对应的上之前的期待感。最后的几次逆转也没有前作的震撼感，总的来说，尚可一读，但是略显鸡肋。我应该会暂时不会涉及他其他作品了。 今村昌弘 他的《尸人庄谜案》之前就久闻大名，等了很久才有中文版上市，只想说：“磨铁出来挨打。” 《尸人庄谜案》 期待了2年的作品，读完觉得有点捧过头了，但是还是挺有意思的。在现代信息发达的社会很难设计出一个合理的暴风雪山庄，这本书的给了一个合乎逻辑的设定。案件设计上还是合乎情理，算得上自圆其说，但是有隐瞒线索的嫌疑。不过读完只能感叹现在推理界不景气啊，这本书并不差，但是对不起它独霸三榜的地位。 《魔眼之匣谜案》 个人觉得不如《尸人庄》，也不是那种很本格的推理，密室与杀人亮点不够，但是整体的结构挺精巧，最后的反转还是有点冲击力的。 西泽保彦 最出名的大概是《解体诸因》了，剩下几本还没读，读了再更新吧。 《解体诸因》 短篇合集，作者一本正经的对分尸的理由做了一系列解答，读起来还是挺有意思的。主要是都是中短篇，看起来也不累。 《死了七次的男人》 作为SF推理，创意上有点意思，可惜没什么推理，剧情槽点满满。 青崎有吾 话说作者也就比俺大两岁，21岁就凭《体育馆之谜》拿奖出道，俺深感惭愧啊。 《体育馆之谜》 这部的诡计被《唐人街探案》抄袭了，虽然挺本格，但是我不太喜欢宅男侦探的人设，和作者偏轻小说的文风。所以也仅仅看了这部。 《敲响密室之门》 哎呀被打脸了，最近补了这本，果然推理还是看中短篇比较轻松。 《水族馆之谜》 逻辑流，真的废话好多，不知道怎么被我看完的。 东川笃哉 看了以他原著改编的电视剧《推理要在晚餐后》才关注的，总觉得文风太轻小说化了，甚至到了感觉有点尬的地步。 《请勿在此丢弃尸体》 实在是太轻小说了，各种角色跟白痴一样，谜设一般般，觉得应该适合于中学生来看，如果能get到他设的各种笑点，阅读体验大概还行吧。 《密室的钥匙借给你》 严格意义上讲，比上面那本读起来更舒服一点，不过动机和手法就不咋地了，而且突然就哲学了起来emmmm。 《推理要在晚餐后》 跳过了被改编成剧的部分，严格意义上讲确实质量不高，不过阅读体验还可以，比起有些作家的晦涩的文字，至少他的文字还算可读。 石持浅海 作者好像喜欢用倒叙推理，《紧闭的门扉》便是如此，我也只看了这本。 《紧闭的门扉》 大概是喜欢《古畑任三郎》，所以对倒叙推理还是挺有兴趣的，这种类型的推理不怕泄底，更看重侦探和凶手的对决，唯一的问题在于，凶手好像有点弱，侦探的屁股也很歪。 早坂吝 传说中的工口推理作家，估计也不太可能在国内出版，不过《彩虹牙刷》有民翻。 《彩虹牙刷》 工口推理赛高，看起来好像是小黄文，不过里面的推理还是挺正经的。结局的脑洞大开，值得一看。 深水黎一郎 只看过《推理竞技场》，个人感觉作者的文风不错。 《推理竞技场》 很娱乐的推理小说，作者一直在戏谑诡叙和多重解答，有种批评文学的感觉。就推理性而言不值一提，当故事来看尚可一读。 泡坂妻夫 这个作者的小说布局很有意思，属于那种炫学流，把其他领域的知识引入到推理小说，又不觉得卖弄，确实有真才实学的那种。 《十一张牌》 作者之前好像是魔术师，所以这本小说对魔术如数家珍，堪称魔术泄底大全。读起来也挺有意思的。 《失控的玩具》 依旧是炫学作品，本小说对机关玩偶如数家珍，读来感觉不明觉厉。推理的话，大概到一半就猜到了， 但是本小说的优点是平实靠谱的推理过程，埋线很细，读罢倒是没有被糊弄的感觉，与某些藏线索的作者高下立判。 《湖底的祭典》 诡叙流作品，布局很有想法，保留了这个作者的一贯水准。至于用到的核心Trick，现在看来倒是很一般，30年间有不少或拙劣或高深的模仿，读来已经觉得见怪不怪了。 大山诚一郎 是近年来水平比较高的作家了，《赤色博物馆》、《密室收藏家》评价口碑都不错，希望新书能早日看到翻译。 《密室收藏家》 总共有5篇很纯粹的密室故事，时间跨度60年，贯穿其中的就是自称密室收集家的一位，容貌永远不老，只要有密室出现就仿若从天而降一般的来解谜的神秘人物。整体质量不错，很正统的本格推理，强烈推荐。 《赤色博物馆》 依旧是短篇集，不过每篇故事都算很完整，写的是从未解决事件的证物细节中发掘真相的警察，读起来感觉还行，感觉不如上一本《密室收藏家》，也算值得一读了。 《伪证破解家》 呜呜呜，实在不应该先看电视剧的，虽然电视剧是俺老婆滨边美波演的，但是实在是表现太尬了，槽点满满。简单来说就是没什么剧情，很白开水。Trick倒是有亮点，但是完全没办法挽回本书口碑。本来我是很喜欢大山诚一郎这个作家的，现在看起来有点跌落神坛的感觉。 市川忧人 代表作品《水母不会冻结》和《蓝玫瑰不会安眠》，作为新锐推理小说作家，对他期待挺高，不过读过《水母不会冻结》后，感觉有点失望，不由对近年来另一部名气很大的推理作品《尸人庄杀人事件》感到忧心啊。 《水母不会冻结》 特点是暴风雪山庄和SF，号称致敬《无人生还》。不过也仅仅是个噱头，可能是叙述手法的问题，揭秘时没什么感觉，诡计也觉得一般。 《蓝玫瑰不会安眠》 和上一部一样的双线叙事的写作手法，配合叙诡，确实没想到是这样的一个布局，但是诡计还是感觉有点扯淡。总的来说可以一看，个人觉得比水母那本强点。 《玻璃鸟不会归来》 作者有意打造一个推理宇宙的样子，在这部能看到前两部的元素，读起来还是有种会心一笑的感觉。可惜不管是动机还是手法，简直跟胡闹差不多，失望之作。 歌野晶午 此人我只看过一部小说，已经隐隐有拉黑趋势了。 《樱树抽芽时，想你》 这是我看过的此人第一部小说。平心而论，就行文方式，确实读着很舒服，然而最核心的诡叙却让我很不信服，虽然解释了之前的一些让我疑惑的点，但是有些地方却让我更加觉得很雷人，甚至有点恶心。 贵志佑介 日本版蔡骏，感觉除了《玻璃之锤》以外别的都可以不看，不过改编的剧版《上锁的房间》居然还成了近10年难得能看的几部推理单元剧了。 《玻璃之锤》 现代社会中想实现完美犯罪实在是太难了，给古典推理造成了毁灭性打击。以往的无面尸诡计在现代刑侦技术中无所遁形。以至于很多推理必须架空背景或者设定为暴风雪山庄。本篇倒是硬刚了一波监控室密室，值得鼓励。作者借律师之口还完成了多重解答，最后由小锁匠一锤定音。 缺点嘛，可能是中间穿插的心路历程过多，有点强行社会派的感觉。另外本篇被影视化了，即为《上锁的房间》最后2话~ 白井智之 鬼畜推理代表之一，读完已被拉黑。 《杀死少女的100种方法》 五个案子，除了第三个案子有点黑色幽默的感觉，其他几个读起来只觉得恶心，感觉作者是心理变态。虽然是很本格的推理，但是我不喜欢他的内容。 中西智明 这老哥凭一部《消失！》出道，然后就没声音了。 《消失！》 八嘎推理作品，诡叙核心我没全猜到，只能说这种作品放在三十年前应该是惊艳的作品，可惜俺出生太晚，读到的时候也太晚了。 西村京太郎 文风好评，完爆绫辻行人那种晦涩文字。缺点在于推理性一般。 《七个证人》 无人生还模式作品，里面写了两个交叠的案子，读起来感觉跟逆转裁判差不多，各种层面上的。总的来说感觉惊喜感不够，但是优点是很重视逻辑自洽，不像某些小说十分牵强的只探讨一个可能性。 二阶堂黎人 他的人狼城早就想读了，可惜由于篇幅太长一直懒得读，这次正好赶上肺炎把坑给填了。 《恐怖的人狼城》 传说中的史上最长推理小说，一个故事拆成了4本书，真的佩服灌水能力。全书场面宏大，同步进行的暴风雪山庄事件，密室也很多，对于本格爱好者还是很友好的，核心诡计好像被金田一某集给抄了，导致我少了点惊喜。但是剧情实在有点扯，不管是动机还是里面的设定都是，最后还整了个玄幻让人摸不着头脑。总的来说，如果只看推理还是可以一试的。 若竹七海 日常推理作家，代表作《我的日常推理》，不过感觉和我电波对不上。 《我的日常推理》 短篇集，小说中日本风情挺多的，还有字谜梗，不过对于我来说就不太友好了。这本书的意图是把12篇故事连结起来，最后弄出三重反转，让人余味无穷，回头一翻伏笔确实挺多的，而且我基本上都没注意到。不过呢，其中有几篇故事实在是太寡淡了，实在很难让我提起兴趣。 中国孙沁文 笔名鸡丁，国产推理作家。只看过《凛冬之棺》。 《凛冬之棺》 包括3个密室，整体来说可以自圆其说，设计上还是挺有想象力的，不过总感觉和一些优秀的国外推理小说比差点味的样子。 陈浩基 香港推理作家，很早就听说过《13 67》的名声了，最近才得以拜读。 《13 67》 6篇故事，以主人公关振铎的视角，描述了香港的一个时代的变迁。就单篇而言是本格推理，放一块又有种社会派的感觉。最后一篇与第一篇遥相呼应，结构上给人很精妙的感觉。推荐一读。听说要改编电影？希望别毁了。 时晨 号称本格良心，逻辑良心，俺看完《黑曜馆事件》后就起了嘀咕，《镜狱岛事件》看了一点就弃了，给写出这样评价的人劈个叉吧。 《黑曜馆事件》 姑且评价一下，暴风雪山庄题材，本来俺挺感兴趣的，不过作者的核心手法都有问题，贯穿始终的“暗黑童话”感觉很可笑，这么一看的话，可读性就一般了，对不起豆瓣上那堆吹上天的评价。 杨叛 小时候在《今古传奇·武侠版》里面读过一点他的小说，很后面才补他的云寄桑三部曲。 《死香煞》 武侠+推理，是我喜欢的两个元素，这块写的好的并不多，小时候读的古龙算是其中的佼佼者了，作为武侠，很多在推理作品里面没法使用的诡计也能合理用出，读起来更有新奇感。可惜就这篇而言，虽然用了暴风雪山庄模式，总感觉情节和冲突都缺点味道，不够成熟。 《鬼缠铃》 其实整体上还行，就是老穿插男主的精神病，感觉故弄玄虚，另外那些配角各种设定，让人觉得神叨叨的，结果后面也不过如此。剩下的因为主角设定受了伤，没上一本那样的神功破案，相对来说限制多了点，可能就推理体验更好。 《傀儡咒》 读起来是因为惯性，其实亮点有限，读起来没什么意外感。而且我不太喜欢里面的棒子。 《自在花》 短篇，读的时候大概猜到了反转，不过也不难看。 欧美约翰·狄克森·卡尔 传说中的密室推理之王，暂时只看过《犹大之窗》。 《犹大之窗》 法庭推理，庭审和密室的二合一，有种逆转裁判的感觉。诡计嘛，个人估计一般，不过考虑到成书年代，也就凑合看了。","link":"/2020/03/05/推理小说记录/"},{"title":"Apriori算法","text":"很多人都听说过“尿布和啤酒”的故事：据说，美国中西部的一家连锁店发现，男人们去超市买尿布的同时，往往会顺便给自己购买啤酒。由此，卖场开始把啤酒和尿布摆放在相同区域，让男人可以同时找到这两件商品，从而获得了很好的销售收入。虽然并没有商店真的把这两样东西放在一起，但是很多商家确实将大家经常购买的物品放在一起捆绑销售以鼓励大家购买。那么我们如何在繁杂的数据发现这些隐含关系呢？这就需要关联分析（association analysis），本文所讨论的Apriori便是其中一种关联分析算法。 基本概念 关联分析是一种在大规模数据集中寻找有趣关系的任务。这些关系有两种形式：频繁项集、关联规则。频繁项集（frequent item sets）是经常出现在一块的物品的集合；关联规则（association rules）暗示两种物品之间可能存在很强的关系。 以下是某个杂货店的交易清单： 交易号码 商品 0 豆奶，莴苣 1 莴苣，尿布，葡萄酒，甜菜 2 豆奶，尿布，葡萄酒，橙汁 3 莴苣，豆奶，尿布，葡萄酒 4 莴苣，豆奶，尿布，橙汁 频繁项集：经常出现在一起的物品集合，如｛葡萄酒，尿布，豆奶｝就是一个频繁项集。 支持度（support）：如何有效定义频繁？其中最重要的两个概念是支持度和可信度。一个项集的支持度被定义为数据集中包含该项集的记录所占的比例。还是上面的例子，豆奶在5条交易中出现了4次，因此｛豆奶｝的支持度为4/5，同理可知，｛豆奶，尿布｝的支持度为3/5。我们可以定义一个最小支持度，从而只保留满足最小支持度的项集。 可信度或置信度（confidence）：是针对一条关联规则来定义的。例如：我们要讨论｛尿布｝→｛葡萄酒｝的关联规则，它的可信度被定义为“支持度（｛尿布，葡萄酒｝） / 支持度（｛尿布｝）”。因为｛尿布, 葡萄酒｝的支持度为3/5，｛尿布｝的支持度为4/5，所以“尿布→葡萄酒”的可信度为3/4=0.75。 Apriori原理 假设我们在经营一家商品种类并不多的杂货店，我们对那些经常一起被购买的商品很感兴趣。我们只有4种商品：商品0，商品1，商品2和商品3。那么所有可能被一起购买的商品组合有哪些？下图显示了物品之间所有可能的组合。 如何对一条给定的集合，如{0,3}，来计算其支持度？通常我们遍历每条记录并检查该记录包含0和3，如果记录确实包含两项，那么就增加总计数值。在扫描完每条数据后，使用统计的总数除以总交易记录数，就可以得到支持率。同样地，如果要获得每种可能集合的支持度就要多次重复上述过程。对于包含4种物品的集合，需要遍历数据15次。而随着物品数目的增加，遍历次数会急剧增长。对于包含N中物品的数据集共有2N−1中项集组合，对于只出售100中商品的商店也会有1.26×1030中可能的项集组合。对于现代计算机，需要很长的时间才能完成运算。 Apriori原理可以帮助我们减少感兴趣的项集。Apriori原理是指如果某个项集是频繁的，那么它的所有子集也是频繁的。反过来，如果一个项集是非频繁集，那么它的所有超集也是非频繁的。 上述例子中，已知阴影项集{2，3}是非频繁的。利用这个知识，我们就知道项集{0,2,3} ，{1,2,3}以及{0,1,2,3}也是非频繁的。这也就是说，一旦计算出了{2,3}的支持度，知道它是非频繁的之后，就不需要再计算{0,2,3}、{1,2,3}和{0,1,2,3}的支持度，因为我们知道这些集合不会满足我们的要求。使用该原理就可以避免项集数目的指数增长，从而在合理时间内计算出频繁项集。 Apriori算法 发现频繁项集的过程如上图所示： 由数据集生成候选项集C1（1表示每个候选项仅有一个数据项）；再由C1通过支持度过滤，生成频繁项集L1（1表示每个频繁项仅有一个数据项）。 将L1的数据项两两拼接成C2。 从候选项集C2开始，通过支持度过滤生成L2。L2根据Apriori原理拼接成候选项集C3；C3通过支持度过滤生成L3……直到Lk中仅有一个或没有数据项为止。 回到上面的杂货店例子，令最小支持度为0.4，结果如下图： 值得注意的是L3到C4这一步并没有得到候选项集，这是由于Apriori算法由两部分组成（在这里假定购买商品是有顺序的）。 连接：对K-1项集中的每个项集中的项排序，只有在前K-1项相同时才将这两项合并，形成候选K项集（因为必须形成K项集，所以只有在前K-1项相同，第K项不相同的情况下才合并。） 剪枝：对于候选K项集，要验证所有项集的所有K-1子集是否频繁（是否在K-1项集中），去掉不满足的项集，就形成了K项集。比如C4连接的｛尿布，莴苣，葡萄酒，豆奶｝的子集｛莴苣，葡萄酒，豆奶｝不存在于L3，因此要去掉。 实现Apriori代码 根据以上原理构造数据集扫描的Python代码，其伪代码大致如下： 1234567对数据集中的每条交易记录tran对每个候选项集can : 检查一下can是否是tran的子集 : 如果是，则增加can的计数值对每个候选项集 :如果其支持度不低于最小值，则保留该项集返回所有频繁项集列表 建立辅助函数： 12345678910111213141516171819202122232425262728293031323334353637383940# 创建一个简单的测试数据集def loadDataSet() : return [[1,3,4], [2,3,5], [1,2,3,5], [2,5]]# 构建集合C1，C1是大小为1的所有候选项集的集合。def createC1(dataSet) : # C1是空列表，用来存储所有不重复的项值。如果某个物品项没有在C1中出现，则将其添加到C1中。 # 这里并不是简单地每个物品项，而是添加只包含该物品项的一个列表。Python不能创建只有一个整 # 数的集合，因此这里实现必须使用列表 C1 = [] for transaction in dataSet : for item in transaction : if not [item] in C1 : C1.append([item]) C1.sort() # frozenset是指被“冰冻”的集合，就是说它们是不可改变 return list(map(frozenset,C1)) # D: 数据集# Ck: 候选项集列表# minSupport: 感兴趣集的最小支持度minSupport# 该函数会返回一个包含支持度的字典以备后用def scanD(D, Ck, minSupport) : ssCnt = {} for tid in D : for can in Ck : if can.issubset(tid) : if not can in ssCnt: ssCnt[can]=1 else : ssCnt[can] += 1 numItems = float(len(D)) retList = [] supportData = {} for key in ssCnt : # 计算所有项集的支持度 support = ssCnt[key]/numItems if support &gt;= minSupport : # 在列表的首部插入新的集合 retList.insert(0, key) supportData[key] = support return retList, supportData 保存为apriori.py，运行效果如下： 123456789101112131415161718&gt;&gt;&gt; import apriori# 导入数据集&gt;&gt;&gt; dataSet = apriori.loadDataSet()&gt;&gt;&gt; dataSet[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]# 构建第一个候选项集集合C1&gt;&gt;&gt; C1 = apriori.createC1(dataSet)&gt;&gt;&gt; C1[frozenset([1]), frozenset([2]), frozenset([3]), frozenset([4]), frozenset([5])]# 构建集合表示的数据集D&gt;&gt;&gt; D = list(map(set, dataSet))&gt;&gt;&gt; D[{1, 3, 4}, {2, 3, 5}, {1, 2, 3, 5}, {2, 5}]# 去掉不满足最小支持度的项集，0.5为最小支持度&gt;&gt;&gt; L1, suppData0 = apriori.scanD(D, C1, 0.5)# 下面四个项集构成了L1列表，该列表中每个单物品项集至少出现在50%以上的记录中&gt;&gt;&gt; L1[frozenset([5]), frozenset([2]), frozenset([3]), frozenset([1])] 整个Apriori算法的伪代码如下： 1234当集合中项的个数大于0时 构建一个k个项组成的候选项集的列表 检查数据以确认每个项集都是频繁的 保留频繁项集并构建k+1项组成的候选项集的列表 将如下算法代码加入apriori.py： 1234567891011121314151617181920212223242526272829303132333435363738394041# 创建候选项集Ck# Lk，频繁项集列表# k，项集元素的个数def aprioriGen(Lk, k) : # create Ck # 创建一个空列表 retList = [] # 计算Lk中的元素 lenLk = len(Lk) for i in range(lenLk) : for j in range(i+1, lenLk) : # 当前k-2个项相同时，将两个集合合并 L1 = list(Lk[i])[:k-2] L2 = list(Lk[j])[:k-2] L1.sort() L2.sort() if L1==L2 : # python中集合的并操作对应的操作符为| retList.append(Lk[i] | Lk[j]) return retList# dataSet，数据集# minSupport，支持度# 此函数会生成候选项集的列表def apriori(dataSet, minSupport = 0.5) : C1 = createC1(dataSet) # map函数将set()映射到dataSet列表中的每一项 D = list(map(set, dataSet)) L1, supportData = scanD(D, C1, minSupport) # 将L1放入L列表中 L = [L1] k = 2 # while循环将L2, L3, L4, ... 放入L列表中，直到下一个大的项集为空 while (len(L[k-2]) &gt; 0) : # 调用aprioriGen()创建候选项集Ck Ck = aprioriGen(L[k-2], k) # 扫描数据集，从Ck得到Lk Lk, supK = scanD(D, Ck, minSupport) supportData.update(supK) L.append(Lk) k += 1 return L, supportData 上面的k-2可能会令人困惑，接下来讨论其细节。当利用{0}、{1}、{2}构建{0,1}、{0,2}、{1,2}时，实际上是将单个项组合到一块。现在如果想利用{0,1}、{0,2}、{1,2}来创建三元素项集，应该怎么做？如果将每两个集合合并，就会得到{0,1,2}、{0,1,2}、{0,1,2}。也就是同样的结果集合会重复3次。接下来需要扫描三元素项集列表来得到非重复结果，我们要做的是确保遍历列表的次数最少。现在，如果比较集合{0,1}、{0,2}、{1,2}的第一个元素并只对第一个元素相同的集合求并操作，又会得到什么结果？{0,1,2}，而且只有一次操作，这样就不用遍历列表来寻找非重复值了。 保存后运行效果如下： 1234567891011121314151617181920212223&gt;&gt;&gt; L, supportData = apriori.apriori(dataSet)&gt;&gt;&gt; L[[frozenset([5]), frozenset([2]), frozenset([3]), frozenset([1])], [frozenset([2, 3]), frozenset([3, 5]), frozenset([2, 5]), frozenset([1, 3])], [frozenset([2,3, 5])], []]# L包含满足最小支持度为0.5的频率项集列表，下面看一下具体值：&gt;&gt;&gt; L[0][frozenset([5]), frozenset([2]), frozenset([3]), frozenset([1])]&gt;&gt;&gt; L[1][frozenset([2, 3]), frozenset([3, 5]), frozenset([2, 5]), frozenset([1, 3])]&gt;&gt;&gt; L[2][frozenset([2, 3, 5])]&gt;&gt;&gt; L[3][]# 每个项集都是在函数apriori()中调用函数aprioriGen()来生成的。下面看一下aprioriGen()函数的工作流程：&gt;&gt;&gt; apriori.aprioriGen(L[0], 2)[frozenset([2, 5]), frozenset([3, 5]), frozenset([1, 5]), frozenset([2, 3]), frozenset([1, 2]), frozenset([1, 3])]# 这里的6个集合是候选项集Ck中的元素。其中4个集合在L[1]中，剩下2个集合被函数scanD()过滤掉。# 下面再尝试70%的支持度：&gt;&gt;&gt; L,support = apriori.apriori(dataSet, minSupport=0.7)&gt;&gt;&gt; L[[frozenset([5]), frozenset([2]), frozenset([3])], [frozenset([2, 5])], []] 从频繁项集中挖掘关联规则 关联分析的两个重要目标是发现频繁项集与关联规则。要找到关联规则，首先从一个频繁项集开始，集合中的元素是不重复的，但我们想知道基于这些元素能否获得其他内容。某个元素或者某个元素集合可能会推导出另一个元素。例如，一个频繁项集｛豆奶, 莴苣｝，可能有一条关联规则“豆奶→莴苣”，这意味着如果有人购买了豆奶，那么在统计上他购买莴苣的概率较大。但是这条反过来并不总是成立。换言之，即使“豆奶→莴苣”统计上显著，那么“莴苣→豆奶”也不一定成立。箭头的左边集合称作前件，箭头右边的集合称为后件。 上节我们给出了繁琐项集的量化定义，即它满足最小支持度要求。对于关联规则，我们也有类似量化方法，这种量化标准称为可信度。一条规则P→H的可信度定义为support(P | H) / support(P)。在前面我们已经计算了所有繁琐项集支持度，要想获得可信度，只需要再做一次除法运算。 从一个繁琐项集中可以产生多少条关联规则？下图给出了从项集{0,1,2,3}产生的所有关联规则。为了找到感兴趣的规则，我们先生成一个可能的规则列表，然后测试每条规则可信度。如果可信度不满足最小要求，则去掉该规则。 可以观察到，如果某条规则并不满足最小可信度要求，那么该规则的所有子集也不会满足最小可信度要求。具体而言，如果012→3是一条低可信度规则，则所有其它3为后件的规则都是低可信度。这需要从可信度的概念去理解，Confidence(012→3) = P(3|0,1,2), Confidence(01→23)=P(2,3|0,1)，P(3|0,1,2) &gt;= P(2,3|0,1)。由此可以对关联规则做剪枝处理。 还是以之前的杂货店交易数据为例，我们发现了以下频繁项集： 对于寻找关联规则来说，频繁1项集L1没有用处，因为L1中的每个集合仅有一个数据项，至少有两个数据项才能生成A→B这样的关联规则。取置信度为0.7，最终从L2发掘出10条关联规则： 接下来是L3： 假设有一个L4项集（文中的数据不能生成L4），其挖掘过程如下： 利用此性质来减少测试的规则数目，可以先从一个频繁项集开始，接着创建一个规则列表，其中规则右部只包含一个元素，然后对这些规则测试。接下来合并所有剩余规则来创建一个新的规则列表，其中右部包含两个元素。这种方法称为分级法。打开apriori.py，加入如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 关联规则生成函数，此函数调用其他两个函数rulesFromConseq、calcConf# L: 频繁项集列表# supportData: 包含那些频繁项集支持数据的字典# minConf: 最小可信度阈值，默认是0.7# 函数最后要生成一个包含可信度的规则列表，后面可以基于可信度对它们进行排序# 这些规则存放在bigRuleList中。def generateRules(L, supportData, minConf=0.7) : bigRuleList = [] # 遍历L中的每一个频繁项集并对每个频繁项集创建只包含单个元素集合的列表H1， # 因为无法从单元素项集中构建关联规则，所以要从包含两个或者更多元素的项集开始规则构建过程。 # 只获取有两个或更多元素的集合 for i in range(1, len(L)) : for freqSet in L[i] : H1 = [frozenset([item]) for item in freqSet] if i &gt; 1 : # 如果频繁项集的元素数目超过2，那么会考虑对它做进一步的合并，合并通过 # rulesFromConseq来完成 rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf) else : # 如果项集中只有两个元素，那么需要使用calcConf()来计算可信度值 calcConf(freqSet, H1, supportData, bigRuleList, minConf) return bigRuleList# 对规则进行评估# 目标是计算规则的可信度以及找到满足最小可信度要求的规则# 函数会返回一个满足最小可信度要求的规则列表，空列表prunedH保存这些规则def calcConf(freqSet, H, supportData, brl, minConf=0.7) : prunedH = [] # 遍历H中的所有项集并计算它们的可信度值 for conseq in H : # 可信度计算时使用supportData中的支持度数据 conf = supportData[freqSet] / supportData[freqSet - conseq] # 规则满足最小可信度值，将这些规则输出到屏幕显示 if conf &gt;= minConf : print(freqSet-conseq, '--&gt;', conseq, 'conf:', conf) brl.append((freqSet-conseq, conseq, conf)) prunedH.append(conseq) return prunedH# 用于生成候选规则集合，从最初的项集中生成更多的关联规则# freqSet: 频繁项集# H: 可以出现在规则右部的元素列表def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7) : # H中频繁项集大小m m = len(H[0]) # 查看该频繁项集是否大到可以移除大小为m的子集 if (len(freqSet) &gt; (m+1)) : # 生成H中元素的无重复组合，结果存储在Hmp1，这也是下一次迭代的H列表 Hmp1 = aprioriGen(H, m+1) # Hmp1包含所有可能的规则，利用calcConf()来测试它们的可信度以确定是否满足要求 Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf) # 如果不止一条规则满足要求，那么使用Hmp1迭代调用函数rulesFromConseq if (len(Hmp1) &gt; 1) : rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf) 检验运行效果： 123456789101112131415161718192021222324252627282930&gt;&gt;&gt; import apriori&gt;&gt;&gt; dataSet = apriori.loadDataSet()&gt;&gt;&gt; dataSet[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]# 生成一个最小支持度为0.5的频繁项集的集合&gt;&gt;&gt; L, supportData = apriori.apriori(dataSet, minSupport=0.5)&gt;&gt;&gt; rules = apriori.generateRules(L, supportData, minConf=0.7)frozenset([5]) --&gt; frozenset([2]) conf: 1.0frozenset([2]) --&gt; frozenset([5]) conf: 1.0frozenset([1]) --&gt; frozenset([3]) conf: 1.0&gt;&gt;&gt; rules[(frozenset([5]), frozenset([2]), 1.0), (frozenset([2]), frozenset([5]), 1.0), (frozenset([1]), frozenset([3]), 1.0)]# 得到了3条规则：{5}→{2}、{2}→{5}、{1}→{3}，可见包含2和5的规则可以互换前后件，包含1和3的不行# 接下来降低可信度阈值，可以得到结果如下&gt;&gt;&gt; rules = apriori.generateRules(L, supportData, minConf=0.5)frozenset([3]) --&gt; frozenset([2]) conf: 0.666666666667frozenset([2]) --&gt; frozenset([3]) conf: 0.666666666667frozenset([5]) --&gt; frozenset([3]) conf: 0.666666666667frozenset([3]) --&gt; frozenset([5]) conf: 0.666666666667frozenset([5]) --&gt; frozenset([2]) conf: 1.0frozenset([2]) --&gt; frozenset([5]) conf: 1.0frozenset([3]) --&gt; frozenset([1]) conf: 0.666666666667frozenset([1]) --&gt; frozenset([3]) conf: 1.0frozenset([5]) --&gt; frozenset([2, 3]) conf: 0.666666666667frozenset([3]) --&gt; frozenset([2, 5]) conf: 0.666666666667frozenset([2]) --&gt; frozenset([3, 5]) conf: 0.666666666667&gt;&gt;&gt; rules[(frozenset({3}), frozenset({2}), 0.6666666666666666), (frozenset({2}), frozenset({3}), 0.6666666666666666), (frozenset({5}), frozenset({3}), 0.6666666666666666), (frozenset({3}), frozenset({5}), 0.6666666666666666), (frozenset({5}), frozenset({2}), 1.0), (frozenset({2}), frozenset({5}), 1.0), (frozenset({3}), frozenset({1}), 0.6666666666666666), (frozenset({1}), frozenset({3}), 1.0), (frozenset({5}), frozenset({2, 3}), 0.6666666666666666), (frozenset({3}), frozenset({2, 5}), 0.6666666666666666), (frozenset({2}), frozenset({3, 5}), 0.6666666666666666)]# 一旦降低可信度阈值，就可以获得更多的规则 Apriori应用 之前我们在小数据上应用了apriori算法，接下来要在更大的真实数据集上测试效果。那么可以使用什么样的数据呢？比如：购物篮分析，搜索引擎的查询词，国会投票，毒蘑菇的相似特征提取等； 示例：发现毒蘑菇的相似特征 从此处下载mushroom.dat，其前几行如下： 12345671 3 9 13 23 25 34 36 38 40 52 54 59 63 67 76 85 86 90 93 98 107 113 2 3 9 14 23 26 34 36 39 40 52 55 59 63 67 76 85 86 90 93 99 108 114 2 4 9 15 23 27 34 36 39 41 52 55 59 63 67 76 85 86 90 93 99 108 115 1 3 10 15 23 25 34 36 38 41 52 54 59 63 67 76 85 86 90 93 98 107 113 2 3 9 16 24 28 34 37 39 40 53 54 59 63 67 76 85 86 90 94 99 109 114 2 3 10 14 23 26 34 36 39 41 52 55 59 63 67 76 85 86 90 93 98 108 114 2 4 9 15 23 26 34 36 39 42 52 55 59 63 67 76 85 86 90 93 98 108 115 第一个特征表示有毒或者可食用，有毒为2，无毒为1。下一个特征是蘑菇伞的形状，有六种可能的值，分别用整数3-8来表示。 为了找到毒蘑菇中存在的公共特征，可以运行Apriori算法来寻找包含特征值为2的频繁项集。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&gt;&gt;&gt; import apriori&gt;&gt;&gt; mushDatSet = [line.split() for line in open('mushroom.dat').readlines()]# 在数据集上运行Apriori算法&gt;&gt;&gt; L, suppData = apriori.apriori(mushDatSet, minSupport=0.3)# 在结果中可以搜索包含有独特征2的频繁项集：&gt;&gt;&gt; for item in L[1] :... if item.intersection('2'): print(item)...frozenset({'28', '2'})frozenset({'2', '53'})frozenset({'2', '23'})frozenset({'2', '34'})frozenset({'2', '36'})frozenset({'59', '2'})frozenset({'63', '2'})frozenset({'67', '2'})frozenset({'2', '76'})frozenset({'2', '85'})frozenset({'2', '86'})frozenset({'2', '90'})frozenset({'93', '2'})frozenset({'2', '39'})# 对更大项集来重复上述过程&gt;&gt;&gt; for item in L[3] :... if item.intersection('2') : print(item)...frozenset({'2', '28', '59', '34'})frozenset({'2', '28', '59', '85'})frozenset({'2', '86', '28', '59'})frozenset({'2', '28', '59', '90'})frozenset({'2', '28', '59', '39'})frozenset({'63', '2', '28', '39'})frozenset({'63', '2', '28', '34'})frozenset({'63', '2', '28', '59'})frozenset({'63', '2', '28', '85'})frozenset({'63', '2', '86', '28'})frozenset({'2', '28', '85', '34'})frozenset({'2', '86', '28', '34'})frozenset({'2', '86', '28', '85'})frozenset({'34', '2', '28', '90'})frozenset({'2', '28', '85', '90'})frozenset({'2', '86', '28', '90'})frozenset({'2', '28', '34', '39'})frozenset({'2', '28', '85', '39'})frozenset({'2', '86', '28', '39'})frozenset({'2', '28', '90', '39'})frozenset({'34', '2', '28', '53'})frozenset({'2', '28', '85', '53'})frozenset({'2', '86', '28', '53'})frozenset({'90', '2', '28', '53'})frozenset({'2', '28', '53', '39'})...... 接下来你需要观察这些特征，以便知道蘑菇的各个方面，如果看到其中任何一个特征，那么这些蘑菇就很有可能有毒。 小结 关联特征是用于发现大数据集元素间有趣关系的一个工具集，可以采用两种方法来量化这些有趣关系。第一种方法是使用频繁项集，它会给出经常在一起出现的元素项。第二种方式是关联规则，每条关联规则意味着元素之前的“如果……那么”关系。 发现元素间不同的组合是个非常耗时的任务，不可避免需要大量昂贵的计算资源，这就需要一些更智能的方法在合适的时间范围内找到频繁项集。其中一个方法是Apriori算法，它使用Apriori原理减少在数据库上进行检查的集合的数目。Apriori原理是说如果一个元素项是不频繁的，那么那些包含该元素的超集也是不频繁的。Apriori算法从单元项集开始，通过组合满足最小支持度要求的项集来形成更大的集合。支持度用来度量一个集合在原始数据中出现的频率。 关联分析可以用在许多不同物品上。商店中的商品以及网站的访问页面是其中比较常见的例子。关联分析也曾用于查看选举人及法官的投票历史。 缺点是每次增加频繁项集的大小，Apriori算法都会重新扫描整个数据集，当数据集很大时，这会显著降低频繁项集发现的速度。 参考资料：《机器学习实战》、《数据挖掘导论》","link":"/2018/01/30/Apriori算法/"},{"title":"前端学习笔记","text":"平生不学WEB，便称编程也枉然 ！ HTML HTML（HyperText Markup Language）是一种标记语言以便于浏览器正确展示网页给用户。HTML使用标签（tags）来区分用户所能看到的内容和便于浏览器解释的指示。 基础 常见的IDE比如 Sublime、 VS code都支持一些智能生成HTML代码，简化输入。 用于生成一个html页面，包含head和body。 1&gt;&gt;&gt;! 通过输入标签名快速生成代码块，同理也可以输入h1、img、a等。 12&gt;&gt;&gt;p&lt;p&gt;&lt;/p&gt; 输入标签*数字可以快速生成多个同级标签。 1234&gt;&gt;&gt;p*3&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt; 也可以用加号连接标签名达到快速生成的目的。 123&gt;&gt;&gt;h1+p&lt;h1&gt;&lt;/h1&gt;&lt;p&gt;&lt;/p&gt; &gt;代表次级，用于快速生成嵌套结构。 123&gt;&gt;&gt;p*2&gt;img+a&lt;p&gt;&lt;img src=\"\" alt=\"\"&gt;&lt;a href=\"\"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img src=\"\" alt=\"\"&gt;&lt;a href=\"\"&gt;&lt;/a&gt;&lt;/p&gt; 用括号可以生成分组标签。 12345&gt;&gt;&gt;(div&gt;p)+(div&gt;img)&lt;div&gt; &lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;img src=\"\" alt=\"\"&gt;&lt;/div&gt; 生成带id或者class的标签 123456&gt;&gt;&gt;div#nav&lt;div id=\"nav\"&gt;&lt;/div&gt;&gt;&gt;&gt;div.bar&lt;div class=\"bar\"&gt;&lt;/div&gt;&gt;&gt;&gt;div#nav.bar&lt;div id=\"nav\" class=\"bar\"&gt;&lt;/div&gt; 标签后面用中括号可以快速添加属性。 12&gt;&gt;&gt;img[src=logo.jpg]&lt;img src=\"logo.jpg\" alt=\"\"&gt; 标签后面用大括号可以快速添加段落内容。 12&gt;&gt;&gt;p{峰哥牛逼}&lt;p&gt;峰哥牛逼&lt;/p&gt; lorem用于快速生成文本。 1234&gt;&gt;&gt;loremLorem ipsum dolor sit amet consectetur adipisicing elit...&gt;&gt;&gt;lorem4Lorem ipsum dolor sit. 标签标题 HTML 标题（Heading）是通过h1 - h6 等标签进行定义的。 1234&lt;h1&gt;这是一级标题&lt;/h1&gt;&lt;!-- 一级标题一般只设一个 --&gt;&lt;h2&gt;这是二级标题&lt;/h2&gt;&lt;h3&gt;这是三级标题&lt;/h3&gt; 段落 HTML 段落通过p标签进行定义。&nbsp; 123456&lt;p&gt;这是段落&lt;/p&gt;&lt;!-- 段落里多个空格会合并为1个空格，因此可以使用&amp;nbsp;来替代 --&gt;&lt;!-- 段落里换行会被忽略，显示为空格，如果要换行用&lt;br /&gt; --&gt;&lt;!-- 使用&lt;hr /&gt;来添加水平线 --&gt;&lt;span&gt;段内分组，方便用CSS来修改样式&lt;/span&gt;&lt;pre&gt;预排版标签，以便于保留段内空格、换行等格式&lt;/pre&gt; 超链接 超链接通过a标签进行定义。 1234567&lt;a href=\"网址\"&gt;文字或图片&lt;/a&gt;&lt;!-- 连接到本站点其他网页 --&gt;&lt;a href=\"news.html\"&gt;新闻&lt;/a&gt;&lt;!-- 连接到其他站点 --&gt;&lt;a href=\"https://www.baidu.com/\"&gt;百度&lt;/a&gt;&lt;!-- 虚拟超链接 --&gt;&lt;a href=\"#\"&gt;版块&lt;/a&gt; 图片 图片通过img标签进行定义。 12&lt;img src=\"w3school.gif\" alt=\"w3c\" /&gt;&lt;!-- alt即为图片替代名字，在未加载出来显示 --&gt; 块 块通过div标签进行定义，用于确定一个单独的区域，如页面的一个组成部分、一个栏目版块。 div元素没有特定的含义。除此之外，由于它属于块级元素，浏览器会在其前后显示折行。 如果与 CSS 一同使用，div元素可用于对大的内容块设置样式属性。 列表 无序列表ul，有序列表ol，列表项li。 12345&lt;ul&gt; &lt;li&gt;项目1&lt;/li&gt; &lt;li&gt;项目2&lt;/li&gt; &lt;li&gt;项目3&lt;/li&gt;&lt;/ul&gt; 项目1 项目2 项目3 12345&lt;ol&gt; &lt;li&gt;项目1&lt;/li&gt; &lt;li&gt;项目2&lt;/li&gt; &lt;li&gt;项目3&lt;/li&gt;&lt;/ol&gt; 项目1 项目2 项目3 表格 表格table， 每个表格均有若干行（由 tr标签定义），每行被分割为若干单元格（由 td标签定义）。字母td指表格数据（table data），即数据单元格的内容。数据单元格可以包含文本、图片、列表、段落、表单、水平线、表格等等。 123456789101112&lt;table border=\"1\"&gt;&lt;!-- border定义边框粗细 --&gt; &lt;tr&gt; &lt;td&gt;row 1, cell 1&lt;/td&gt; &lt;td&gt;row 1, cell 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 2, cell 1&lt;/td&gt; &lt;td&gt;row 2, cell 2&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;!-- table&gt;tr*2&gt;td*2 --&gt; row 1, cell 1 row 1, cell 2 row 2, cell 1 row 2, cell 2 123456789101112131415&lt;!-- 表头使用th标签,即将上表修改如下 --&gt;&lt;table border=\"1\"&gt; &lt;tr&gt; &lt;th&gt;title1&lt;/th&gt; &lt;th&gt;title2&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 1, cell 1&lt;/td&gt; &lt;td&gt;row 1, cell 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 2, cell 1&lt;/td&gt; &lt;td&gt;row 2, cell 2&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; title1 title2 row 1, cell 1 row 1, cell 2 row 2, cell 1 row 2, cell 2 如果有空格子，使用&amp;nbsp;占位，避免不显示边框 表单 HTML 表单用于搜集不同类型的用户输入，用form来表示。 input 通过改变type属性，可以得到不同input形态。action属性定义在提交表单时执行的动作，通常为提交的url地址，缺省则为当前页面。 12345678&lt;!-- text/password --&gt;&lt;form&gt; 账户: &lt;input type=\"text\" name=\"userName\" /&gt; &lt;br /&gt; 密码: &lt;input type=\"password\" name=\"userPsd\" /&gt;&lt;/form&gt; 账户: 密码: 1234567&lt;!-- submit/reset --&gt;&lt;form&gt; 姓名: &lt;input type=\"text\" value=\"\" name=\"myName\" /&gt; &lt;input type=\"submit\" value=\"提交\" name=\"submitBtn\" /&gt; &lt;input type=\"reset\" value=\"重置\" name=\"resetBtn\" /&gt;&lt;/form&gt; 姓名: 123456789101112&lt;!-- radio/checkbox --&gt;&lt;form&gt; 性别： 男&lt;input type=\"radio\" value=\"boy\" name=\"gender\" checked=\"checked\" /&gt; 女&lt;input type=\"radio\" value=\"girl\" name=\"gender\" /&gt; &lt;br /&gt; 爱好： &lt;input type=\"checkbox\" value=\"music\" name=\"music\" checked=\"checked\" /&gt;音乐 &lt;input type=\"checkbox\" value=\"sport\" name=\"sport\" /&gt;体育 &lt;input type=\"checkbox\" value=\"reading\" name=\"reading\" /&gt;阅读&lt;/form&gt; &lt;!-- checked属性设置成\"checked\"，该选项默认为选中 --&gt; 性别： 男 女 爱好： 音乐 体育 阅读 123456789101112131415&lt;!-- &lt;datalist&gt;元素为&lt;input&gt;元素规定预定义选项列表。 --&gt;&lt;!-- 用户会在他们输入数据时看到预定义选项的下拉列表。 --&gt;&lt;!-- &lt;input&gt; 元素的 list 属性必须引用 &lt;datalist&gt; 元素的 id 属性。 --&gt;&lt;form&gt; &lt;input list=\"选择你的浏览器：\"&gt; &lt;datalist id=\"browsers\"&gt; &lt;option value=\"Internet Explorer\"&gt; &lt;option value=\"Firefox\"&gt; &lt;option value=\"Chrome\"&gt; &lt;option value=\"Opera\"&gt; &lt;option value=\"Safari\"&gt; &lt;/datalist&gt; &lt;input type=\"submit\" value=\"提交\" name=\"submitBtn\" /&gt; &lt;input type=\"reset\" value=\"重置\" name=\"resetBtn\" /&gt;&lt;/form&gt; select select元素定义下拉列表。 12345678910&lt;!-- select --&gt;&lt;form&gt; 爱好： &lt;select&gt; &lt;option&gt;唱&lt;/option&gt; &lt;option selected=\"selected\"&gt;跳&lt;/option&gt; &lt;option&gt;rap&lt;/option&gt; &lt;option&gt;篮球&lt;/option&gt; &lt;/select&gt;&lt;/form&gt; 爱好： 看书 旅游 运动 购物 textarea textarea元素定义多行输入字段（文本域）。 12345678910&lt;!-- textarea --&gt;&lt;form&gt; 个人简介：&lt;br /&gt; &lt;textarea cols=\"50\" rows=\"10\"&gt; 在这里输入内容... &lt;/textarea&gt; &lt;br /&gt; &lt;input type=\"submit\" value=\"提交\" name=\"submitBtn\" /&gt; &lt;input type=\"reset\" value=\"重置\" name=\"resetBtn\" /&gt;&lt;/form&gt; 个人简介： 在这里输入内容... button button元素定义多行输入字段（文本域）。 1234&lt;!-- button --&gt;&lt;form&gt; &lt;button type=\"button\" onclick=\"alert('峰哥牛逼')\"&gt;点我&lt;/button&gt; &lt;/form&gt; 点我 语义化 语义化就是指让网页的含义更加明确，用于清楚地向浏览器和开发者描述其意义。 非语义元素的例子：div和 span - 无法提供关于其内容的信息。 语义元素的例子：form、table以及 img - 清晰地定义其内容。 下面列出了以字母顺序排列的 HTML5 新语义元素。 标签 描述 article 定义文章。 aside 定义页面内容以外的内容。 details 定义用户能够查看或隐藏的额外细节。 figcaption 定义 figure元素的标题。 figure 规定自包含内容，比如图示、图表、照片、代码清单等。 footer 定义文档或节的页脚。 header 规定文档或节的页眉。 main 规定文档的主内容。 mark 定义重要的或强调的文本。 nav 定义导航链接。 section 定义文档中的节。 summary 定义 details 元素的可见标题。 time 定义日期/时间。 强调 em和i用于斜体，strong和b用于加粗。但是前者有语义，后者没有。 自定义列表 自定义列表dl，列表项dt，描述dd。 123456&lt;dl&gt; &lt;dt&gt;HTML&lt;/dt&gt; &lt;dd&gt;超文本标记语言&lt;/dd&gt; &lt;dt&gt;CSS&lt;/dt&gt; &lt;dd&gt;层叠样式表&lt;/dd&gt;&lt;/dl&gt; HTML 超文本标记语言 CSS 层叠样式表 CSS CSS 指层叠样式表 (Cascading Style Sheets)，样式定义如何显示 HTML 元素，通常存储在样式表中，它的出现，是为了解决内容与表现分离的问题，可以极大提高工作效率。外部样式表通常存储在 CSS 文件中，多个样式定义可层叠为一。 基础 在IDE中，可以通过快捷的方式生成样式结构。 生成css的link。 12&gt;&gt;&gt;link:css&lt;link rel=\"stylesheet\" href=\"style.css\"&gt; 常见css缩写： 12345678910111213/* 在css框内输 */&gt;&gt;&gt;w30width: 30px;&gt;&gt;&gt;h30height: 30px;&gt;&gt;&gt;mg10margin: 10px;&gt;&gt;&gt;pd5padding: 5px;&gt;&gt;&gt;lh2emline-height: 2em;&gt;&gt;&gt;bgcbackground-color: #fff; 语法 以下为一个css样式，p为选择器，即选择哪个标签添加样式。为了方便易读，每行代码最好写在一个新行。 12345p{ font-size:12px; /*字号*/ color:blue; /*文本颜色*/ font-weight:bold; /*加粗*/} 创建内联样式 由于要将表现和内容混杂在一起，内联样式会损失掉样式表的许多优势。请慎用这种方法，例如当样式仅需要在一个元素上应用一次时。 要使用内联样式，你需要在相关的标签内使用样式（style）属性。Style 属性可以包含任何 CSS 属性。本例展示如何改变段落的颜色： 123&lt;p style=\"color:red;\"&gt; 我不会CSS&lt;/p&gt; 我不会CSS 内部样式 当单个文档需要特殊的样式时，就应该使用内部样式表。你可以使用 style标签在文档头部定义内部样式表，就像这样: 123456789101112131415&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;style type=\"text/css\"&gt; p[type=\"css_Demo\"]{ color:red; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;p type=\"css_Demo\"&gt; 我不会CSS &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; p[type=\"css_Demo\"]{ color:red; } 我不会CSS 这里使用了属性和值选择器，关于选择器，具体后面再提。 外部样式 当样式需要应用于很多页面时，外部样式表将是理想的选择。在使用外部样式表的情况下，你可以通过改变一个文件来改变整个站点的外观。每个页面使用link 标签链接到样式表。link标签在（文档的）头部，例如： 123&lt;head&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"mystyle.css\" /&gt;&lt;/head&gt; 浏览器会从文件 mystyle.css 中读到样式声明，并根据它来格式文档。 外部样式表可以在任何文本编辑器中进行编辑。文件不能包含任何的 html 标签。样式表应该以 .css 扩展名进行保存。 123p{ color:red;} 这样对于多个页面，就能通过链接进行样式设定，方便维护。 多重样式 如果某些属性在不同的样式表中被同样的选择器定义，那么属性值将依赖于就近原则。简而言之，优先级内联样式&gt;内部样式&gt;外部样式。 例如，外部样式表拥有针对 h3 选择器的三个属性： 12345h3 { color: red; text-align: left; font-size: 8pt; } 而内部样式表拥有针对 h3 选择器的两个属性： 1234h3 { text-align: right; font-size: 20pt; } 假如拥有内部样式表的这个页面同时与外部样式表链接，那么 h3 得到的样式是： 12345h3 { color: red; text-align: right; font-size: 20pt; } 即颜色属性将被继承于外部样式表，而文字排列（text-alignment）和字体尺寸（font-size）会被内部样式表中的规则取代。 选择器标签选择器 以下面为例，通过body，h1，p，hr这些标签名来定义相应的CSS。 12345678910111213141516171819202122&lt;style type=\"text/css\"&gt; body{ background-color: #ccc; text-align: center; font-size: 12px; } h1{ font: \"黑体\"; font-size: 20px; } p{ color: red; font-size: 16px; } hr{width: 200px;}&lt;/style&gt;&lt;body&gt; &lt;h1&gt;标题&lt;/h1&gt; &lt;hr&gt; &lt;p&gt;正文段落&lt;/p&gt; 版权所有&lt;/body&gt; 类别选择器 CSS中，类别选择器用一个.显示。 123456789101112&lt;style type=\"text/css\"&gt; p{font-size: 12px;} .one{font-size: 18px;} .two{font-size: 24px;}&lt;/style&gt;&lt;body&gt; &lt;p class=\"one\"&gt;类别1&lt;/p&gt; &lt;p class=\"one\"&gt;类别1&lt;/p&gt; &lt;p class=\"two\"&gt;类别2&lt;/p&gt; &lt;p class=\"two\"&gt;类别2&lt;/p&gt; &lt;p&gt;正文段落&lt;/p&gt;&lt;/body&gt; ID选择器 CSS中，ID选择器用一个#号显示。与类别选择器不同之处在于，它具有唯一性。 12345678&lt;style type=\"text/css\"&gt; #one{font-size: 12px;} #two{font-size: 24px;}&lt;/style&gt;&lt;body&gt; &lt;p id=\"one\"&gt;ID1&lt;/p&gt; &lt;p id=\"two\"&gt;ID2&lt;/p&gt;&lt;/body&gt; 嵌套声明 根据文档的上下文关系来确定某个标签的样式。 123456&lt;style type=\"text/css\"&gt; p span{color: green;}&lt;/style&gt;&lt;body&gt; &lt;p&gt;法国男兵法国女兵都是&lt;span&gt;法国士兵&lt;/span&gt;。&lt;/p&gt;&lt;/body&gt; 集体申明 用逗号将所有需要申明的选择器分开，这样可以分享相同的声明。 12345678910&lt;style type=\"text/css\"&gt; h1,p{ color: green; text-align:center; }&lt;/style&gt;&lt;body&gt; &lt;h1&gt;峰哥牛逼&lt;/h1&gt; &lt;p&gt;黄浦江之王！&lt;/p&gt;&lt;/body&gt; 全局申明 用*表示所有标签均应用申明。 1234567891011&lt;style type=\"text/css\"&gt; *{ color: green; text-align:center; }&lt;/style&gt;&lt;body&gt; &lt;h1&gt;峰哥牛逼&lt;/h1&gt; &lt;p&gt;黄浦江之王！&lt;/p&gt; &lt;h2&gt;不服的沉了！&lt;/h2&gt;&lt;/body&gt; 样式文本 CSS 文本属性可定义文本的外观。 单位 单位 描述 px 像素 em 字符，自动适应用户所使用的字体 % 百分比，继承自DOM树上一级 颜色 颜色 描述 red,blue,green CSS颜色名 rgb(x,x,x) RGB值，每个参数 (red、green 以及 blue) 定义颜色的强度，可以是介于 0 与 255 之间的整数 rgb(x%,x%,x%) RGB百分比值，取值介于0%到100% rgba(x,x,x,x) 是 RGB 颜色值的扩展，带有一个 alpha 通道 - 它规定了对象的不透明度，介于0.0（完全透明）与1.0（完全不透明）之间 #rrggbb 十六进制数，参考CSS颜色十六进制值 段落 属性 描述 取值 letter-spacing 字符间距 2px -3px line-height 行高 14px 1.5em 120% text-align 对齐 center left right justify text-decoration 装饰线 none overline underline line-through text-indent 首行缩进 2em 字体 font是有顺序的： font:斜体 粗体 字号/行高 字体; font:italic bold 16px/1.5em 宋体; 属性 描述 举例 font 声明设置所有的字体属性 2px -3px font-family 字体系列 font-family:”Hiragino Sans GB”,sans-serif font-size 字号 14px 120% font-style 斜体 italic font-weight 首行缩进 bold 背景 空元素需要先定义元素的高度和宽度。 属性 描述 举例 background 声明设置所有的背景属性 2px -3px background-color 背景颜色 red blue green background-image 背景图片 url(xxx.gif) background-repeat 填充方式 repeat repeat-x repeat-y no-repeat 超链接 以下这种形式也被称为伪类选择器。 a:link - 普通的、未被访问的链接 a:visited - 用户已访问的链接 a:hover - 鼠标指针位于链接的上方悬停，必须位于a:link和a:visited之后 a:active - 链接被点击的时刻，必须位于a:hover之后 示例：鼠标悬停放大字体： 12345678a{ font-size:22px;}a:hover{ font-size:200%}&lt;a href=https://www.douyu.com/9999&gt;Rua!&lt;/a&gt; a[id=\"fgnb\"]{ font-size:20px; } a[id=\"fgnb\"]:hover{ font-size:200%; color:green; } Rua! 列表 属性 描述 举例 list-style 声明设置所有的列表属性 type position image list-style-image 为列表项标志设置图像 url(xxx.gif) list-style-position 标志位置 inside outside list-style-type 标志类型 none square more 表格常见属性 width, height - 表格大小 border - 表格边框 border-collapse - 合并表格边框和单元格边框 奇偶选择器:nth-child(odd/even) 1234tr:nth-child(odd){ background-color:#EAF2D3; }/* 奇行设置背景色 */ 布局盒子模型 页面上所有元素看成一个盒子，占据一定的页面空间。 content - 内容 height - 高度 width - 宽度 border - 边框 padding - 内边距 margin - 外边距 盒子的实际宽度、高度由content、padding、border、margin决定。以下为一个简单的盒子模型。 1234567891011121314151617181920&lt;html&gt;&lt;head&gt;&lt;style type=\"text/css\"&gt; #box{ width: 100px; height: 100px; border: 1px solid; padding: 20px; margin: 10px; }&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"box\"&gt; Rua!Rua!Rua! Rua!Rua!Rua! Rua!Rua!Rua! &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; overflow 上述例子中，内容可以超出盒子框，应该定义overflow属性来应对。它取值包括： hidden - 超出部分不可见 scroll - 显示滚动条 auto - 如果有超出部分，显示滚动条 border 属性 描述 border width style color border-width px thin medium thick border-style dashed dotted solid double border-color green #EAF2D3 以水平分割线为例： 12345.line{ height:1px; width:500px; border-top:1px solid #e5e5e5;} 需要的时候定义class为line即可。 padding&amp;margin 由于浏览器默认对padding和margin有赋值，通常我们会对它们清零。 1234*{ margin:0; padding:0;} 取值：px，%（外层盒子的宽度和高度），对于margin:1px 2px 1px 3px;而言，分别是定义上、右、下、左的边距，对于margin:1px 2px;而言，相当于省略了下和左，他们的取值与上、右保持一致，也就是等同于margin:1px 2px 1px 2px;的效果。同理，如果是写3个值，相当于省略最后一个左，其值等于右。 内边距 外边距 组成 padding:5px; margin:5px; 上右下左 padding-top:10%; margin-top:10%; 上 padding-left margin-left 左 padding-right margin-right 右 padding-bottom margin-bottom 下 以下为例，值得注意的是div做盒子，会有换行的效果。margin会有合并的效果，具体而言：垂直方向合并，水平方向不合并。 12345678910111213141516&lt;html&gt;&lt;head&gt;&lt;style type=\"text/css\"&gt; div{ width: 100px; height: 100px; border: 1px solid red; margin: 15px 10px 20px 30px; }&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"box1\"&gt;box1&lt;/div&gt; &lt;div id=\"box2\"&gt;box2&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 平时我们对图片文字水平居中，通常用text-align:center;，而div水平居中，可以用margin:0 auto;，浏览器自动计算。 定位文档流flow 除非专门指定，否则所有框均以此来定位。 none 设置为这个的元素不会被显示。 123a{ display:none;} block 独占一行，元素的height、width、margin、padding都可设置。 常见的block元素：div、 p、h1…h6、ol、ul、table、form。 将其他元素显示成block元素，以inline元素a为例： 123a{ display:block;} inline 不单独占用一行。 width、height不可设置。 width就是它包含的文字或图片的宽度，不可改变。 常见的inline元素：span、a。 显示为inline元素： 123a{ display:inline;} 值得注意的是inline元素有间隙。 inline-block 同时具备inline元素、block元素的特点。 不单独占用一行。 可以设置height、width、margin、padding。 常见的inline-block元素：img。 显示为inline-block元素： 123a{ display:inline-block;} 示例 以导航条为例： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;html&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style type=\"text/css\"&gt; *{ padding: 0; margin: 0; } #nav_1{ width: 300px; margin: 0 auto; font-size: 0; } .nav_a{ display: inline-block; width: 80px; height: 30px; font-size: 14px; text-align: center; line-height: 30px; text-decoration: none; border-bottom: 1px solid #ccc; } a.nav_a:hover{ color: white; background-color: #ccc; border: 1px solid; border-left-color: orange; border-top-color: orange; border-right-color: orange; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"nav_1\"&gt; &lt;a class=\"nav_a\" href=\"https://www.douyu.com/9999\"&gt;Rua!&lt;/a&gt; &lt;a class=\"nav_a\" href=\"https://www.douyu.com/9999\"&gt;Rua!！&lt;/a&gt; &lt;a class=\"nav_a\" href=\"https://www.douyu.com/9999\"&gt;Rua!!!&lt;/a&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 浮动floatfloat 通过float属性来定位，例如div实现多列布局。 以下为例，box1和box2就脱离了文档流原来位置（竖直摆放）。 12345678910111213141516&lt;html&gt;&lt;head&gt;&lt;style type=\"text/css\"&gt; div{ width: 100px; height: 100px; border: 1px solid red; float: left; }&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"box1\"&gt;box1&lt;/div&gt; &lt;div id=\"box2\"&gt;box2&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; clear 用于清除浮动。 both，清除左右两边的浮动。 left和right只能清除一个方向的浮动。 none为默认值，只在需要移除已指定的清除值时用到。 清除的意思是指该元素指定方向不会有浮动，用于浮动换行。比如要设置footer，不希望它左右两边有浮动元素： 123#footer{ clear:both;} 示例 三行一列： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style&gt; *{ padding: 0; margin: 0; } body{ font-size: 14px; } #container{ margin: 0 auto; width: 1000px; height: 500px; } #header{ height: 100px; background-color: #6cf; margin-bottom: 5px; } #main{ height: 500px; background-color: #cff; margin-bottom: 5px; } #footer{ height: 60px; background-color: #6cf; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"container\"&gt; &lt;div id=\"header\"&gt;&lt;/div&gt; &lt;div id=\"main\"&gt;&lt;/div&gt; &lt;div id=\"footer\"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 一行两列： 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style&gt; *{ padding: 0; margin: 0; } body{ font-size: 14px; } #container{ margin: 0 auto; width: 1000px; height: 500px; } #aside{ float: right; width: 695px; height: 500px; background-color: #6cf; } #content{ float: left; width: 300px; height: 500px; background-color: #cff; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"container\"&gt; &lt;div id=\"aside\"&gt;&lt;/div&gt; &lt;div id=\"content\"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 组合为三行两列: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style&gt; *{ padding: 0; margin: 0; } body{ font-size: 14px; } #container{ margin: 0 auto; width: 1000px; height: 500px; } #header{ height: 100px; background-color: #6cf; margin-bottom: 5px; } #main{ height: 500px; margin-bottom: 5px; } #aside{ float: right; width: 695px; height: 500px; background-color: #6cf; } #content{ float: left; width: 300px; height: 500px; background-color: #cff; } #footer{ height: 60px; background-color: #6cf; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"container\"&gt; &lt;div id=\"header\"&gt;&lt;/div&gt; &lt;div id=\"main\"&gt; &lt;div id=\"aside\"&gt;&lt;/div&gt; &lt;div id=\"content\"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id=\"footer\"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 最后是四行三列： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style&gt; *{ padding: 0; margin: 0; } body{ font-family: \"微软雅黑\"; font-size: 14px; } #container{ margin: 0 auto; width: 900px; } #header{ height: 100px; background-color: #6cf; margin-bottom: 5px; } #nav{ height: 30px; background-color: #09c; margin-bottom: 5px; } #main{ height: 500px; margin-bottom: 5px; } .aside{ float: left; width: 100px; height: 500px; background-color: #6cf; } #aside1{ margin-right: 5px; } #aside2{ margin-left: 5px; } #content{ float: left; width: 690px; height: 500px; background-color: #cff; } #footer{ height: 60px; background-color: #6cf; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"container\"&gt; &lt;div id=\"header\"&gt;&lt;/div&gt; &lt;div id=\"nav\"&gt;&lt;/div&gt; &lt;div id=\"main\"&gt; &lt;div id=\"aside1\" class=\"aside\"&gt;&lt;/div&gt; &lt;div id=\"content\"&gt;&lt;/div&gt; &lt;div id=\"aside2\" class=\"aside\"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id=\"footer\"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 层layer 通过position属性来定位。目的是希望网页的元素能叠加在另外一个元素上面，能像图像软件中的图层一样可以对每个layer能够精确定位操作。 static 默认值，没有定位，元素出现在正常的流中，top、bottom、left、right、z-index无效。 z-index：定义层叠顺序，越大则处于更前。 fixed 固定定位，相对于浏览器窗口进行定位，top、bottom、left、right、z-index有效。 123456789#fixed-box{ width: 200px; height: 200px; border: 1px solid red; position: fixed; left: 100px; top: 50px;} relative 相对定位，相对于其直接父元素进行定位，top、bottom、left、right、z-index有效。 定位为relative的层脱离正常文本流，但其在正常流的原位置存在。 12345678#relative-box{ width: 170px; height: 190px; position: relative; left: 20px; top: 20px;} absolute 绝对定位，相对于static定位以外的第一个父元素进行定位，top、bottom、left、right、z-index有效。 定位为absolute的层脱离正常文本流，但与relative的区别是：其在正常流的原位置不再存在。 对于absolute定位的层总是相对于其最近的定义为absolute或relative的父层，而这个父层并不一定是其直接父层。 极端而言，对于absolute定位的层，如果其父层中都未定义absolute或relative，则其将相对body进行定位。 总结而言： 相对定位 绝对定位 position取值 relative absolute 文档流中原位置 保留 不保留 定位参照物 直接父元素 非static的父元素 relative+absolute 通常按照如下思路来定位： 父元素box1：position:relative; 子元素box2：position:absolute; 子元素box2：top、bottom、left、right相对于父元素来进行偏移定位。 类似如此： 1234567891011#box1{ position:relative;}#box2{ position:absolute;}&lt;div id=\"box1\"&gt; &lt;div id=\"box2\"&gt; &lt;/div&gt;&lt;/div&gt; 举例而言，如果对于定义一副图片+图片说明，可以这样写： 123456789101112131415161718192021&lt;style&gt; div{ border: 1px solid red; color: #fff; } #box1{ width: 170px; height: 190px; position: relative; } #box2{ width: 99%; position: absolute; bottom: 0; }&lt;/style&gt;&lt;div id=\"box1\"&gt; &lt;img src=\"coffee.jpg\" alt=\"coffee\"&gt; &lt;div id=\"box2\"&gt;一起享受咖啡带来的温暖吧&lt;/div&gt;&lt;/div&gt; CSS3 由于W3C对标准更新速度较慢，所以浏览器会先于标准制定对新标准的支持。对于不同的浏览器，有不同的CSS3前缀： 浏览器内核 浏览器 CSS3前缀 Webkit Safari/Chrome -webkit- Gecko Firefox -moz- Presto Opera -o- Trident IE -ms- 边框border-radius 圆角边框，由border-top-left-radius、border-top-right-radius、border-bottom-left-radius、border-bottom-right-radius组成。 如果填两个值，即为水平值和垂直值，如果只填一个，则默认两值相等。 1234567div{ height: 100px; width: 150px; border: 1px solid blue; border-top-left-radius: 40px 20px; border-bottom-right-radius: 20px;} 也可以直接通过设置border-radius来一次定义四个边角的框。 1234567div{ height: 50px; width: 350px; border: 2px solid #alalal; background: #ddd; border-radius: 25px;} box-shadow 阴影，可以有内部阴影inset，外部阴影outset两种，默认外部阴影。 四个参数分别是：水平偏移，垂直偏移，模糊距离，颜色。 123456div{ height: 100px; width: 300px; background-color: #f90; box-shadow: 10px 10px 5px #888;} 文本text-shadow 设置文本阴影。四个参数分别指水平偏移，垂直偏移，阴影大小（可省略），颜色。 123456h1{ text-shadow: 2px 2px #FF0000;}h1{ text-shadow: 2px 2px 8PX blue;} 常用于文字描边，比如： 123h1{ text-shadow: 0 0 3px #F00;} 又比如用来做突起浮雕的效果： 1234h1{ color: white; text-shadow: 2px 2px 4px #000;} word-wrap 允许长单词，URL 强制进行换行。如果不设置，长单词可能会溢出边框外。 1234567891011&lt;style&gt; p.wdrp{ width: 8em; border: 1px solid #333; word-wrap: break-word; }&lt;/style&gt;&lt;body&gt;&lt;p class='wdrp'&gt;这是最长的英文单词:pneumonoultramicroscopicsilicovolcanoconiosis&lt;/p&gt;&lt;/body&gt; @font-face规则 即把特殊字体放在服务器端。根据@font-face规则，定义Web字体，并引用需要字体的四种格式，确保能在主流浏览器中都能正常显示该字体。 字体文件后缀 适用于浏览器 .TTF或.OTF Firefox、Safari、Opera .EOT Internet Explorer 4.0+ .SVG Chrome、IPhone .WOFF Chrome、Firefox 其定义格式如下： 123456789101112131415&lt;style&gt; @font-face{ /** 定义字体名称 **/ font-family: kastlerFont; /** 定义字体来源 **/ src:url('fonts/kastler.ttf'), url('fonts/kastler.eot'), url('fonts/kastler.woff'), url('fonts/kastler.svg'); } p{ /** 引用字体 **/ font-family: kastlerFont; }&lt;/style&gt; 2D转换 CSS3中2D转换主要包括对元素进行旋转、缩放、移动、拉伸。 主要是用transform属性，rotate()、scale()。 rotate 示例如下： 1234567891011121314151617&lt;style&gt; div{ width: 8em; height: 75px; background-color: #ccc; border: 1px solid black; } #rotateDiv{ /** 正值代表顺时针旋转 **/ transform: rotate(30deg); }&lt;/style&gt;&lt;div id=\"container\"&gt; &lt;div&gt;峰哥牛逼&lt;/div&gt; &lt;div id=\"rotateDiv\"&gt;峰哥牛逼&lt;/div&gt;&lt;/div&gt; scale 以transform: scale(x,y)为例，x代表水平方向缩放倍数，y代表垂直方向缩放倍数，省略同x，倍数取值0~1代表缩小，大于1为放大。 123#scaleDiv{ transform: scale(1.2);} 过渡与动画过渡 用transition表示，主要是把元素的某个属性从一个值在指定时间内过渡到另一个值，包括： 属性 描述 transition 简写，同时在一个属性中设置四个过渡属性 transition-property 属性名，对哪个属性进行变化，所以属性可以用all表示 transition-duration 定义过渡效果花费的时间，默认是 0 transition-timing-function 过渡效果的方法函数，默认是 “ease” transition-delay 规定过渡效果何时开始，默认是 0 示例： 12345678910111213141516171819202122&lt;html&gt;&lt;head&gt; &lt;style type=\"text/css\"&gt; #transition_demo{ height: 30px; width: 100px; line-height: 30px; border-radius: 5px; color: #000; background-color: silver; transition: all 1s linear; } #transition_demo:hover{ color: white; background-color: #45b823; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"transition_demo\"&gt;Rua!&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 动画 主要用@keyframes规则 ，animation属性。包含如下 属性 描述 @keyframes 规定动画 animation 所有动画属性的简写属性 animation-name 引入 @keyframes 动画的名称 animation-duration 规定动画完成一个周期所花费的秒或毫秒 animation-timing-function 规定动画的速度曲线，默认是 “ease” animation-play-state 规定动画何时开始。默认是 0。 12345678910111213141516171819202122&lt;html&gt;&lt;head&gt; &lt;style type=\"text/css\"&gt; @keyframes mycolor { 0% {background-color: red;} 30% {background-color: blue;} 60% {background-color: yellow;} 100% {background-color: green;} } #keyframes_demo:hover{ animation: mycolor 5s linear; } &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id=\"keyframes_demo\"&gt;Rua!&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3D变换 用transform-style: preserve-3d，常用的有旋转和透视。 通常用嵌套形式设置，里面的对象称为父容器，设置transform属性，外面的对象称为舞台，设置perspective属性。 旋转 transform属性，角度deg： rotateX() rotateY() rotateZ() 透视 perspective属性。 JavaScript JavaScript是一种运行于JavaScript解释器/引擎中的解释型脚本语言。 基本引用 类似于CSS，可以在html文件中任意地方使用，也可以用 &lt;script src=&quot;...&quot;&gt;&lt;/script&gt;引入这个文件，注意如果引用外部文件，里面不能再有js代码了。 语法 类似Java，每句用；结束。 大小写敏感 //单行注释，/ /多行注释 变量 声明，var变量名。不申明即为全局变量，可能会出现冲突。 1234//声明var userName;//赋值var bookPrice=25.5; 运算符 值得注意的是与Python不一样的有： 比较运算符，==会转换数据类型，为了避免有bug应用===，这样不会转换数据类型。 Python的递增我们一般用i+=1，这里用i++即可。 逻辑运算符， 与&amp;&amp; ，或 || ，三元运算符变量= (条件) ? 值A:值B 12345//例如：var age = 20;var msg = age &gt; 18 ? \"成年\" : \"未成年\";console.log(msg);//\"成年\" 可以嵌套： 1234var score = 55;var result = score &gt;= 80 ? \"优秀\" : (score &gt;= 60 ? \"及格\" : \"不及格\");console.log(result);//\"不及格\" 函数 最基本： 1234567891011function 函数名(){ 可执行语句;} //e.g.function printHello(){ console.log(\"Hello,\"); console.log(\"World!\");}printHello();/* Hello, World! */ 带参数： 123456789function 函数名(参数列表声明){ 可执行语句;} //e.g.function printInfo(userName,userPwd){ console.log('用户名:'+userName + ' 密码:'+userPwd);}printInfo('Tom','123');// 用户名:Tom 密码:123 带返回值： 1234567891011function 函数名(参数列表声明){ 可执行语句; return 值;} //e.g.function add(num1,num2){ return num1 + num2;}var result = add(10,20);console.log('结果是：'+result);// 结果是：30 注意函数作用域里面的变量（局部变量）只在当前函数能访问，离开此范围就无法访问了。 123456function add(){ var sum = 1 + 2; console.log(sum);}console.log(sum);// Uncaught ReferenceError: sum is not defined 参数按值传递，传参的时候实际上是将实参复制一份传给函数，在函数体内对变量进行修改，实际上不影响外部实参变量。 1234567var n=100; //全局变量function fun(n){ //参数变量 n-=3; //修改的是局部变量n console.log(n); //输出的是局部变量}fun(n); //按值传递，方法内输出97console.log(n); //输出全局变量的值：100 流程控制条件判断if-else结构1234567891011121314151617181920// ifif(条件表达式){ 语句块; }// 带elseif(条件表达式){ 语句块1; }else{ 语句块2; }// 带else ifif(条件1){ 语句块1; }else if(条件2){ 语句块2; }else if(条件3){ 语句块3; }else{ 语句块4; } switch-case结构 通常用于等值判断的条件中，满足case条件执行，但是因为执行后会执行后面的语句，所以需要和break联用。 123456789101112switch(表达式){ case 值1: 语句1; 语句2; break; case 值2: 语句3; break; ...... default: 语句n; } 循环while循环12345678910111213141516171819while(表达式){ 循环体语句;}//e.g.var i=0;while(i&lt;10){ console.log('Hello,world!'); i++;}// 类似python，也有continue和break// e.g.var i=0;while(i&lt;100){ console.log(i); if(i==5){ break; } i++;} do-while循环123do{ 循环体语句;}while(表达式); for循环1234567for(表达式1(初始条件);表达式2(判断条件);表达式3(递增条件)){ 循环体;}//e.g.for(var i=0;i&lt;10;i++){ console.log(i);} for循环的三个条件可以省略，如果没有break会无限循环下去。 for-in循环123456789var o = { name: 'Jack', age: 20, city: 'Beijing'};for (var key in o) { console.log(key); }// 'name', 'age', 'city' 数组索引数组 类似python列表或者numpy的array。 1234// 直接创建var arr=[];// 用newvar arr=new Array(); 用索引来添加： 1234567// 如果添加没按顺序，则中间会被empty补位var empArray = [];empArray[0] = \"pis\";empArray[1] = \"2009\";empArray[3] = \"yyf\";console.log(empArray);// [\"pis\", \"2009\", empty, \"yyf\"] 通过arr.length赋值，可以达到缩容的目的。 关联数组 有点类似python的字典，用于描述对象。 123var bookInfo =[];bookInfo['bookName']='西游记';bookInfo['price']=35.5; 数组函数 String(arr)：转成字符串。 arr.join(“连接符”)：类似于python的join，语法稍有区别。 arr.concat()：拼接并返回新数组。 12345678var arr1=[90,91,92];var arr2=[80,81];var arr3=[70,71,72,73];var arr4=arr1.concat(50,60,arr2,arr3);console.log(arr1);// [90, 91, 92]console.log(arr4);// [90, 91, 92, 50, 60, 80, 81, 70, 71, 72, 73] arr.slice()：类似于切片。 省略第二个参数，相当于于python切片的：，选取到结尾；省略所有参数则是相当于复制数组。 123456789var arr1=[10,20,30,40,50];var arr2=arr1.slice(1,4); // [20, 30, 40]var arr3=arr1.slice(2);// [30, 40, 50]var arr4=arr1.slice(-4,-2);// [20, 30]console.log(arr1);// [10, 20, 30, 40, 50] arr.splice(i,n(,…))：删除arr中i位置开始的n个元素不考虑含头，直接修改原数组，返回值则会保存被删除元素组成的数组；如果加入后面的参数，则会在删除位置插入后面输入的元素，这样通过修改n可以达到不同目的，如n=0，则为插入效果，n与后面元素数字相等相当于替换效果。 1234567891011121314151617var arr1=[10,20,30,40,50];var arr2=arr1.splice(2,1); console.log(arr1);// [10, 20, 40, 50]console.log(arr2);// [30]var arr3=arr1.splice(2,2,21,22,23); var arr4=arr1.splice(2,2,[91,92,93]); console.log(arr1);// [10, 20, 21, 22, 23, 50]console.log(arr3);// [30, 40]console.log(arr1);// [10, 20, Array(3), 50]console.log(arr4);// [30, 40] arr.reverse()：颠倒数组顺序。 arr.sort()：排序，不过只能排字符串类型。 DOM DOM(document object model)，可以用于对网页增删改查。 查找 按id，var elem=document.getElementById(&quot;id&quot;)。 1234567&lt;ul id=\"myList\"&gt; &lt;li id=\"m1\"&gt;yyf&lt;/li&gt; &lt;li id=\"m2\"&gt;2009&lt;/li&gt; &lt;li id=\"m3\"&gt;pis&lt;/li&gt;&lt;/ul&gt;var ul=document.getElementById(\"myList\");console.log(ul); 按标签名，var elem=parent.getElementsByTagName(&quot;tag&quot;)，直接查找parent节点下所有标签为tag的子代节点，返回一个动态集合，就算只有一个也要用[0]来取出。 12345678&lt;ul id=\"myList\"&gt; &lt;li id=\"m1\"&gt;yyf&lt;/li&gt; &lt;li id=\"m2\"&gt;2009&lt;/li&gt; &lt;li id=\"m3\"&gt;pis&lt;/li&gt;&lt;/ul&gt;var ul=document.getElementById(\"myList\");var list=ul.getElementsByTagName(\"li\");console.log(list); 按name，var elem=document.getElementsByName(&quot;name&quot;)，返回所有子集合。 12345678&lt;form id=\"registerForm\"&gt; &lt;input type=\"checkbox\" name=\"boy\" /&gt; &lt;input type=\"checkbox\" name=\"boy\" /&gt; &lt;input type=\"checkbox\" name=\"boy\" /&gt;&lt;/form&gt;var list=document.getElementsByName(\"boy\");console.log(list);console.log(typeof list); 按class，var elem=parent.getElementsByClassName(&quot;class&quot;)。 12345678&lt;div id=\"news\"&gt; &lt;p class=\"mainTitle\"&gt;title1&lt;/p&gt; &lt;p class=\"subTitle\"&gt;title2&lt;/p&gt; &lt;p class=\"mainTitle\"&gt;title3&lt;/p&gt;&lt;/div&gt;var div=document.getElementById(\"news\");var list=div.getElementsByClassName(\"mainTitle\");console.log(list); 按CSS选择器： 只找一个元素：var elem=parent.querySelector(&quot;selector&quot;)，如果有多个也只返回一个，类似于bs4。 找多个：var elems=parent.querySelectorAll(&quot;selector&quot;)。 核心 读取属性值，有点类似bs4的操作： 123456// 先获得属性节点对象，再获得节点对象的值var attrNode=elem.attributes[下标/属性名];var attrNode=elem.getAttributeNode(属性名);attrNode.value; //属性值// 直接获得属性值var value=elem.getAttribute(\"属性名\"); 修改的时候，用set方法： 12var h1=document.getElementById(\"a1\");h1.setAttributeNode(\"name\",zhangji); 判断是否包含指定属性： 123var bool=elem.hasAttribute(\"属性名\");//e.g.document.getElementById(\"bt1\").hasAttribute(\"onclick\"); 移除属性： 12345elem.removeAttribute(\"属性名\");//e.g.&lt;a id=\"alink\" class=\"slink\" href=\"javascript:void(0)\" onlick=\"jump()\"&gt;百度搜索&lt;/a&gt;var a=document.getElementById(\"alink\");a.removeAttribute(\"class\") 修改样式： 1234567// 内联样式elem.style.属性名;// 强调属性名：去横线，变驼峰；// e.g.css:background-color=&gt;backgroundColor; list-style-type=&gt;listStyleType; 添加 创建空元素。 1234567var elem=document.createElement(\"元素名\");//e.g.var table=document.createElement(\"table\");var tr=document.createElement(\"tr\");var td=document.createElement(\"td\");var td=document.createElement(\"td\");console.log(table); 设置关键属性。 123a.innerHTML=\"yyfyyf123\";a.href=\"https://www.douyu.com/9999\";//&lt;a href=\"https://www.douyu.com/9999\"&gt;yyfyyf123&lt;/a&gt; 设置关键样式。 1234// 修改某一项a.style.opacity=\"1\";// 批量修改a.style.cssText=\"width:100px;height:100px\"; 将元素添加到DOM树，parentNode.appendChild(childNode)，可用于为一个父元素追加一个子节点。 1234var div=document.createElement(\"div\");var txt=document.createTextNode(\"版权说明\");div.appendChild(txt);document.body.appendChild(div); parentNode.insertBefore(newChild,existingChild)，用于在父元素中的指定子节点之前添加一个新的子节点。 1234567&lt;ul id=\"menu\"&gt; &lt;li&gt;首页&lt;/li&gt; &lt;li&gt;联系我们&lt;/li&gt;&lt;/ul&gt;var ul=document.getElementById(\"menu\");var newLi=document.createElement(\"li\");ul.insertBefore(newLi,ul.lastChild); 注意：尽量要少操作DOM树，避免每次重新layout。优化思路：1.如果同时创建父元素和子元素时，建议在内存中先将子元素添加到父元素，再讲父元素一次性挂到页面；2.如果只添加多个平级子元素时，就要将所有子元素临时添加到文档片段中，再将文档片段整体添加到页面。 1234567// 创建片段（相当于虚拟父元素）var frag=document.createDocumentFragment();// 将子元素临时追加到frag中frag.appendChild(child);// 将frag追加到页面parent.appendChild(frag);// append之后，frag自动释放，不会占用元素 BOM BOM(browser object model)，操作浏览器窗口，可能有兼容性问题。 基本 window：代表整个窗口。 1234// 获取当前窗口大小window.outerWidth/outerHeight;// 文档显示区大小window.innerWidth/innerHeight; history：封装当前窗口打开后，成功访问过的历史url记录。 navigator：封装浏览器配置信息。 document：封装当前正在加载的网页内容。 location：封装了当前窗口正在打开的url地址。 screen：封装了屏幕的信息。 event：定义了网页中的事件机制。 定时器周期性定时器 语法： setInterval(exp,time)：周期性触发代码exp。 exp：执行语句。 time：时间周期，单位为毫秒。 123setInterval(function()){ console.log(\"Rua!!!\");},1000); 停止定时器 给定时器取名： 123var timer=setInterval(function()){ console.log(\"Rua!!!\");},1000); 停止定时器： 1claerInterval(timer); 一次性定时器 让程序延迟一段时间运行，语法： setTimeout(exp,time)：一次性触发代码exp。 exp：执行语句。 time：间隔时间，单位为毫秒。 123setTimeout(function()){ alert(\"Rua!!!\");},3000); JQuery 类似于插件库，稍作了解。 概述工厂函数$()","link":"/2019/10/19/前端学习笔记/"}],"tags":[{"name":"Review","slug":"Review","link":"/tags/Review/"},{"name":"Unboxing","slug":"Unboxing","link":"/tags/Unboxing/"},{"name":"Earphone","slug":"Earphone","link":"/tags/Earphone/"},{"name":"Apple","slug":"Apple","link":"/tags/Apple/"},{"name":"AirPods","slug":"AirPods","link":"/tags/AirPods/"},{"name":"Gigabyte","slug":"Gigabyte","link":"/tags/Gigabyte/"},{"name":"Laptop","slug":"Laptop","link":"/tags/Laptop/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"Flask","slug":"Flask","link":"/tags/Flask/"},{"name":"Nintendo","slug":"Nintendo","link":"/tags/Nintendo/"},{"name":"Switch","slug":"Switch","link":"/tags/Switch/"},{"name":"Literature","slug":"Literature","link":"/tags/Literature/"},{"name":"Poetry","slug":"Poetry","link":"/tags/Poetry/"},{"name":"GEO","slug":"GEO","link":"/tags/GEO/"},{"name":"TCGA","slug":"TCGA","link":"/tags/TCGA/"},{"name":"R","slug":"R","link":"/tags/R/"},{"name":"StarBase","slug":"StarBase","link":"/tags/StarBase/"},{"name":"DESeq","slug":"DESeq","link":"/tags/DESeq/"},{"name":"STRING","slug":"STRING","link":"/tags/STRING/"},{"name":"miRanda","slug":"miRanda","link":"/tags/miRanda/"},{"name":"Histopathology","slug":"Histopathology","link":"/tags/Histopathology/"},{"name":"Cryostat","slug":"Cryostat","link":"/tags/Cryostat/"},{"name":"Leica","slug":"Leica","link":"/tags/Leica/"},{"name":"CM1860","slug":"CM1860","link":"/tags/CM1860/"},{"name":"Manual","slug":"Manual","link":"/tags/Manual/"},{"name":"Cheminformatics","slug":"Cheminformatics","link":"/tags/Cheminformatics/"},{"name":"MOE","slug":"MOE","link":"/tags/MOE/"},{"name":"Neurons","slug":"Neurons","link":"/tags/Neurons/"},{"name":"Nissl body","slug":"Nissl-body","link":"/tags/Nissl-body/"},{"name":"Staining","slug":"Staining","link":"/tags/Staining/"},{"name":"OpenBabel","slug":"OpenBabel","link":"/tags/OpenBabel/"},{"name":"Pybel","slug":"Pybel","link":"/tags/Pybel/"},{"name":"RDKit","slug":"RDKit","link":"/tags/RDKit/"},{"name":"NanoZoomer","slug":"NanoZoomer","link":"/tags/NanoZoomer/"},{"name":"Pathology","slug":"Pathology","link":"/tags/Pathology/"},{"name":"Machine Learning","slug":"Machine-Learning","link":"/tags/Machine-Learning/"},{"name":"Data Mining","slug":"Data-Mining","link":"/tags/Data-Mining/"},{"name":"Similarity","slug":"Similarity","link":"/tags/Similarity/"},{"name":"Euclidean distance","slug":"Euclidean-distance","link":"/tags/Euclidean-distance/"},{"name":"Manhattan distance","slug":"Manhattan-distance","link":"/tags/Manhattan-distance/"},{"name":"Pearson coefficient","slug":"Pearson-coefficient","link":"/tags/Pearson-coefficient/"},{"name":"Jaccard coefficient","slug":"Jaccard-coefficient","link":"/tags/Jaccard-coefficient/"},{"name":"Tanimoto coefficient","slug":"Tanimoto-coefficient","link":"/tags/Tanimoto-coefficient/"},{"name":"Game","slug":"Game","link":"/tags/Game/"},{"name":"RPG","slug":"RPG","link":"/tags/RPG/"},{"name":"Wuxia","slug":"Wuxia","link":"/tags/Wuxia/"},{"name":"Link","slug":"Link","link":"/tags/Link/"},{"name":"Writing","slug":"Writing","link":"/tags/Writing/"},{"name":"Experiment","slug":"Experiment","link":"/tags/Experiment/"},{"name":"Pytesseract","slug":"Pytesseract","link":"/tags/Pytesseract/"},{"name":"Fiddler","slug":"Fiddler","link":"/tags/Fiddler/"},{"name":"Efficiency","slug":"Efficiency","link":"/tags/Efficiency/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"KNN","slug":"KNN","link":"/tags/KNN/"},{"name":"Visual novel","slug":"Visual-novel","link":"/tags/Visual-novel/"},{"name":"Lattice resoning","slug":"Lattice-resoning","link":"/tags/Lattice-resoning/"},{"name":"Galgame","slug":"Galgame","link":"/tags/Galgame/"},{"name":"AVG","slug":"AVG","link":"/tags/AVG/"},{"name":"Association Analysis","slug":"Association-Analysis","link":"/tags/Association-Analysis/"},{"name":"FP-growth","slug":"FP-growth","link":"/tags/FP-growth/"},{"name":"English","slug":"English","link":"/tags/English/"},{"name":"Word","slug":"Word","link":"/tags/Word/"},{"name":"Daily life","slug":"Daily-life","link":"/tags/Daily-life/"},{"name":"Detective story","slug":"Detective-story","link":"/tags/Detective-story/"},{"name":"Penetralium","slug":"Penetralium","link":"/tags/Penetralium/"},{"name":"Apriori","slug":"Apriori","link":"/tags/Apriori/"},{"name":"HTML","slug":"HTML","link":"/tags/HTML/"},{"name":"CSS","slug":"CSS","link":"/tags/CSS/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"Monthly","slug":"Monthly","link":"/tags/Monthly/"}],"categories":[{"name":"负尽年华","slug":"负尽年华","link":"/categories/负尽年华/"},{"name":"生活记录","slug":"生活记录","link":"/categories/生活记录/"},{"name":"学习笔记","slug":"学习笔记","link":"/categories/学习笔记/"},{"name":"诗词遗珠","slug":"诗词遗珠","link":"/categories/诗词遗珠/"},{"name":"心得体会","slug":"心得体会","link":"/categories/心得体会/"},{"name":"缓寻芳草","slug":"缓寻芳草","link":"/categories/缓寻芳草/"},{"name":"不务正业","slug":"不务正业","link":"/categories/不务正业/"}]}