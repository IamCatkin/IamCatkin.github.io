<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一个生信挖掘的DEMO]]></title>
    <url>%2F2020%2F01%2F17%2F%E4%B8%80%E4%B8%AA%E7%94%9F%E4%BF%A1%E6%8C%96%E6%8E%98%E7%9A%84DEMO%2F</url>
    <content type="text"><![CDATA[起源是海洋师兄让我复现一个公司做的生信分析，据说这样一个东西收费1w+，于是我开始尝试进行探索。 分析GEO数据miRNA表达情况 GSE106452是4种肝癌细胞的外泌体miRNA的微阵列分析数据，我们由于只有HepG2细胞，因此只拿该细胞数据，挑选表达较高的30个miRNA数据。甚至都用不到Python和R，Excel排序即可。 点评：开始俺还以为得用GEO2R做差异分析，事实上是俺想复杂了。 TCGA差异分析TCGA数据下载选择数据 访问GDC，在Cases里的Project选择TCGA-LIHC，Files里的Data Category选择transcriptome profiling，如果需要下载临床资料，类似地，Data Category选择Clinical即可。 原始方法 如果大小不超过50M，可以点击右边的Add All Files to Cart，然后再右上角的Cart里面选择Download即可下载。 使用GDC Data Transfer Tool 下载GDC Data Transfer Tool，并配置环境变量。 在之前的页面Data Category选择transcriptome profiling，Experimental Strategy选择RNA-Seq，然后在右边选择下载Manifest，文件命名为gdc_manifest.2020-01-17-LIHC-RNA-Seq.txt，此外Experimental Strategy选择miRNA-Seq，Data Type分别选择miRNA Expression Quantification和Isoform Expression Quantification分别得到另外两个文件gdc_manifest.2020-01-17-LIHC-miRNA-Seq.txt和gdc_manifest.2020-01-17-LIHC-miRNA-Isoform.txt。类似地，Data Category选择Clinical，Data Format选择bcr xml即可获取gdc_manifest.2020-01-17-LIHC-Clinical.txt。 新建一个LIHC文件夹，将上述Manifest拷进去，CMD下输入gdc-client download -m gdc_manifest.2020-01-17-LIHC-Clinical.txt -d Clinical/ --log-file Clinical.log即可下载临床数据，其他的操作同理。不过无力吐槽这个网络可连接性，下载起来比登天还难。 这里我采用了分割文件&amp;挂代理的策略才把RNA数据下完。 console下设置代理：set https_proxy=http://127.0.0.1:10809。 数据处理Clinical数据合并 主要是xml文件，利用R包来分析。以单个文件为例： 1234567library("XML")library("methods")result = xmlParse(file="D:/Bioinformatics/TCGA/LIHC/Clinical/00a9a7f4-06eb-40fb-8d3a-66f5f5d315f7/nationwidechildrens.org_clinical.TCGA-KR-A7K0.xml")rootnode = xmlRoot(result)rootsize = xmlSize(rootnode)xmldataframe = xmlToDataFrame(rootnode[2])write.table(t(xmldataframe),'tmp') 当然具体数据有成百上千个，应该用循环来做。 1234567891011library("XML")library("methods")dir = "D:/Bioinformatics/TCGA/LIHC/Clinical/"cl = lapply(list.files(path=dir,pattern="*.xml$",recursive=T),function(x)&#123; result = xmlParse(file=file.path(dir,x)) rootnode = xmlRoot(result) xmldataframe = xmlToDataFrame(rootnode[2]) return(t(xmldataframe))&#125;)cl_df = t(do.call(cbind,cl))save(cl_df,file="D:/Bioinformatics/TCGA/LIHC/Rdata/GDC_TCGA_LIHC_clinical_df.Rdata") miRNA-Seq数据合并 类似地，修改处理代码如下： 123456789dir = "D:/Bioinformatics/TCGA/LIHC/miRNA-Seq/"mi = lapply(list.files(path=dir,pattern="*.mirnas.quantification.txt$",recursive=T),function(x)&#123; result = read.table(file=file.path(dir,x),sep="\t",header=T)[,1:2] return(result)&#125;)mi_df = t(do.call(cbind,mi))colnames(mi_df) = mi_df[1,]mi_df = mi_df[seq(2,nrow(mi_df),by=2),]save(mi_df,file="D:/Bioinformatics/TCGA/LIHC/Rdata/GDC_TCGA_LIHC_miRNA-Seq_df.Rdata") 这样可以得到一个表达矩阵。]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>GEO</tag>
        <tag>TCGA</tag>
        <tag>R</tag>
        <tag>StarBase</tag>
        <tag>DESeq</tag>
        <tag>STRING</tag>
        <tag>miRanda</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019年末的碎碎念]]></title>
    <url>%2F2019%2F12%2F31%2F2019%E5%B9%B4%E6%9C%AB%E7%9A%84%E7%A2%8E%E7%A2%8E%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[好久没写正经文字了，读书也是断断续续的，来点流水账总结一下吧。 概述 总的来说，2019算是平淡的一年，就算是3、4月份的那段经历也差不多在我意料之中。这种波澜不惊的生活虽然并非我所愿，也所幸没有超出我承受范围的事件。 生活 上半年经历的外放大概还是挺开心的，特别是现在长沙的鬼天气让我尤为怀念深圳的气候，更怀念的是那种不用考虑任何杂事，只用做手中活的那种状态，本社恐还是很难习惯和人打交道。 略遗憾的是并没有去很多地方玩，香港去了几次，后面由于众所周知的的原因，也没机会再去那边玩了，想去的海洋公园终究也没去成，也没能和文同学碰面。不过和菜神终于面基成功，说起来也认识好多年了，在本科都没机会见面，没想到多年以后还能在深圳相见。五一一块去了香港，那天也算是我在香港体验最好的一天了。 抽空见了一次发小，从小在一起长大的交情，随着这些年的距离和圈子的变化，感觉也变的生分很多，看着他在深圳混的很好，又想着我现在的状态，还是略惆怅的。可能是我不太擅长维护友情吧，今年还失去了一个朋友，想想就更难过了。 学习 作为一条咸鱼，自律学习对我来说还是难度太大了。说到底也是因为我2、3月学习不认真才会有现在的境地。Python和机器学习已经进入吃老本状态了，被老弟拍死在沙滩上。Java从入门到放弃，JavaScript也停滞不前，希望明年能抽空搞定Vue或React吧。 科研方向上毫无进展，从之前的PPIs到肝癌样本再到HIF1-α，方向一直在换，现在又变成MSCs了，感觉老板对我很不满意了，明年的重点就是好好读文献，目标能做出预实验。 所谓生活不如意，开始记单词。由于多年以后又遭6级的毒打和转博无望，决心好好学英语，再不济也得刷个6级分数吧，从明天开始背。 娱乐 年纪大了精力就十分有限，几年前从来没想过我居然还有不玩DOTA的时候，转眼间上次玩都可以追溯到过年了。 小说 今年看的小说数目极其有限，其中我觉得有意思的有：《首无·作祟之物》、《密室收藏家》、《水母不会冻结》、《尸人庄谜案》，不分先后。 电影/电视剧 这两年日剧/日影基本上没有能提起我兴趣的，除了惯例要看的《世界奇妙物语》，唯一让我有兴趣追完的日剧唯有《轮到你了》，结果还虎头蛇尾。不过补了一点老剧，《古畑任三郎》意外的惊喜。 电影方面，今年上映的电影个人喜好度排名：《海市蜃楼》、《 复仇者联盟4:终局之战 》、《调音师》、《流浪地球》、《飞驰人生》。此外，其他渠道看的电影这几部我也觉得不错：《大河恋》、《岁月神偷》、《一一》、《我们天上见》、《和莎莫的500天》、《她》。草，真的是雅俗皆赏。 游戏 游戏方面，虽然鉴于碎片时间玩了2个垃圾手游过渡了一下，但还是以单机游戏为主。今年居然几乎没玩PC上的游戏，除了开年的《隐形守护者》，出于对《潜伏之赤途》的好感体验了一下，意外的感觉还不错，然后居然就没有特别能让我感兴趣的PC单机了，希望明年可以体验一下《极乐迪斯科》。 Switch方面，嫖了老弟的《塞尔达传说：旷野之息》，确实名不虚传，《AI：梦境档案》略有失望，觉得可以更好玩。此外，《宝可梦：盾》真香。最后，期待一下明年能有好的推理作。 最后 希望明年能开开心心。祝能看到本文的朋友们工作顺利/早日毕业。]]></content>
      <categories>
        <category>负尽年华</category>
      </categories>
      <tags>
        <tag>Review</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一些可能有用的网站]]></title>
    <url>%2F2019%2F12%2F12%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E4%BA%9B%E5%8F%AF%E8%83%BD%E6%9C%89%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[存链接用，图文无关 学习综合Medium：美国的一个内容平台，有些类似中国的简书。对于一些不懂的技术可能会在上面找到科普。 机器学习Papers with Code：上面可以找到一些机器学习的论文，优点是代码也一并提供了，方便从代码中体会。 写作LaTeXOverleaf：在线LaTeX写作，如果不想在本地安装巨大的TeXLive并配置TeX写作环境的话这个网站提供了一个可靠的解决方案。 近义词替换Thesaurus：输入词语即可找到该词的近义词，用不同程度的橙色显示。 短语搭配Academic Phrasebank：提供了一些学术报告中的常用搭配，比如描述趋势、数量变化等。 Ludwig：整句的搜索引擎，可以从可靠的资源库通常是一些专业的英文网站的文章里来找符合语境的表达。 Linggle：找正确搭配的网站，对于一些介词的使用可以看大部分人是如何选择的。 润色Grammarly ：名气很大的语法校正网站，不过貌似是收费的，反正俺没试过。 微软爱写作：微软出品的写作检查网站，需要微信扫码注册，大致瞄了眼感觉很不错。 Hemingway Editor：用来检查有问题的词句，如过于冗长、用词错误和重复等。 NounPlus：对语法拼写错误会注释并给出建议，目前没测试是否好用。 画图配色Colorgorical：用来生成配色，看起来不明觉厉。 实验细胞小鼠原代肝细胞protocol：提供了小鼠原代肝细胞分离培养的详细步骤，还非常贴心地附上了Q&amp;A、图片和小视频，此外他还提供了一些肝细胞代谢实验的详细步骤 ，对于初次涉及这个实验的是一个很好的入门教程。]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Link</tag>
        <tag>Writing</tag>
        <tag>Experiment</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Flask学习笔记]]></title>
    <url>%2F2019%2F11%2F14%2FFlask%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Django有点繁琐，俺打算转战Flask了。 初始化安装 在虚拟环境下安装。 12conda create -n flaskconda install flask Hello，Flask Flask 类的构造函数只有一个必须指定的参数，即程序主模块或包的名字。在大多数程序中，Python 的__name__变量就是所需的值。 12from flask import Flaskapp = Flask(__name__) 以上即为一个最简单的实例创建。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数字切片扫描仪操作流程]]></title>
    <url>%2F2019%2F11%2F13%2F%E6%95%B0%E5%AD%97%E5%88%87%E7%89%87%E6%89%AB%E6%8F%8F%E4%BB%AA%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[理由同上上。 步骤开启设备设备通电 先开电脑，再开扫描仪。 开启软件 运行桌面的NDP.Scan程序，初始化后选择扫描模式，即单张模式或批量模式。 放置切片 稍用力向里推压切片舱门，使舱门弹出。 标签向上，盖玻片向外放入切片槽。 开始扫描单张模式 选择模式，点击载入切片。 输入文件名。 如有需要，手动调整区域。 如有需要，手动调整聚焦位置。 开始扫描。 扫描完成后可以浏览图像。 批量模式 大部分与单张模式一样，值得注意的是输入文件名，可以在Excel或记事本中预设文件名，然后载入。 图像操作 通过NDP.View2操作，可以根据需要缩放、拖动、放大、添加标注以及截图输出，也可以调节图片的γ值、亮度、对比度及锐化程度。]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Manual</tag>
        <tag>NanoZoomer</tag>
        <tag>Pathology</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[尼氏染色操作流程]]></title>
    <url>%2F2019%2F10%2F25%2F%E5%B0%BC%E6%B0%8F%E6%9F%93%E8%89%B2%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[理由同上。 原理 尼氏染色法(Nissl Staining)是用碱性染料染神经组织的一种方法。尼氏体是胞质内的一种嗜碱性物质，广泛见于各种神经元，不同神经元中的尼氏体形状、大小和数量则各有差异。用于尼氏染色的碱性染料主要有焦油紫、亚甲蓝、甲苯胺蓝和硫堇等。尼氏染色法可以染出尼氏体，用来观察神经元内的细胞结构；还可以通过尼氏染色后对尼氏体的观察来了解神经元的损伤情况 。 步骤 不同老师有方法略有区别，我们以熊鲲老师的方法为例。 将处理好的样本放入尼氏染色液，时间可根据切片厚度等，结合染色情况调整，一般在10分钟-30分钟左右。 蒸馏水洗涤数次，每次几秒。 用无水乙醇分色，每次浸入几秒拿出观察脱色情况，到变蓝或者浅紫色为止。 轻磕载玻片，将水甩干，注意避免组织被甩掉，时间允许则风干。 用无水乙醇脱水3分钟。 （水洗，并甩干）。 二甲苯脱脂3-5分钟。 换新鲜二甲苯再脱脂3-5分钟。 封片：用棉签屁股挑去少许中性树脂到盖玻片上，手持载玻片压下去，注意避免气泡产生。如果产生，可以将气泡挤出。 观察染色情况。]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Manual</tag>
        <tag>Neurons</tag>
        <tag>Nissl body</tag>
        <tag>Staining</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[冰冻切片机操作流程]]></title>
    <url>%2F2019%2F10%2F22%2F%E5%86%B0%E5%86%BB%E5%88%87%E7%89%87%E6%9C%BA%E6%93%8D%E4%BD%9C%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[由于要交一份电子版，所以修改一下顺便传上来了。 目的 为什么要做冰冻切片而不是石蜡切片，因为冰冻切片相对于石蜡切片相对简便快速，用时短， 多应用于手术中的快速病理诊断 ，缺点是不利于持久保存。 步骤开机 使用前最少2小时，按右侧电源键开机。但在实际情况下，一般为待机状态，长按待机键解除待机状态。 预冷 调节温度至-25℃，将刀片刷子样品等提前放进去预冷。等待仪器降至所需温度。 固定刀片及样品 在样本托上滴点蒸馏水，用来固定样品，如有需要可用蓝色速冻台降温，冷冻后将其固定在切片机样本头上。一般不需要动刀座的锁紧杆，只需要打开刀片的锁紧杆放入刀片。注意使用仪器左侧控制面板上的样本后退按键，将样本头调到最后方，防止安装样本时撞坏防卷板、刀片等 调节切片厚度 一般调节切片厚度为15或20μm，小心控制仪器的样本推进按键，使样本向刀架方向前进直到刀片快要接触样本时，此时再换用手轮控制。 切片 打开手轮柄锁，顺时针均力旋转手轮一圈，切好后将手轮锁定在12点位置，即样本头移动在最高位置以便于取出切片，掀开防卷板，用常温的针管弯头将切片粘附放入常温放置的蒸馏水或者PBS中，再用带毛针管头小心贴片。当然也有用常温载玻片往样本上靠的方法。如果刀上或防卷板粘有脏东西，用预冷过的刷子顺着刀刃方向刷干净。 清理 切片结束后收好刀片，锁定手轮，用冰冻台里面的刷子扫除多余组织碎片并清理出去，较小组织可以用常温放置的卫生纸擦拭。注意不能用水擦拭，应当用无水乙醇。 关机 一般情况下因为要经常使用，可不必关闭电源。用完将温度调到-10℃，然后长按待机键使时间中间的：消失，即为进入待机状态。 其他注意事项 环境温度应该在20℃下进行。 防卷板轻拿轻放，避免损坏。 切片完毕收好刀片，锁死手轮锁。 其他已设参数勿动，一般只调整切片厚度。 应保持切片机及周围区域清洁，机外废水壶满应及时倒掉。]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Histopathology</tag>
        <tag>Cryostat</tag>
        <tag>Leica</tag>
        <tag>CM1860</tag>
        <tag>Manual</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端学习笔记]]></title>
    <url>%2F2019%2F10%2F19%2F%E5%89%8D%E7%AB%AF%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[平生不学WEB，便称编程也枉然 ！ HTML HTML（HyperText Markup Language）是一种标记语言以便于浏览器正确展示网页给用户。HTML使用标签（tags）来区分用户所能看到的内容和便于浏览器解释的指示。 基础 常见的IDE比如 Sublime、 VS code都支持一些智能生成HTML代码，简化输入。 用于生成一个html页面，包含head和body。 1&gt;&gt;&gt;! 通过输入标签名快速生成代码块，同理也可以输入h1、img、a等。 12&gt;&gt;&gt;p&lt;p&gt;&lt;/p&gt; 输入标签*数字可以快速生成多个同级标签。 1234&gt;&gt;&gt;p*3&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt; 也可以用加号连接标签名达到快速生成的目的。 123&gt;&gt;&gt;h1+p&lt;h1&gt;&lt;/h1&gt;&lt;p&gt;&lt;/p&gt; &gt;代表次级，用于快速生成嵌套结构。 123&gt;&gt;&gt;p*2&gt;img+a&lt;p&gt;&lt;img src="" alt=""&gt;&lt;a href=""&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="" alt=""&gt;&lt;a href=""&gt;&lt;/a&gt;&lt;/p&gt; 用括号可以生成分组标签。 12345&gt;&gt;&gt;(div&gt;p)+(div&gt;img)&lt;div&gt; &lt;p&gt;&lt;/p&gt;&lt;/div&gt;&lt;div&gt;&lt;img src="" alt=""&gt;&lt;/div&gt; 生成带id或者class的标签 123456&gt;&gt;&gt;div#nav&lt;div id="nav"&gt;&lt;/div&gt;&gt;&gt;&gt;div.bar&lt;div class="bar"&gt;&lt;/div&gt;&gt;&gt;&gt;div#nav.bar&lt;div id="nav" class="bar"&gt;&lt;/div&gt; 标签后面用中括号可以快速添加属性。 12&gt;&gt;&gt;img[src=logo.jpg]&lt;img src="logo.jpg" alt=""&gt; 标签后面用大括号可以快速添加段落内容。 12&gt;&gt;&gt;p&#123;峰哥牛逼&#125;&lt;p&gt;峰哥牛逼&lt;/p&gt; lorem用于快速生成文本。 1234&gt;&gt;&gt;loremLorem ipsum dolor sit amet consectetur adipisicing elit...&gt;&gt;&gt;lorem4Lorem ipsum dolor sit. 标签标题 HTML 标题（Heading）是通过h1 - h6 等标签进行定义的。 1234&lt;h1&gt;这是一级标题&lt;/h1&gt;&lt;!-- 一级标题一般只设一个 --&gt;&lt;h2&gt;这是二级标题&lt;/h2&gt;&lt;h3&gt;这是三级标题&lt;/h3&gt; 段落 HTML 段落通过p标签进行定义。&nbsp; 123456&lt;p&gt;这是段落&lt;/p&gt;&lt;!-- 段落里多个空格会合并为1个空格，因此可以使用&amp;nbsp;来替代 --&gt;&lt;!-- 段落里换行会被忽略，显示为空格，如果要换行用&lt;br /&gt; --&gt;&lt;!-- 使用&lt;hr /&gt;来添加水平线 --&gt;&lt;span&gt;段内分组，方便用CSS来修改样式&lt;/span&gt;&lt;pre&gt;预排版标签，以便于保留段内空格、换行等格式&lt;/pre&gt; 超链接 超链接通过a标签进行定义。 1234567&lt;a href="网址"&gt;文字或图片&lt;/a&gt;&lt;!-- 连接到本站点其他网页 --&gt;&lt;a href="news.html"&gt;新闻&lt;/a&gt;&lt;!-- 连接到其他站点 --&gt;&lt;a href="https://www.baidu.com/"&gt;百度&lt;/a&gt;&lt;!-- 虚拟超链接 --&gt;&lt;a href="#"&gt;版块&lt;/a&gt; 图片 图片通过img标签进行定义。 12&lt;img src="w3school.gif" alt="w3c" /&gt;&lt;!-- alt即为图片替代名字，在未加载出来显示 --&gt; 块 块通过div标签进行定义，用于确定一个单独的区域，如页面的一个组成部分、一个栏目版块。 div元素没有特定的含义。除此之外，由于它属于块级元素，浏览器会在其前后显示折行。 如果与 CSS 一同使用，div元素可用于对大的内容块设置样式属性。 列表 无序列表ul，有序列表ol，列表项li。 12345&lt;ul&gt; &lt;li&gt;项目1&lt;/li&gt; &lt;li&gt;项目2&lt;/li&gt; &lt;li&gt;项目3&lt;/li&gt;&lt;/ul&gt; 项目1 项目2 项目3 12345&lt;ol&gt; &lt;li&gt;项目1&lt;/li&gt; &lt;li&gt;项目2&lt;/li&gt; &lt;li&gt;项目3&lt;/li&gt;&lt;/ol&gt; 项目1 项目2 项目3 表格 表格table， 每个表格均有若干行（由 tr标签定义），每行被分割为若干单元格（由 td标签定义）。字母td指表格数据（table data），即数据单元格的内容。数据单元格可以包含文本、图片、列表、段落、表单、水平线、表格等等。 123456789101112&lt;table border="1"&gt;&lt;!-- border定义边框粗细 --&gt; &lt;tr&gt; &lt;td&gt;row 1, cell 1&lt;/td&gt; &lt;td&gt;row 1, cell 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 2, cell 1&lt;/td&gt; &lt;td&gt;row 2, cell 2&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;!-- table&gt;tr*2&gt;td*2 --&gt; row 1, cell 1 row 1, cell 2 row 2, cell 1 row 2, cell 2 123456789101112131415&lt;!-- 表头使用th标签,即将上表修改如下 --&gt;&lt;table border="1"&gt; &lt;tr&gt; &lt;th&gt;title1&lt;/th&gt; &lt;th&gt;title2&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 1, cell 1&lt;/td&gt; &lt;td&gt;row 1, cell 2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;row 2, cell 1&lt;/td&gt; &lt;td&gt;row 2, cell 2&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; title1 title2 row 1, cell 1 row 1, cell 2 row 2, cell 1 row 2, cell 2 如果有空格子，使用`&nbsp;`占位，避免不显示边框 表单 HTML 表单用于搜集不同类型的用户输入，用form来表示。 input 通过改变type属性，可以得到不同input形态。action属性定义在提交表单时执行的动作，通常为提交的url地址，缺省则为当前页面。 12345678&lt;!-- text/password --&gt;&lt;form&gt; 账户: &lt;input type="text" name="userName" /&gt; &lt;br /&gt; 密码: &lt;input type="password" name="userPsd" /&gt;&lt;/form&gt; 账户: 密码: 1234567&lt;!-- submit/reset --&gt;&lt;form&gt; 姓名: &lt;input type="text" value="" name="myName" /&gt; &lt;input type="submit" value="提交" name="submitBtn" /&gt; &lt;input type="reset" value="重置" name="resetBtn" /&gt;&lt;/form&gt; 姓名: 123456789101112&lt;!-- radio/checkbox --&gt;&lt;form&gt; 性别： 男&lt;input type="radio" value="boy" name="gender" checked="checked" /&gt; 女&lt;input type="radio" value="girl" name="gender" /&gt; &lt;br /&gt; 爱好： &lt;input type="checkbox" value="music" name="music" checked="checked" /&gt;音乐 &lt;input type="checkbox" value="sport" name="sport" /&gt;体育 &lt;input type="checkbox" value="reading" name="reading" /&gt;阅读&lt;/form&gt; &lt;!-- checked属性设置成"checked"，该选项默认为选中 --&gt; 性别： 男 女 爱好： 音乐 体育 阅读 123456789101112131415&lt;!-- &lt;datalist&gt;元素为&lt;input&gt;元素规定预定义选项列表。 --&gt;&lt;!-- 用户会在他们输入数据时看到预定义选项的下拉列表。 --&gt;&lt;!-- &lt;input&gt; 元素的 list 属性必须引用 &lt;datalist&gt; 元素的 id 属性。 --&gt;&lt;form&gt; &lt;input list="选择你的浏览器："&gt; &lt;datalist id="browsers"&gt; &lt;option value="Internet Explorer"&gt; &lt;option value="Firefox"&gt; &lt;option value="Chrome"&gt; &lt;option value="Opera"&gt; &lt;option value="Safari"&gt; &lt;/datalist&gt; &lt;input type="submit" value="提交" name="submitBtn" /&gt; &lt;input type="reset" value="重置" name="resetBtn" /&gt;&lt;/form&gt; select select元素定义下拉列表。 12345678910&lt;!-- select --&gt;&lt;form&gt; 爱好： &lt;select&gt; &lt;option&gt;唱&lt;/option&gt; &lt;option selected="selected"&gt;跳&lt;/option&gt; &lt;option&gt;rap&lt;/option&gt; &lt;option&gt;篮球&lt;/option&gt; &lt;/select&gt;&lt;/form&gt; 爱好： 看书 旅游 运动 购物 textarea textarea元素定义多行输入字段（文本域）。 12345678910&lt;!-- textarea --&gt;&lt;form&gt; 个人简介：&lt;br /&gt; &lt;textarea cols="50" rows="10"&gt; 在这里输入内容... &lt;/textarea&gt; &lt;br /&gt; &lt;input type="submit" value="提交" name="submitBtn" /&gt; &lt;input type="reset" value="重置" name="resetBtn" /&gt;&lt;/form&gt; 个人简介： 在这里输入内容... button button元素定义多行输入字段（文本域）。 1234&lt;!-- button --&gt;&lt;form&gt; &lt;button type="button" onclick="alert('峰哥牛逼')"&gt;点我&lt;/button&gt; &lt;/form&gt; 点我 语义化 语义化就是指让网页的含义更加明确，用于清楚地向浏览器和开发者描述其意义。 非语义元素的例子：div和 span - 无法提供关于其内容的信息。 语义元素的例子：form、table以及 img - 清晰地定义其内容。 下面列出了以字母顺序排列的 HTML5 新语义元素。 标签 描述 article 定义文章。 aside 定义页面内容以外的内容。 details 定义用户能够查看或隐藏的额外细节。 figcaption 定义 figure元素的标题。 figure 规定自包含内容，比如图示、图表、照片、代码清单等。 footer 定义文档或节的页脚。 header 规定文档或节的页眉。 main 规定文档的主内容。 mark 定义重要的或强调的文本。 nav 定义导航链接。 section 定义文档中的节。 summary 定义 details 元素的可见标题。 time 定义日期/时间。 强调 em和i用于斜体，strong和b用于加粗。但是前者有语义，后者没有。 自定义列表 自定义列表dl，列表项dt，描述dd。 123456&lt;dl&gt; &lt;dt&gt;HTML&lt;/dt&gt; &lt;dd&gt;超文本标记语言&lt;/dd&gt; &lt;dt&gt;CSS&lt;/dt&gt; &lt;dd&gt;层叠样式表&lt;/dd&gt;&lt;/dl&gt; HTML 超文本标记语言 CSS 层叠样式表 CSS CSS 指层叠样式表 (Cascading Style Sheets)，样式定义如何显示 HTML 元素，通常存储在样式表中，它的出现，是为了解决内容与表现分离的问题，可以极大提高工作效率。外部样式表通常存储在 CSS 文件中，多个样式定义可层叠为一。 基础 在IDE中，可以通过快捷的方式生成样式结构。 生成css的link。 12&gt;&gt;&gt;link:css&lt;link rel="stylesheet" href="style.css"&gt; 常见css缩写： 12345678910111213/* 在css框内输 */&gt;&gt;&gt;w30width: 30px;&gt;&gt;&gt;h30height: 30px;&gt;&gt;&gt;mg10margin: 10px;&gt;&gt;&gt;pd5padding: 5px;&gt;&gt;&gt;lh2emline-height: 2em;&gt;&gt;&gt;bgcbackground-color: #fff; 语法 以下为一个css样式，p为选择器，即选择哪个标签添加样式。为了方便易读，每行代码最好写在一个新行。 12345p&#123; font-size:12px; /*字号*/ color:blue; /*文本颜色*/ font-weight:bold; /*加粗*/&#125; 创建内联样式 由于要将表现和内容混杂在一起，内联样式会损失掉样式表的许多优势。请慎用这种方法，例如当样式仅需要在一个元素上应用一次时。 要使用内联样式，你需要在相关的标签内使用样式（style）属性。Style 属性可以包含任何 CSS 属性。本例展示如何改变段落的颜色： 123&lt;p style="color:red;"&gt; 我不会CSS&lt;/p&gt; 我不会CSS 内部样式 当单个文档需要特殊的样式时，就应该使用内部样式表。你可以使用 style标签在文档头部定义内部样式表，就像这样: 123456789101112131415&lt;!doctype html&gt;&lt;html&gt;&lt;head&gt; &lt;style type="text/css"&gt; p[type="css_Demo"]&#123; color:red; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;p type="css_Demo"&gt; 我不会CSS &lt;/p&gt;&lt;/body&gt;&lt;/html&gt; p[type="css_Demo"]{ color:red; } 我不会CSS 这里使用了属性和值选择器，关于选择器，具体后面再提。 外部样式 当样式需要应用于很多页面时，外部样式表将是理想的选择。在使用外部样式表的情况下，你可以通过改变一个文件来改变整个站点的外观。每个页面使用link 标签链接到样式表。link标签在（文档的）头部，例如： 123&lt;head&gt; &lt;link rel="stylesheet" type="text/css" href="mystyle.css" /&gt;&lt;/head&gt; 浏览器会从文件 mystyle.css 中读到样式声明，并根据它来格式文档。 外部样式表可以在任何文本编辑器中进行编辑。文件不能包含任何的 html 标签。样式表应该以 .css 扩展名进行保存。 123p&#123; color:red;&#125; 这样对于多个页面，就能通过链接进行样式设定，方便维护。 多重样式 如果某些属性在不同的样式表中被同样的选择器定义，那么属性值将依赖于就近原则。简而言之，优先级内联样式&gt;内部样式&gt;外部样式。 例如，外部样式表拥有针对 h3 选择器的三个属性： 12345h3 &#123; color: red; text-align: left; font-size: 8pt; &#125; 而内部样式表拥有针对 h3 选择器的两个属性： 1234h3 &#123; text-align: right; font-size: 20pt; &#125; 假如拥有内部样式表的这个页面同时与外部样式表链接，那么 h3 得到的样式是： 12345h3 &#123; color: red; text-align: right; font-size: 20pt; &#125; 即颜色属性将被继承于外部样式表，而文字排列（text-alignment）和字体尺寸（font-size）会被内部样式表中的规则取代。 选择器标签选择器 以下面为例，通过body，h1，p，hr这些标签名来定义相应的CSS。 12345678910111213141516171819202122&lt;style type="text/css"&gt; body&#123; background-color: #ccc; text-align: center; font-size: 12px; &#125; h1&#123; font: "黑体"; font-size: 20px; &#125; p&#123; color: red; font-size: 16px; &#125; hr&#123;width: 200px;&#125;&lt;/style&gt;&lt;body&gt; &lt;h1&gt;标题&lt;/h1&gt; &lt;hr&gt; &lt;p&gt;正文段落&lt;/p&gt; 版权所有&lt;/body&gt; 类别选择器 CSS中，类别选择器用一个.显示。 123456789101112&lt;style type="text/css"&gt; p&#123;font-size: 12px;&#125; .one&#123;font-size: 18px;&#125; .two&#123;font-size: 24px;&#125;&lt;/style&gt;&lt;body&gt; &lt;p class="one"&gt;类别1&lt;/p&gt; &lt;p class="one"&gt;类别1&lt;/p&gt; &lt;p class="two"&gt;类别2&lt;/p&gt; &lt;p class="two"&gt;类别2&lt;/p&gt; &lt;p&gt;正文段落&lt;/p&gt;&lt;/body&gt; ID选择器 CSS中，ID选择器用一个#号显示。与类别选择器不同之处在于，它具有唯一性。 12345678&lt;style type="text/css"&gt; #one&#123;font-size: 12px;&#125; #two&#123;font-size: 24px;&#125;&lt;/style&gt;&lt;body&gt; &lt;p id="one"&gt;ID1&lt;/p&gt; &lt;p id="two"&gt;ID2&lt;/p&gt;&lt;/body&gt; 嵌套声明 根据文档的上下文关系来确定某个标签的样式。 123456&lt;style type="text/css"&gt; p span&#123;color: green;&#125;&lt;/style&gt;&lt;body&gt; &lt;p&gt;法国男兵法国女兵都是&lt;span&gt;法国士兵&lt;/span&gt;。&lt;/p&gt;&lt;/body&gt; 集体申明 用逗号将所有需要申明的选择器分开，这样可以分享相同的声明。 12345678910&lt;style type="text/css"&gt; h1,p&#123; color: green; text-align:center; &#125;&lt;/style&gt;&lt;body&gt; &lt;h1&gt;峰哥牛逼&lt;/h1&gt; &lt;p&gt;黄浦江之王！&lt;/p&gt;&lt;/body&gt; 全局申明 用*表示所有标签均应用申明。 1234567891011&lt;style type="text/css"&gt; *&#123; color: green; text-align:center; &#125;&lt;/style&gt;&lt;body&gt; &lt;h1&gt;峰哥牛逼&lt;/h1&gt; &lt;p&gt;黄浦江之王！&lt;/p&gt; &lt;h2&gt;不服的沉了！&lt;/h2&gt;&lt;/body&gt; 样式文本 CSS 文本属性可定义文本的外观。 单位 单位 描述 px 像素 em 字符，自动适应用户所使用的字体 % 百分比，继承自DOM树上一级 颜色 颜色 描述 red,blue,green CSS颜色名 rgb(x,x,x) RGB值，每个参数 (red、green 以及 blue) 定义颜色的强度，可以是介于 0 与 255 之间的整数 rgb(x%,x%,x%) RGB百分比值，取值介于0%到100% rgba(x,x,x,x) 是 RGB 颜色值的扩展，带有一个 alpha 通道 - 它规定了对象的不透明度，介于0.0（完全透明）与1.0（完全不透明）之间 #rrggbb 十六进制数，参考CSS颜色十六进制值 段落 属性 描述 取值 letter-spacing 字符间距 2px -3px line-height 行高 14px 1.5em 120% text-align 对齐 center left right justify text-decoration 装饰线 none overline underline line-through text-indent 首行缩进 2em 字体 font是有顺序的： font:斜体 粗体 字号/行高 字体; font:italic bold 16px/1.5em 宋体; 属性 描述 举例 font 声明设置所有的字体属性 2px -3px font-family 字体系列 font-family:”Hiragino Sans GB”,sans-serif font-size 字号 14px 120% font-style 斜体 italic font-weight 首行缩进 bold 背景 空元素需要先定义元素的高度和宽度。 属性 描述 举例 background 声明设置所有的背景属性 2px -3px background-color 背景颜色 red blue green background-image 背景图片 url(xxx.gif) background-repeat 填充方式 repeat repeat-x repeat-y no-repeat 超链接 以下这种形式也被称为伪类选择器。 a:link - 普通的、未被访问的链接 a:visited - 用户已访问的链接 a:hover - 鼠标指针位于链接的上方悬停，必须位于a:link和a:visited之后 a:active - 链接被点击的时刻，必须位于a:hover之后 示例：鼠标悬停放大字体： 12345678a&#123; font-size:22px;&#125;a:hover&#123; font-size:200%&#125;&lt;a href=https://www.douyu.com/9999&gt;Rua!&lt;/a&gt; a[id="fgnb"]{ font-size:20px; } a[id="fgnb"]:hover{ font-size:200%; color:green; } Rua! 列表 属性 描述 举例 list-style 声明设置所有的列表属性 type position image list-style-image 为列表项标志设置图像 url(xxx.gif) list-style-position 标志位置 inside outside list-style-type 标志类型 none square more 表格常见属性 width, height - 表格大小 border - 表格边框 border-collapse - 合并表格边框和单元格边框 奇偶选择器:nth-child(odd/even) 1234tr:nth-child(odd)&#123; background-color:#EAF2D3; &#125;/* 奇行设置背景色 */ 布局盒子模型 页面上所有元素看成一个盒子，占据一定的页面空间。 content - 内容 height - 高度 width - 宽度 border - 边框 padding - 内边距 margin - 外边距 盒子的实际宽度、高度由content、padding、border、margin决定。以下为一个简单的盒子模型。 1234567891011121314151617181920&lt;html&gt;&lt;head&gt;&lt;style type="text/css"&gt; #box&#123; width: 100px; height: 100px; border: 1px solid; padding: 20px; margin: 10px; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="box"&gt; Rua!Rua!Rua! Rua!Rua!Rua! Rua!Rua!Rua! &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; overflow 上述例子中，内容可以超出盒子框，应该定义overflow属性来应对。它取值包括： hidden - 超出部分不可见 scroll - 显示滚动条 auto - 如果有超出部分，显示滚动条 border 属性 描述 border width style color border-width px thin medium thick border-style dashed dotted solid double border-color green #EAF2D3 以水平分割线为例： 12345.line&#123; height:1px; width:500px; border-top:1px solid #e5e5e5;&#125; 需要的时候定义class为line即可。 padding&amp;margin 由于浏览器默认对padding和margin有赋值，通常我们会对它们清零。 1234*&#123; margin:0; padding:0;&#125; 取值：px，%（外层盒子的宽度和高度），对于margin:1px 2px 1px 3px;而言，分别是定义上、右、下、左的边距，对于margin:1px 2px;而言，相当于省略了下和左，他们的取值与上、右保持一致，也就是等同于margin:1px 2px 1px 2px;的效果。同理，如果是写3个值，相当于省略最后一个左，其值等于右。 内边距 外边距 组成 padding:5px; margin:5px; 上右下左 padding-top:10%; margin-top:10%; 上 padding-left margin-left 左 padding-right margin-right 右 padding-bottom margin-bottom 下 以下为例，值得注意的是div做盒子，会有换行的效果。margin会有合并的效果，具体而言：垂直方向合并，水平方向不合并。 12345678910111213141516&lt;html&gt;&lt;head&gt;&lt;style type="text/css"&gt; div&#123; width: 100px; height: 100px; border: 1px solid red; margin: 15px 10px 20px 30px; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="box1"&gt;box1&lt;/div&gt; &lt;div id="box2"&gt;box2&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 平时我们对图片文字水平居中，通常用text-align:center;，而div水平居中，可以用margin:0 auto;，浏览器自动计算。 定位文档流flow 除非专门指定，否则所有框均以此来定位。 none 设置为这个的元素不会被显示。 123a&#123; display:none;&#125; block 独占一行，元素的height、width、margin、padding都可设置。 常见的block元素：div、 p、h1…h6、ol、ul、table、form。 将其他元素显示成block元素，以inline元素a为例： 123a&#123; display:block;&#125; inline 不单独占用一行。 width、height不可设置。 width就是它包含的文字或图片的宽度，不可改变。 常见的inline元素：span、a。 显示为inline元素： 123a&#123; display:inline;&#125; 值得注意的是inline元素有间隙。 inline-block 同时具备inline元素、block元素的特点。 不单独占用一行。 可以设置height、width、margin、padding。 常见的inline-block元素：img。 显示为inline-block元素： 123a&#123; display:inline-block;&#125; 示例 以导航条为例： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style type="text/css"&gt; *&#123; padding: 0; margin: 0; &#125; #nav_1&#123; width: 300px; margin: 0 auto; font-size: 0; &#125; .nav_a&#123; display: inline-block; width: 80px; height: 30px; font-size: 14px; text-align: center; line-height: 30px; text-decoration: none; border-bottom: 1px solid #ccc; &#125; a.nav_a:hover&#123; color: white; background-color: #ccc; border: 1px solid; border-left-color: orange; border-top-color: orange; border-right-color: orange; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="nav_1"&gt; &lt;a class="nav_a" href="https://www.douyu.com/9999"&gt;Rua!&lt;/a&gt; &lt;a class="nav_a" href="https://www.douyu.com/9999"&gt;Rua!！&lt;/a&gt; &lt;a class="nav_a" href="https://www.douyu.com/9999"&gt;Rua!!!&lt;/a&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 浮动floatfloat 通过float属性来定位，例如div实现多列布局。 以下为例，box1和box2就脱离了文档流原来位置（竖直摆放）。 12345678910111213141516&lt;html&gt;&lt;head&gt;&lt;style type="text/css"&gt; div&#123; width: 100px; height: 100px; border: 1px solid red; float: left; &#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="box1"&gt;box1&lt;/div&gt; &lt;div id="box2"&gt;box2&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; clear 用于清除浮动。 both，清除左右两边的浮动。 left和right只能清除一个方向的浮动。 none为默认值，只在需要移除已指定的清除值时用到。 清除的意思是指该元素指定方向不会有浮动，用于浮动换行。比如要设置footer，不希望它左右两边有浮动元素： 123#footer&#123; clear:both;&#125; 示例 三行一列： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style&gt; *&#123; padding: 0; margin: 0; &#125; body&#123; font-size: 14px; &#125; #container&#123; margin: 0 auto; width: 1000px; height: 500px; &#125; #header&#123; height: 100px; background-color: #6cf; margin-bottom: 5px; &#125; #main&#123; height: 500px; background-color: #cff; margin-bottom: 5px; &#125; #footer&#123; height: 60px; background-color: #6cf; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="container"&gt; &lt;div id="header"&gt;&lt;/div&gt; &lt;div id="main"&gt;&lt;/div&gt; &lt;div id="footer"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 一行两列： 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style&gt; *&#123; padding: 0; margin: 0; &#125; body&#123; font-size: 14px; &#125; #container&#123; margin: 0 auto; width: 1000px; height: 500px; &#125; #aside&#123; float: right; width: 695px; height: 500px; background-color: #6cf; &#125; #content&#123; float: left; width: 300px; height: 500px; background-color: #cff; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="container"&gt; &lt;div id="aside"&gt;&lt;/div&gt; &lt;div id="content"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 组合为三行两列: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style&gt; *&#123; padding: 0; margin: 0; &#125; body&#123; font-size: 14px; &#125; #container&#123; margin: 0 auto; width: 1000px; height: 500px; &#125; #header&#123; height: 100px; background-color: #6cf; margin-bottom: 5px; &#125; #main&#123; height: 500px; margin-bottom: 5px; &#125; #aside&#123; float: right; width: 695px; height: 500px; background-color: #6cf; &#125; #content&#123; float: left; width: 300px; height: 500px; background-color: #cff; &#125; #footer&#123; height: 60px; background-color: #6cf; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="container"&gt; &lt;div id="header"&gt;&lt;/div&gt; &lt;div id="main"&gt; &lt;div id="aside"&gt;&lt;/div&gt; &lt;div id="content"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id="footer"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 最后是四行三列： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;mysite&lt;/title&gt; &lt;style&gt; *&#123; padding: 0; margin: 0; &#125; body&#123; font-family: "微软雅黑"; font-size: 14px; &#125; #container&#123; margin: 0 auto; width: 900px; &#125; #header&#123; height: 100px; background-color: #6cf; margin-bottom: 5px; &#125; #nav&#123; height: 30px; background-color: #09c; margin-bottom: 5px; &#125; #main&#123; height: 500px; margin-bottom: 5px; &#125; .aside&#123; float: left; width: 100px; height: 500px; background-color: #6cf; &#125; #aside1&#123; margin-right: 5px; &#125; #aside2&#123; margin-left: 5px; &#125; #content&#123; float: left; width: 690px; height: 500px; background-color: #cff; &#125; #footer&#123; height: 60px; background-color: #6cf; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="container"&gt; &lt;div id="header"&gt;&lt;/div&gt; &lt;div id="nav"&gt;&lt;/div&gt; &lt;div id="main"&gt; &lt;div id="aside1" class="aside"&gt;&lt;/div&gt; &lt;div id="content"&gt;&lt;/div&gt; &lt;div id="aside2" class="aside"&gt;&lt;/div&gt; &lt;/div&gt; &lt;div id="footer"&gt;&lt;/div&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 层layer 通过position属性来定位。目的是希望网页的元素能叠加在另外一个元素上面，能像图像软件中的图层一样可以对每个layer能够精确定位操作。 static 默认值，没有定位，元素出现在正常的流中，top、bottom、left、right、z-index无效。 z-index：定义层叠顺序，越大则处于更前。 fixed 固定定位，相对于浏览器窗口进行定位，top、bottom、left、right、z-index有效。 123456789#fixed-box&#123; width: 200px; height: 200px; border: 1px solid red; position: fixed; left: 100px; top: 50px;&#125; relative 相对定位，相对于其直接父元素进行定位，top、bottom、left、right、z-index有效。 定位为relative的层脱离正常文本流，但其在正常流的原位置存在。 12345678#relative-box&#123; width: 170px; height: 190px; position: relative; left: 20px; top: 20px;&#125; absolute 绝对定位，相对于static定位以外的第一个父元素进行定位，top、bottom、left、right、z-index有效。 定位为absolute的层脱离正常文本流，但与relative的区别是：其在正常流的原位置不再存在。 对于absolute定位的层总是相对于其最近的定义为absolute或relative的父层，而这个父层并不一定是其直接父层。 极端而言，对于absolute定位的层，如果其父层中都未定义absolute或relative，则其将相对body进行定位。 总结而言： 相对定位 绝对定位 position取值 relative absolute 文档流中原位置 保留 不保留 定位参照物 直接父元素 非static的父元素 relative+absolute 通常按照如下思路来定位： 父元素box1：position:relative; 子元素box2：position:absolute; 子元素box2：top、bottom、left、right相对于父元素来进行偏移定位。 类似如此： 1234567891011#box1&#123; position:relative;&#125;#box2&#123; position:absolute;&#125;&lt;div id="box1"&gt; &lt;div id="box2"&gt; &lt;/div&gt;&lt;/div&gt; 举例而言，如果对于定义一副图片+图片说明，可以这样写： 123456789101112131415161718192021&lt;style&gt; div&#123; border: 1px solid red; color: #fff; &#125; #box1&#123; width: 170px; height: 190px; position: relative; &#125; #box2&#123; width: 99%; position: absolute; bottom: 0; &#125;&lt;/style&gt;&lt;div id="box1"&gt; &lt;img src="coffee.jpg" alt="coffee"&gt; &lt;div id="box2"&gt;一起享受咖啡带来的温暖吧&lt;/div&gt;&lt;/div&gt; CSS3 由于W3C对标准更新速度较慢，所以浏览器会先于标准制定对新标准的支持。对于不同的浏览器，有不同的CSS3前缀： 浏览器内核 浏览器 CSS3前缀 Webkit Safari/Chrome -webkit- Gecko Firefox -moz- Presto Opera -o- Trident IE -ms- 边框border-radius 圆角边框，由border-top-left-radius、border-top-right-radius、border-bottom-left-radius、border-bottom-right-radius组成。 如果填两个值，即为水平值和垂直值，如果只填一个，则默认两值相等。 1234567div&#123; height: 100px; width: 150px; border: 1px solid blue; border-top-left-radius: 40px 20px; border-bottom-right-radius: 20px;&#125; 也可以直接通过设置border-radius来一次定义四个边角的框。 1234567div&#123; height: 50px; width: 350px; border: 2px solid #alalal; background: #ddd; border-radius: 25px;&#125; box-shadow 阴影，可以有内部阴影inset，外部阴影outset两种，默认外部阴影。 四个参数分别是：水平偏移，垂直偏移，模糊距离，颜色。 123456div&#123; height: 100px; width: 300px; background-color: #f90; box-shadow: 10px 10px 5px #888;&#125; 文本text-shadow 设置文本阴影。四个参数分别指水平偏移，垂直偏移，阴影大小（可省略），颜色。 123456h1&#123; text-shadow: 2px 2px #FF0000;&#125;h1&#123; text-shadow: 2px 2px 8PX blue;&#125; 常用于文字描边，比如： 123h1&#123; text-shadow: 0 0 3px #F00;&#125; 又比如用来做突起浮雕的效果： 1234h1&#123; color: white; text-shadow: 2px 2px 4px #000;&#125; word-wrap 允许长单词，URL 强制进行换行。如果不设置，长单词可能会溢出边框外。 1234567891011&lt;style&gt; p.wdrp&#123; width: 8em; border: 1px solid #333; word-wrap: break-word; &#125;&lt;/style&gt;&lt;body&gt;&lt;p class='wdrp'&gt;这是最长的英文单词:pneumonoultramicroscopicsilicovolcanoconiosis&lt;/p&gt;&lt;/body&gt; @font-face规则 即把特殊字体放在服务器端。根据@font-face规则，定义Web字体，并引用需要字体的四种格式，确保能在主流浏览器中都能正常显示该字体。 字体文件后缀 适用于浏览器 .TTF或.OTF Firefox、Safari、Opera .EOT Internet Explorer 4.0+ .SVG Chrome、IPhone .WOFF Chrome、Firefox 其定义格式如下： 123456789101112131415&lt;style&gt; @font-face&#123; /** 定义字体名称 **/ font-family: kastlerFont; /** 定义字体来源 **/ src:url('fonts/kastler.ttf'), url('fonts/kastler.eot'), url('fonts/kastler.woff'), url('fonts/kastler.svg'); &#125; p&#123; /** 引用字体 **/ font-family: kastlerFont; &#125;&lt;/style&gt; 2D转换 CSS3中2D转换主要包括对元素进行旋转、缩放、移动、拉伸。 主要是用transform属性，rotate()、scale()。 rotate 示例如下： 1234567891011121314151617&lt;style&gt; div&#123; width: 8em; height: 75px; background-color: #ccc; border: 1px solid black; &#125; #rotateDiv&#123; /** 正值代表顺时针旋转 **/ transform: rotate(30deg); &#125;&lt;/style&gt;&lt;div id="container"&gt; &lt;div&gt;峰哥牛逼&lt;/div&gt; &lt;div id="rotateDiv"&gt;峰哥牛逼&lt;/div&gt;&lt;/div&gt; scale 以transform: scale(x,y)为例，x代表水平方向缩放倍数，y代表垂直方向缩放倍数，省略同x，倍数取值0~1代表缩小，大于1为放大。 123#scaleDiv&#123; transform: scale(1.2);&#125; 过渡与动画过渡 用transition表示，主要是把元素的某个属性从一个值在指定时间内过渡到另一个值，包括： 属性 描述 transition 简写，同时在一个属性中设置四个过渡属性 transition-property 属性名，对哪个属性进行变化，所以属性可以用all表示 transition-duration 定义过渡效果花费的时间，默认是 0 transition-timing-function 过渡效果的方法函数，默认是 “ease” transition-delay 规定过渡效果何时开始，默认是 0 示例： 12345678910111213141516171819202122&lt;html&gt;&lt;head&gt; &lt;style type="text/css"&gt; #transition_demo&#123; height: 30px; width: 100px; line-height: 30px; border-radius: 5px; color: #000; background-color: silver; transition: all 1s linear; &#125; #transition_demo:hover&#123; color: white; background-color: #45b823; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="transition_demo"&gt;Rua!&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 动画 主要用@keyframes规则 ，animation属性。包含如下 属性 描述 @keyframes 规定动画 animation 所有动画属性的简写属性 animation-name 引入 @keyframes 动画的名称 animation-duration 规定动画完成一个周期所花费的秒或毫秒 animation-timing-function 规定动画的速度曲线，默认是 “ease” animation-play-state 规定动画何时开始。默认是 0。 12345678910111213141516171819202122&lt;html&gt;&lt;head&gt; &lt;style type="text/css"&gt; @keyframes mycolor &#123; 0% &#123;background-color: red;&#125; 30% &#123;background-color: blue;&#125; 60% &#123;background-color: yellow;&#125; 100% &#123;background-color: green;&#125; &#125; #keyframes_demo:hover&#123; animation: mycolor 5s linear; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="keyframes_demo"&gt;Rua!&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 3D变换 用transform-style: preserve-3d，常用的有旋转和透视。 通常用嵌套形式设置，里面的对象称为父容器，设置transform属性，外面的对象称为舞台，设置perspective属性。 旋转 transform属性，角度deg： rotateX() rotateY() rotateZ() 透视 perspective属性。 JavaScript JavaScript是一种运行于JavaScript解释器/引擎中的解释型脚本语言。 基本引用 类似于CSS，可以在html文件中任意地方使用，也可以用 &lt;script src=&quot;...&quot;&gt;&lt;/script&gt;引入这个文件，注意如果引用外部文件，里面不能再有js代码了。 语法 类似Java，每句用；结束。 大小写敏感 //单行注释，/* */多行注释 变量 声明，var变量名。不申明即为全局变量，可能会出现冲突。 1234//声明var userName;//赋值var bookPrice=25.5; 运算符 值得注意的是与Python不一样的有： 比较运算符，==会转换数据类型，为了避免有bug应用===，这样不会转换数据类型。 Python的递增我们一般用i+=1，这里用i++即可。 逻辑运算符， 与&amp;&amp; ，或 || ，三元运算符变量= (条件) ? 值A:值B 12345//例如：var age = 20;var msg = age &gt; 18 ? "成年" : "未成年";console.log(msg);//"成年" 可以嵌套： 1234var score = 55;var result = score &gt;= 80 ? "优秀" : (score &gt;= 60 ? "及格" : "不及格");console.log(result);//"不及格" 函数 最基本： 1234567891011function 函数名()&#123; 可执行语句;&#125; //e.g.function printHello()&#123; console.log("Hello,"); console.log("World!");&#125;printHello();/* Hello, World! */ 带参数： 123456789function 函数名(参数列表声明)&#123; 可执行语句;&#125; //e.g.function printInfo(userName,userPwd)&#123; console.log('用户名:'+userName + ' 密码:'+userPwd);&#125;printInfo('Tom','123');// 用户名:Tom 密码:123 带返回值： 1234567891011function 函数名(参数列表声明)&#123; 可执行语句; return 值;&#125; //e.g.function add(num1,num2)&#123; return num1 + num2;&#125;var result = add(10,20);console.log('结果是：'+result);// 结果是：30 注意函数作用域里面的变量（局部变量）只在当前函数能访问，离开此范围就无法访问了。 123456function add()&#123; var sum = 1 + 2; console.log(sum);&#125;console.log(sum);// Uncaught ReferenceError: sum is not defined 参数按值传递，传参的时候实际上是将实参复制一份传给函数，在函数体内对变量进行修改，实际上不影响外部实参变量。 1234567var n=100; //全局变量function fun(n)&#123; //参数变量 n-=3; //修改的是局部变量n console.log(n); //输出的是局部变量&#125;fun(n); //按值传递，方法内输出97console.log(n); //输出全局变量的值：100 流程控制条件判断if-else结构1234567891011121314151617181920// ifif(条件表达式)&#123; 语句块; &#125;// 带elseif(条件表达式)&#123; 语句块1; &#125;else&#123; 语句块2; &#125;// 带else ifif(条件1)&#123; 语句块1; &#125;else if(条件2)&#123; 语句块2; &#125;else if(条件3)&#123; 语句块3; &#125;else&#123; 语句块4; &#125; switch-case结构 通常用于等值判断的条件中，满足case条件执行，但是因为执行后会执行后面的语句，所以需要和break联用。 123456789101112switch(表达式)&#123; case 值1: 语句1; 语句2; break; case 值2: 语句3; break; ...... default: 语句n; &#125; 循环while循环12345678910111213141516171819while(表达式)&#123; 循环体语句;&#125;//e.g.var i=0;while(i&lt;10)&#123; console.log('Hello,world!'); i++;&#125;// 类似python，也有continue和break// e.g.var i=0;while(i&lt;100)&#123; console.log(i); if(i==5)&#123; break; &#125; i++;&#125; do-while循环123do&#123; 循环体语句;&#125;while(表达式); for循环1234567for(表达式1(初始条件);表达式2(判断条件);表达式3(递增条件))&#123; 循环体;&#125;//e.g.for(var i=0;i&lt;10;i++)&#123; console.log(i);&#125; for循环的三个条件可以省略，如果没有break会无限循环下去。 for-in循环123456789var o = &#123; name: 'Jack', age: 20, city: 'Beijing'&#125;;for (var key in o) &#123; console.log(key); &#125;// 'name', 'age', 'city' 数组索引数组 类似python列表或者numpy的array。 1234// 直接创建var arr=[];// 用newvar arr=new Array(); 用索引来添加： 1234567// 如果添加没按顺序，则中间会被empty补位var empArray = [];empArray[0] = "pis";empArray[1] = "2009";empArray[3] = "yyf";console.log(empArray);// ["pis", "2009", empty, "yyf"] 通过arr.length赋值，可以达到缩容的目的。 关联数组 有点类似python的字典，用于描述对象。 123var bookInfo =[];bookInfo['bookName']='西游记';bookInfo['price']=35.5; 数组函数 String(arr)：转成字符串。 arr.join(“连接符”)：类似于python的join，语法稍有区别。 arr.concat()：拼接并返回新数组。 12345678var arr1=[90,91,92];var arr2=[80,81];var arr3=[70,71,72,73];var arr4=arr1.concat(50,60,arr2,arr3);console.log(arr1);// [90, 91, 92]console.log(arr4);// [90, 91, 92, 50, 60, 80, 81, 70, 71, 72, 73] arr.slice()：类似于切片。 省略第二个参数，相当于于python切片的：，选取到结尾；省略所有参数则是相当于复制数组。 123456789var arr1=[10,20,30,40,50];var arr2=arr1.slice(1,4); // [20, 30, 40]var arr3=arr1.slice(2);// [30, 40, 50]var arr4=arr1.slice(-4,-2);// [20, 30]console.log(arr1);// [10, 20, 30, 40, 50] arr.splice(i,n(,…))：删除arr中i位置开始的n个元素不考虑含头，直接修改原数组，返回值则会保存被删除元素组成的数组；如果加入后面的参数，则会在删除位置插入后面输入的元素，这样通过修改n可以达到不同目的，如n=0，则为插入效果，n与后面元素数字相等相当于替换效果。 1234567891011121314151617var arr1=[10,20,30,40,50];var arr2=arr1.splice(2,1); console.log(arr1);// [10, 20, 40, 50]console.log(arr2);// [30]var arr3=arr1.splice(2,2,21,22,23); var arr4=arr1.splice(2,2,[91,92,93]); console.log(arr1);// [10, 20, 21, 22, 23, 50]console.log(arr3);// [30, 40]console.log(arr1);// [10, 20, Array(3), 50]console.log(arr4);// [30, 40] arr.reverse()：颠倒数组顺序。 arr.sort()：排序，不过只能排字符串类型。 DOM DOM(document object model)，可以用于对网页增删改查。 查找 按id，var elem=document.getElementById(&quot;id&quot;)。 1234567&lt;ul id="myList"&gt; &lt;li id="m1"&gt;yyf&lt;/li&gt; &lt;li id="m2"&gt;2009&lt;/li&gt; &lt;li id="m3"&gt;pis&lt;/li&gt;&lt;/ul&gt;var ul=document.getElementById("myList");console.log(ul); 按标签名，var elem=parent.getElementsByTagName(&quot;tag&quot;)，直接查找parent节点下所有标签为tag的子代节点，返回一个动态集合，就算只有一个也要用[0]来取出。 12345678&lt;ul id="myList"&gt; &lt;li id="m1"&gt;yyf&lt;/li&gt; &lt;li id="m2"&gt;2009&lt;/li&gt; &lt;li id="m3"&gt;pis&lt;/li&gt;&lt;/ul&gt;var ul=document.getElementById("myList");var list=ul.getElementsByTagName("li");console.log(list); 按name，var elem=document.getElementsByName(&quot;name&quot;)，返回所有子集合。 12345678&lt;form id="registerForm"&gt; &lt;input type="checkbox" name="boy" /&gt; &lt;input type="checkbox" name="boy" /&gt; &lt;input type="checkbox" name="boy" /&gt;&lt;/form&gt;var list=document.getElementsByName("boy");console.log(list);console.log(typeof list); 按class，var elem=parent.getElementsByClassName(&quot;class&quot;)。 12345678&lt;div id="news"&gt; &lt;p class="mainTitle"&gt;title1&lt;/p&gt; &lt;p class="subTitle"&gt;title2&lt;/p&gt; &lt;p class="mainTitle"&gt;title3&lt;/p&gt;&lt;/div&gt;var div=document.getElementById("news");var list=div.getElementsByClassName("mainTitle");console.log(list); 按CSS选择器： 只找一个元素：var elem=parent.querySelector(&quot;selector&quot;)，如果有多个也只返回一个，类似于bs4。 找多个：var elems=parent.querySelectorAll(&quot;selector&quot;)。 核心 读取属性值，有点类似bs4的操作： 123456// 先获得属性节点对象，再获得节点对象的值var attrNode=elem.attributes[下标/属性名];var attrNode=elem.getAttributeNode(属性名);attrNode.value; //属性值// 直接获得属性值var value=elem.getAttribute("属性名"); 修改的时候，用set方法： 12var h1=document.getElementById("a1");h1.setAttributeNode("name",zhangji); 判断是否包含指定属性： 123var bool=elem.hasAttribute("属性名");//e.g.document.getElementById("bt1").hasAttribute("onclick"); 移除属性： 12345elem.removeAttribute("属性名");//e.g.&lt;a id="alink" class="slink" href="javascript:void(0)" onlick="jump()"&gt;百度搜索&lt;/a&gt;var a=document.getElementById("alink");a.removeAttribute("class") 修改样式： 1234567// 内联样式elem.style.属性名;// 强调属性名：去横线，变驼峰；// e.g.css:background-color=&gt;backgroundColor; list-style-type=&gt;listStyleType; 添加 创建空元素。 1234567var elem=document.createElement("元素名");//e.g.var table=document.createElement("table");var tr=document.createElement("tr");var td=document.createElement("td");var td=document.createElement("td");console.log(table); 设置关键属性。 123a.innerHTML="yyfyyf123";a.href="https://www.douyu.com/9999";//&lt;a href="https://www.douyu.com/9999"&gt;yyfyyf123&lt;/a&gt; 设置关键样式。 1234// 修改某一项a.style.opacity="1";// 批量修改a.style.cssText="width:100px;height:100px"; 将元素添加到DOM树，parentNode.appendChild(childNode)，可用于为一个父元素追加一个子节点。 1234var div=document.createElement("div");var txt=document.createTextNode("版权说明");div.appendChild(txt);document.body.appendChild(div); parentNode.insertBefore(newChild,existingChild)，用于在父元素中的指定子节点之前添加一个新的子节点。 1234567&lt;ul id="menu"&gt; &lt;li&gt;首页&lt;/li&gt; &lt;li&gt;联系我们&lt;/li&gt;&lt;/ul&gt;var ul=document.getElementById("menu");var newLi=document.createElement("li");ul.insertBefore(newLi,ul.lastChild); 注意：尽量要少操作DOM树，避免每次重新layout。优化思路：1.如果同时创建父元素和子元素时，建议在内存中先将子元素添加到父元素，再讲父元素一次性挂到页面；2.如果只添加多个平级子元素时，就要将所有子元素临时添加到文档片段中，再将文档片段整体添加到页面。 1234567// 创建片段（相当于虚拟父元素）var frag=document.createDocumentFragment();// 将子元素临时追加到frag中frag.appendChild(child);// 将frag追加到页面parent.appendChild(frag);// append之后，frag自动释放，不会占用元素 BOM BOM(browser object model)，操作浏览器窗口，可能有兼容性问题。 基本 window：代表整个窗口。 1234// 获取当前窗口大小window.outerWidth/outerHeight;// 文档显示区大小window.innerWidth/innerHeight; history：封装当前窗口打开后，成功访问过的历史url记录。 navigator：封装浏览器配置信息。 document：封装当前正在加载的网页内容。 location：封装了当前窗口正在打开的url地址。 screen：封装了屏幕的信息。 event：定义了网页中的事件机制。 定时器周期性定时器 语法： setInterval(exp,time)：周期性触发代码exp。 exp：执行语句。 time：时间周期，单位为毫秒。 123setInterval(function())&#123; console.log("Rua!!!");&#125;,1000); 停止定时器 给定时器取名： 123var timer=setInterval(function())&#123; console.log("Rua!!!");&#125;,1000); 停止定时器： 1claerInterval(timer); 一次性定时器 让程序延迟一段时间运行，语法： setTimeout(exp,time)：一次性触发代码exp。 exp：执行语句。 time：间隔时间，单位为毫秒。 123setTimeout(function())&#123; alert("Rua!!!");&#125;,3000); JQuery 类似于插件库，稍作了解。 概述工厂函数$()]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>HTML</tag>
        <tag>CSS</tag>
        <tag>JavaScript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[悬疑推理向游戏记录]]></title>
    <url>%2F2019%2F09%2F29%2F%E6%82%AC%E7%96%91%E6%8E%A8%E7%90%86%E5%90%91%E6%B8%B8%E6%88%8F%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录一下玩过的悬疑推理向游戏，因为显得比较不务正业，所以决定藏在下面一点，排名按照个人喜好，分先后。 428:被封锁的涩谷 严格意义上讲，这个不能算推理游戏，应该归为悬疑游戏。不过叙事上非常优秀，而且结局众多，众多情节都很合乎逻辑，相互照应。是Fami通唯一一个满分的音像小说。 这个游戏以涉谷一天中5个不同主角的不同行为来推演结果，其中一个主角无厘头的行为有可能就决定了另外一个主角的生死，当最后所有人的剧本交织在一起的时候，那种美妙的感觉实在是让人感叹。 本作是我最喜欢的ADV，个人评分：9.6分。 Ever 17 meta类的游戏，它并不是第一个，诡叙类的游戏，它也不是第一个，不过把这些核心诡计藏到最后，直到最后一刻才揭晓，难怪大部分玩过这部作品都要称为“神作”。作为一部02年的作品，它的地位大概可以类比《占星术杀人魔法》在推理小说中的地位，属于开创性的。 由于我不喜欢Galgame中冗长的日常，所以觉得前面四条线日常有点偏多，而这游戏属于必须通完五条线才能看到真结局的，觉得有点拖沓。但是通关后会有豁然开朗之感，之前的一些伏线基本上全部收回。只能佩服打越钢太郎的布局和脑洞。 总结而言，本作是打越钢太郎的巅峰之作，他后面的作品都未能再有突破，个人评分：9.5分。 幽灵诡计 巧舟的另一部封神之作，主角开场就死了，然后灵魂状态的他拥有附体和回到死前4分钟的能力，要在一夜之间一步步找回记忆并发现死亡真相的故事。剧情全程无尿点，浑然天成，各种反转让人欲罢不能。和巧舟所做的逆转裁判比这个更像是一个小品级的作品，剧情又因为已经形成闭环大概也不可能有续作了，可惜受限于平台在国内只能是小众。 个人评分：9.2分。 大逆转裁判系列 合并在一块是因为这个作品单看第一部并不够出色，很多线没收，只有一二部合在一起才算构成了闭环。逆转裁判系列在我心目中尚且不如这部外传。 整个作品设定在十九世纪末二十世纪初的英国，音乐和画风确实很还原，用了不少细节刻画当时的风土人情，而且我喜欢的福尔摩斯也在里面出场，就推理质量而言，整体案件二比一强了不少，而且二基本上把一里面挖的坑填完了，硬生生挽回了大逆转裁判一几乎崩掉的口碑。 个人而言更喜欢这个系列，逆转裁判本作更类似于设定系推理，我是不太喜欢推理作品里面有超自然因素的，相对而言大逆转裁判更加古典一点。 个人评分：大逆转裁判一8分，大逆转裁判二9.2分，合起来可以算9.1分。 去月球 这个也不能被当做推理游戏，在众多RPG Maker作品中可以排进总统山级别了，尤其是里面的《for river》我一度单曲循环。这个世界有借由改变记忆为弥留之际的人们完成愿望的公司，其中的两个医生准备为约翰完成这个服务，却发现并没有容易奏效，通过不断发掘他的记忆从而揭开了他过去的秘密。 个人感受就是好的故事不会受限于表达形式与技术水平，虽然是很简单的一个RM游戏，但是也让人感动万分。 作者有意做一个“去月球宇宙”，但《鸟的故事》和《寻找天堂》还是没给我带来相比于《去月球》的体验的。 PS：给我带来深刻印象的RM游戏，还有《黑暗圣剑传说》、《血雨》系列。 个人评分：9.0分，《鸟的故事》&amp;《寻找天堂》8.5分。 命运石之门 这部作品比Ever 17强在动画化了，而且人设更加讨喜，因此名气大了不少。不过就我个人而言，一方面觉得这种LOOP类的游戏已经珠玉在前，创新性扣分，此外日常部分就更多，玩起来就更觉得拖沓了。 但是这部游戏作为科学幻想系列作品，世界观的设定更为严谨一点，谜面解答也很公平，称得上是佳作。 个人评分：9.0分。 弹丸论破系列 这个游戏系列的名气还是很高的，毕竟也有过动画化。个人而言比较喜欢这个系列的题材，暴风雪山庄的设定加上水平尚可的案件，量大管饱，而且比逆转裁判系列代入感和推理性要更强一点，逆转裁判的问题稍后再说。 案件质量而言应该是2&gt;1&gt;V3，V3的问题一方面人设感觉没之前有亮点，另一方面后期有点放飞自我，直接变meta了，感觉把系列的路全堵死了，不过中间玩的Trick还算有点意思，扣住了主题“谎言”。 总体来说还是相当推荐的，毕竟推理性很强，比起《逆转裁判》这类的更本格一点。在《诡计×逻辑》的汉化出来之前（恐怕也不太可能出来）似乎也就这个更符合我的审美了。 个人评分：弹丸论破1为8.8分，弹丸论破2为9.0分，弹丸论破V3为8.6分，综合来看系列分大概在8.9左右。 极限脱出系列 打越钢太郎的代表作之一了，第一部《极限脱出:9小时9个人9之门》是该系列的巅峰之作，最终的Trick配合NDS特有的双屏给人的震撼无以复加。当然核心诡计抄了打越自己的《Ever 17》，这就是传说中的我抄我自己。 从第二部《极限脱出:善人死亡》开始，就开始一部比一部扑，诡计上也一部不如一部，第三部还是在欧美粉丝的支持下才出来的，不过建模岂是一个崩字了得，可见经费捉襟见肘。估计也不会有续作了，还是挺遗憾的。不过要说到密室脱逃，个人感觉手机上爆火的《Room》远不如这个。 个人评分：极限脱出1为9.2分，极限脱出2为8.8分，极限脱出3为8.4分，综合来看系列分估计也就给个8.8左右。 逆转裁判系列 这里把逆转裁判1-6和逆转检事1-2以及雷顿教授vs逆转裁判拉一块说。 逆转裁判的切入点确实很好，在那个年代的游戏基本上都是侦探视角的破案游戏，巧舟把观念逆转过来，弄了个法庭辩论游戏，当然法庭辩论在侦探小说界也算不上新梗，毕竟卡尔的名作《犹大之窗》早就涉及相关题材，但是这个游戏也算是开辟了推理ADV的新道路。 个人觉得在逆转裁判1-3和逆转检事1-2之后这个系列已经露出了疲态，该写的已经都写了，按理说应该可以完结了。卡普空为了继续捞钱，强行开续作，而之后的增加的主角王泥喜和心音完全撑不起逆转裁判这个IP，案件乏善可陈，玩下去已经成为一种惯性，我猜大概也是巧舟要重新开大逆转裁判系列的目的吧。 《雷顿教授vs逆转裁判》这一作联动完全对不住两个IP的名头，剧情也有点扯淡，亮点恐怕就是有配音的逆转裁判了。 个人评分：逆转裁判三部曲8.7分，逆转检事两部曲8.8分，剩下的4-6大致在8.4-8.6分左右，雷逆8.0分，综合评价8.7分。 AI：梦境档案 打越新作，这次国庆肝了3天全通了。不得不说，现在的推理悬疑向游戏太少了，连一年一部都很难保证。 本来是期待一部超越《Ever 17》或者《极限脱出》的作品，不过看上去打越对市场妥协了，做了一部相对比较讨喜市场的作品。游戏里有非常多玩梗的地方，看到会给人会心一笑的感觉，相对于他之前的作品，整体氛围也轻松了不少。不同支线埋的坑，基本上都在最后回收了，还是可以见到打越的功力的。然而这部作品的谜面并不出众，基本上玩到中途就能猜到结尾了，给我的惊喜不够。 另外本作的Psync感觉没《极限脱出》系列的密室逃脱有意思，大概还是对市场的妥协吧，毕竟不能再承受一次《善人死亡》的暴死了吧。 更新：听说这次在日本销量又暴死了，这次可能是里面黄段子太多了吧哈哈哈。 个人评分：8.5分。 G弦上的魔王 同样是诡叙性的作品，而且游戏一直在刻意误导玩家，然而最后的反转会让人感觉铺垫不足，不够严谨。优点在于是斗智类剧情，能够吸引人一直玩下去，BGM也是其中的亮点，基本上全部是世界古典名曲或变奏。 总的来说，是一部主线强而支线较弱的作品，值得一口气玩下去，但是核心诡计不够完美应该扣分。 个人评分：8.0分。 柯南/金田一系列 从GB到3DS有众多柯南/金田一主题的游戏，姑且放在一类吧。当然远古作品很多没有汉化无法玩到，我就挑有汉化的几部来说吧，总的来说这些系列作品的质量还算稳定，但也没什么惊喜。 《名侦探柯南&amp;金田一少年事件薄：交错的两位名侦探》：剧本是小高和刚，总的来说质量不差，算是这堆作品里面最靠谱的一个了。两大著名死神携手作战，双线叙事，诡计也有点意思，而且当初玩的时候还年轻，没现在这样身经百战。评分：8.5分。 《金田一少年事件簿：恶魔之杀人航海》：推理性一般，故事相对比较无聊，有恶心的拆炸弹游戏。评分：7分。 《名侦探柯南：苍蓝宝石的轮舞曲》：其实还行，比上一个作品好点。玩这个的时候我还丢了一次存档，重打的时候真痛苦。评分：7.5分。 《名侦探柯南：来自过去的前奏曲》：比苍蓝宝石好玩一点，至少是一个练成线的故事，可惜毫无惊喜感。评分：7.7分。 《名侦探柯南：木偶交响曲》：推理性不咋地，不过表现系统还行，画面嘛，玩过NDS的作品，感觉3DS贼亲切hhh，平庸之作。评分：7.5分。 《名侦探柯南：幻影狂诗曲》：3DS汉化第二作，比第一作有意思一点，整了个多重反转，尚可一玩。评分：7.9分。 个人总结：作为粉丝向作品，主要还是看喜欢的人物，就故事性而言，各个案件水平参差不齐，无聊的时候可以玩玩。综合评价：7.8分。]]></content>
      <categories>
        <category>缓寻芳草</category>
      </categories>
      <tags>
        <tag>Game</tag>
        <tag>Visual novel</tag>
        <tag>Lattice resoning</tag>
        <tag>Galgame</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[推理小说记录]]></title>
    <url>%2F2019%2F09%2F05%2F%E6%8E%A8%E7%90%86%E5%B0%8F%E8%AF%B4%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[谨以此文记录看过的推理小说。 日本东野圭吾 名气实在太大了，感觉没有必要靠俺推荐，太知名作品就不写了，写点小众一点的。 《假面山庄》 这部小说最大的问题就是看起来是暴风雪山庄，结果最后的结果又全推翻了，看起来想打人。 《名侦探的守则》 本格推理讲义，把常见推理小说核心全用戏说手法表现出来了，读起来让人会心一笑。 岛田庄司 作为新本格的代表人物，岛田庄司的作品很多，有名的有：《占星术杀人魔法》、《斜屋犯罪》、《奇想天动》、《异邦骑士》、《北方夕鹤2/3杀人事件》、《螺丝人》，惭愧的是大部分我都看不下去，所以就提2部。 《占星术杀人魔法》 很遗憾，读到这篇小说的时候，我已经看过金田一和少年包青天的类似案件了，知道了核心诡计，小说的魅力大减，不过作为首个用出该核心诡计的小说，被抄袭不是它的错，只能说这个诡计设计太精妙了。 《斜屋犯罪》 很有意思的密室杀人，宏大的场面，就诡计而言确实瞒过我了，而且那个建筑物有点复杂，看的时候来来回回研究了半天。当然动机觉得有点弱，总的来说值得一读。 绫辻行人 绫辻行人的主要作品就是馆系列，值得一提的是其中的一位侦探主角的名字岛田洁就是来源于岛田庄司和他笔下的侦探御手洗洁。馆系列的作品质量良莠不齐，也就如下几部值得一看。 《钟表馆事件》 公认的馆系列最高作，双线叙事，暴风雪山庄模式+ 时间诡计，加上作者的叙述性诡计，整体看下来是相当精彩的，不过得对照地图来看。 《十角馆事件》 感觉是日本版的《无人生还》，当然没有童谣杀人的设定，由于是伪暴风雪山庄，主要是看凶手制造不在场证明的手法，配合作者的诡叙，还是值得一看的，动机设定就emmm了。 《迷宫馆事件》 这个系列看下来，就是觉得作者为了一个故事就设定一个建筑确实很敬业。就这本书而已，还是惯用的诡叙，事件本身很吸引人，但解答看起来有种被愚弄的感觉。 《咚咚吊桥坠落》 文笔是真的不太行。但是作为看多了本格推理之余的小菜还是值得一提的，把叙述性诡计玩花了。另外在取名上把知名推理作家都唰了一通，特别是我孙子武丸，每条狗都要取这名hhh。 森博嗣 森博嗣是因为之前看过小说同名电视剧《全部成为F》，毕竟单元推理剧并不是很多，看完后对他的小说有点兴趣，又翻出来看。不过他的小说还是很有特点的，有种特有的理工科的浪漫。 《全部成为F》 应该是在大陆名气最高的作品了，不过也有可能是其他作品不在大陆出版的缘故。当然小说内容本身就在电视剧里被改编过了，得知了谜底的情况下，也就只剩下对比细节了。 《不会笑的数学家》 看过的感觉就是《三星馆事件》？和斜屋犯罪或者馆系列一样的建筑推理，核心诡计有点意思，当然这类推理都这样，反正森博嗣的S&amp;M系列看的是教授和学生的恋爱日常23333。 《死亡幻术的门徒》 听说这部在日本评价很高，看完后感觉一般，总共有3起案件，谜设看起来挺华丽的，不过解谜感觉都挺一般的，反正我觉得有点扯淡，感觉这种诡计侮辱我智商。 三津田信三 风格有点特色，民俗/恐怖与推理结合，暂时觉得还不错。 《首无·作祟之物》 怪异君评价为“本格神作”，不过我拖了很久才开始读。读过觉得还是挺惊喜的， 叙事结构很精巧，采用了书中书的模式。把一个简单的无头尸诡计写到了极致，最后的三重反转十分精彩。当然其中首无的制造有点扯淡，算是瑕不掩瑜吧。 《山魔·嗤笑之物》 这部的硬伤较多，看点是童谣/比拟杀人，之前一家人消失给人的错愕，最后的解答虽然是我没想到的，但是是很低级的解答，并没有对应的上之前的期待感。最后的几次逆转也没有前作的震撼感，总的来说，尚可一读，但是略显鸡肋。我应该会暂时不会涉及他其他作品了。 今村昌弘 他的《尸人庄谜案》之前就久闻大名，等了很久才有中文版上市，只想说：“磨铁出来挨打。” 《尸人庄谜案》 期待了2年的作品，读完觉得有点捧过头了，但是还是挺有意思的。在现代信息发达的社会很难设计出一个合理的暴风雪山庄，这本书的给了一个合乎逻辑的设定。案件设计上还是合乎情理，算得上自圆其说，但是有隐瞒线索的嫌疑。不过读完只能感叹现在推理界不景气啊，这本书并不差，但是对不起它独霸三榜的地位。 《魔眼之匣谜案》 个人觉得不如《尸人庄》，也不是那种很本格的推理，密室与杀人亮点不够，但是整体的结构挺精巧，最后的反转还是有点冲击力的。 西泽保彦 最出名的大概是《解体诸因》了，剩下几本还没读，读了再更新吧。 《解体诸因》 短篇合集，作者一本正经的对分尸的理由做了一系列解答，读起来还是挺有意思的。主要是都是中短篇，看起来也不累。 《死了七次的男人》 作为SF推理，创意上有点意思，可惜没什么推理，剧情槽点满满。 青崎有吾 话说作者也就比俺大两岁，21岁就凭《体育馆之谜》拿奖出道，俺深感惭愧啊。 《体育馆之谜》 这部的诡计被《唐人街探案》抄袭了，虽然挺本格，但是我不太喜欢宅男侦探的人设，和作者偏轻小说的文风。所以也仅仅看了这部。 《敲响密室之门》 哎呀被打脸了，最近补了这本，果然推理还是看中短篇比较轻松。 《水族馆之谜》 逻辑流，真的废话好多，不知道怎么被我看完的。 东川笃哉 看了以他原著改编的电视剧《推理要在晚餐后》才关注的，总觉得文风太轻小说化了，甚至到了感觉有点尬的地步。 《请勿在此丢弃尸体》 实在是太轻小说了，各种角色跟白痴一样，谜设一般般，觉得应该适合于中学生来看，如果能get到他设的各种笑点，阅读体验大概还行吧。 《密室的钥匙借给你》 严格意义上讲，比上面那本读起来更舒服一点，不过动机和手法就不咋地了，而且突然就哲学了起来emmmm。 《推理要在晚餐后》 跳过了被改编成剧的部分，严格意义上讲确实质量不高，不过阅读体验还可以，比起有些作家的晦涩的文字，至少他的文字还算可读。 石持浅海 作者好像喜欢用倒叙推理，《紧闭的门扉》便是如此，我也只看了这本。 《紧闭的门扉》 大概是喜欢《古畑任三郎》，所以对倒叙推理还是挺有兴趣的，这种类型的推理不怕泄底，更看重侦探和凶手的对决，唯一的问题在于，凶手好像有点弱，侦探的屁股也很歪。 早坂吝 传说中的工口推理作家，估计也不太可能在国内出版，不过《彩虹牙刷》有民翻。 《彩虹牙刷》 工口推理赛高，看起来好像是小黄文，不过里面的推理还是挺正经的。结局的脑洞大开，值得一看。 深水黎一郎 只看过《推理竞技场》，个人感觉作者的文风不错。 《推理竞技场》 很娱乐的推理小说，作者一直在戏谑诡叙和多重解答，有种批评文学的感觉。就推理性而言不值一提，当故事来看尚可一读。 泡坂妻夫 这个作者的小说布局很有意思，属于那种炫学流，把其他领域的知识引入到推理小说，又不觉得卖弄，确实有真才实学的那种。 《十一张牌》 作者之前好像是魔术师，所以这本小说对魔术如数家珍，堪称魔术泄底大全。读起来也挺有意思的。 《失控的玩具》 依旧是炫学作品，本小说对机关玩偶如数家珍，读来感觉不明觉厉。推理的话，大概到一半就猜到了， 但是本小说的优点是平实靠谱的推理过程，埋线很细，读罢倒是没有被糊弄的感觉，与某些藏线索的作者高下立判。 《湖底的祭典》 诡叙流作品，布局很有想法，保留了这个作者的一贯水准。至于用到的核心Trick，现在看来倒是很一般，30年间有不少或拙劣或高深的模仿，读来已经觉得见怪不怪了。 大山诚一郎 是近年来水平比较高的作家了，《赤色博物馆》、《密室收藏家》评价口碑都不错，希望新书能早日看到翻译。 《密室收藏家》 总共有5篇很纯粹的密室故事，时间跨度60年，贯穿其中的就是自称密室收集家的一位，容貌永远不老，只要有密室出现就仿若从天而降一般的来解谜的神秘人物。整体质量不错，很正统的本格推理，强烈推荐。 《赤色博物馆》 依旧是短篇集，不过每篇故事都算很完整，写的是从未解决事件的证物细节中发掘真相的警察，读起来感觉还行，感觉不如上一本《密室收藏家》，也算值得一读了。 市川忧人 代表作品《水母不会冻结》和《蓝玫瑰不会安眠》，作为新锐推理小说作家，对他期待挺高，不过读过《水母不会冻结》后，感觉有点失望，不由对近年来另一部名气很大的推理作品《尸人庄杀人事件》感到忧心啊。 《水母不会冻结》 特点是暴风雪山庄和SF，号称致敬《无人生还》。不过也仅仅是个噱头，可能是叙述手法的问题，揭秘时没什么感觉，诡计也觉得一般。 《蓝玫瑰不会安眠》 和上一部一样的双线叙事的写作手法，配合叙诡，确实没想到是这样的一个布局，但是诡计还是感觉有点扯淡。总的来说可以一看，个人觉得比水母那本强点。 《玻璃鸟不会归来》 作者有意打造一个推理宇宙的样子，在这部能看到前两部的元素，读起来还是有种会心一笑的感觉。可惜不管是动机还是手法，简直跟胡闹差不多，失望之作。 歌野晶午 此人我只看过一部小说，已经隐隐有拉黑趋势了。 《樱树抽芽时，想你》 这是我看过的此人第一部小说。平心而论，就行文方式，确实读着很舒服，然而最核心的诡叙却让我很不信服，虽然解释了之前的一些让我疑惑的点，但是有些地方却让我更加觉得很雷人，甚至有点恶心。 白井智之 鬼畜推理代表之一，读完已被拉黑。 《杀死少女的100种方法》 五个案子，除了第三个案子有点黑色幽默的感觉，其他几个读起来只觉得恶心，感觉作者是心理变态。虽然是很本格的推理，但是我不喜欢他的内容。 中西智明 这老哥凭一部《消失！》出道，然后就没声音了。 《消失！》 八嘎推理作品，诡叙核心我没全猜到，只能说这种作品放在三十年前应该是惊艳的作品，可惜俺出生太晚，读到的时候也太晚了。 西村京太郎 文风好评，完爆绫辻行人那种晦涩文字。缺点在于推理性一般。 《七个证人》 无人生还模式作品，里面写了两个交叠的案子，读起来感觉跟逆转裁判差不多，各种层面上的。总的来说感觉惊喜感不够，但是优点是很重视逻辑自洽，不像某些小说十分牵强的只探讨一个可能性。 二阶堂黎人 他的人狼城早就想读了，可惜由于篇幅太长一直懒得读，这次正好赶上肺炎把坑给填了。 《恐怖的人狼城》 传说中的史上最长推理小说，一个故事拆成了4本书，真的佩服灌水能力。全书场面宏大，同步进行的暴风雪山庄事件，密室也很多，对于本格爱好者还是很友好的，核心诡计好像被金田一某集给抄了，导致我少了点惊喜。但是剧情实在有点扯，不管是动机还是里面的设定都是，最后还整了个玄幻让人摸不着头脑。总的来说，如果只看推理还是可以一试的。 中国孙沁文 笔名鸡丁，国产推理作家。只看过《凛冬之棺》。 《凛冬之棺》 包括3个密室，整体来说可以自圆其说，设计上还是挺有想象力的，不过总感觉和一些优秀的国外推理小说比差点味的样子。 陈浩基 香港推理作家，很早就听说过《13 67》的名声了，最近才得以拜读。 《13 67》 6篇故事，以主人公关振铎的视角，描述了香港的一个时代的变迁。就单篇而言是本格推理，放一块又有种社会派的感觉。最后一篇与第一篇遥相呼应，结构上给人很精妙的感觉。推荐一读。听说要改编电影？希望别毁了。 时晨 号称本格良心，逻辑良心，俺看完《黑曜馆事件》后就起了嘀咕，《镜狱岛事件》看了一点就弃了，给写出这样评价的人劈个叉吧。 《黑曜馆事件》 姑且评价一下，暴风雪山庄题材，本来俺挺感兴趣的，不过作者的核心手法都有问题，贯穿始终的“暗黑童话”感觉很可笑，这么一看的话，可读性就一般了，对不起豆瓣上那堆吹上天的评价。 杨叛 小时候在《今古传奇·武侠版》里面读过一点他的小说，很后面才补他的云寄桑三部曲。 《死香煞》 武侠+推理，是我喜欢的两个元素，这块写的好的并不多，小时候读的古龙算是其中的佼佼者了，作为武侠，很多在推理作品里面没法使用的诡计也能合理用出，读起来更有新奇感。可惜就这篇而言，虽然用了暴风雪山庄模式，总感觉情节和冲突都缺点味道，不够成熟。 《鬼缠铃》 其实整体上还行，就是老穿插男主的精神病，感觉故弄玄虚，另外那些配角各种设定，让人觉得神叨叨的，结果后面也不过如此。剩下的因为主角设定受了伤，没上一本那样的神功破案，相对来说限制多了点，可能就推理体验更好。 《傀儡咒》 读起来是因为惯性，其实亮点有限，读起来没什么意外感。而且我不太喜欢里面的棒子。 《自在花》 短篇，读的时候大概猜到了反转，不过也不难看。 欧美约翰·狄克森·卡尔 传说中的密室推理之王，暂时只看过《犹大之窗》。 《犹大之窗》 法庭推理，庭审和密室的二合一，有种逆转裁判的感觉。诡计嘛，个人估计一般，不过考虑到成书年代，也就凑合看了。]]></content>
      <categories>
        <category>缓寻芳草</category>
      </categories>
      <tags>
        <tag>Lattice resoning</tag>
        <tag>Detective story</tag>
        <tag>Penetralium</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django学习笔记]]></title>
    <url>%2F2019%2F04%2F12%2FDjango%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[最近在学习一些WEB相关知识，这篇博文用于记录一些知识点，基于Django2.2来编写。 初始化新建虚拟环境 安装virtualenv： 1pip install virtualenv virtualenv使用： 123456# 创建virtualenv &lt;虚拟环境名称&gt;# 启动activate# 退出deactiavte 一键导出/安装扩展 命令提示符下： 12pip freeze &gt; requirements.txtpip install -r requirements.txt 基础知识新建项目 CMD下输入：django-admin startproject &lt;项目名&gt; 初始化数据库 CMD下输入：python manage.py migrate 启动本地项目 CMD下输入：python manage.py runserver 创建管理员 CMD下输入：python manage.py createsuperuser 创建应用 CMD下输入：python manage.py startapp &lt;应用名&gt; 在app目录下定义models.py，例如： 123class Article(models.Model): title = models.CharField(max_length=30) content = models.TextField() 保存后在项目目录下，settings.py注册该应用： CMD下执行： basic12python manage.py makemigrationspython manage.py migrate 在应用目录下，编辑admin.py： 12from .models import Articleadmin.site.register(Article) 绑定url 在项目目录下，编辑urls.py，参考注释： 12Add an import: from my_app import viewsAdd a URL to urlpatterns: path(&apos;&apos;, views.home, name=&apos;home&apos;) 注意事项 公用全局设置可放在settings中，统一管理 12from django.conf import settingssettings.XXX 进阶知识定制admin后台 在应用目录下，models.py中的类中，增加__str__方法，例如： 123456789from django.db import models# Create your models here.class Article(models.Model): title = models.CharField(max_length=30) content = models.TextField() def __str__(self): return "&lt;Article: %s&gt;" % self.title 项目目录下的admin.py： 1234567891011from django.contrib import adminfrom .models import Article# Register your models here.@admin.register(Article)class ArticleAdmin(admin.ModelAdmin): list_display = ('id','title','content') ordering = ('id',) # 倒序：('-id',)# admin.site.register(Article, ArticleAdmin) 修改模型 模型修改后要重新执行 12python manage.py makemigrationspython manage.py migrate 增加其他参数 修改models.py，增加如下内容： 1234567from django.utils import timezoneclass Article(models.Model):...... created_time = models.DateTimeField(auto_now_add=True) last_updated_time = models.DateTimeField(auto_now=True) author = models.ForeignKey(User, on_delete=models.DO_NOTHING,default=1) 相应的应于admin中的list_display增加字段。 给类增加默认排序，在父类中增加子类，形如： 12345678910111213141516171819202122from django.db import modelsfrom django.contrib.auth.models import Userclass BlogType(models.Model): type_name = models.CharField(max_length=15) def __str__(self): return self.type_nameclass Blog(models.Model): title = models.CharField(max_length=50) blog_type = models.ForeignKey(BlogType,on_delete=models.DO_NOTHING) content = models.TextField() author = models.ForeignKey(User, on_delete=models.DO_NOTHING) created_time = models.DateTimeField(auto_now_add=True) last_updated_time = models.DateTimeField(auto_now=True) def __str__(self): return "&lt;Blog: %s&gt;" % self.title class Meta: ordering = ['-created_time'] 使用Shell命令 命令提示符下输入： 1python manage.py shell 管理博文12345678910111213141516171819202122232425&gt;&gt;&gt;from blog.models import Blog&gt;&gt;&gt;from blog.models import BlogType&gt;&gt;&gt;from django.contrib.auth.models import User# 常用&gt;&gt;&gt;Blog.objects.all()&gt;&gt;&gt;BlogType.objects.all()&gt;&gt;&gt;User.objects.all()# 实例化&gt;&gt;&gt;blog = Blog()&gt;&gt;&gt;blog.title = 'shell下第1篇'&gt;&gt;&gt;blog.content = 'xxxxxxxxxxxxxxx'&gt;&gt;&gt;blog_type = BlogType.objects.all()[0]&gt;&gt;&gt;blog.blog_type = blog_type&gt;&gt;&gt;user = User.objects.all()[0]&gt;&gt;&gt;blog.author = user# 保存&gt;&gt;&gt;blog.save()#批量添加&gt;&gt;&gt;for i in range(1,31):... blog = Blog()... blog.title = "for %s" % i... blog.content = 'xxxx:%s' % i... blog.blog_type = blog_type... blog.author = user... blog.save() 网页搭建使用模版 应用目录下创建文件夹templates，然后创建html文件，编辑view.py，类似以下编辑： 1234567891011from django.shortcuts import renderfrom article.models import Articledef article_detail(request, article_id): try: article = Article.objects.get(id=article_id) context = &#123;&#125; context['article_obj'] = article return render(request, "article_detail.html", context) except Article.DoesNotExist: raise Http404('不存在') 也可以使用render_to_response方法： 123from django.shortcuts import render_to_response...... return render_to_response("article_detail.html", context) 还有get_object_or_404方法： 12345678from django.shortcuts import render_to_response,get_object_or_404from article.models import Articledef article_detail(request, article_id): article = get_object_or_404(Article, pk=article_id) context = &#123;&#125; context['article_obj'] = article return render_to_response("article_detail.html", context) html文件类似： 123456789&lt;html&gt; &lt;head&gt; &lt;body&gt; &lt;h2&gt;&#123;&#123; article_obj.title &#125;&#125;&lt;/h2&gt; &lt;hr&gt; &lt;p&gt;&#123;&#123; article_obj.content &#125;&#125;&lt;/p&gt; &lt;/body&gt; &lt;/head&gt;&lt;/html&gt; 创建目录 创建目录html页面，在urls里绑定，使用循环来遍历文章id，使用pk而不是id是更保险的写法。 123456789&lt;html&gt; &lt;head&gt; &lt;body&gt; &#123;% for article in articles %&#125; &lt;a href="/article/&#123;&#123; article.pk &#125;&#125;"&gt;&#123;&#123; article.title &#125;&#125;&lt;/a&gt; &#123;% endfor %&#125; &lt;/body&gt; &lt;/head&gt;&lt;/html&gt; 超链接部分也可以用这种写法： 1&lt;a href="&#123;% url 'article_detail' article.pk %&#125;"&gt;&#123;&#123; article.title &#125;&#125;&lt;/a&gt; url合并 如果有很多应用，按之前的写法，url会太臃肿，因此可以在应用下新建urls.py： 1234567from django.urls import pathfrom . import viewsurlpatterns = [ path('&lt;int:article_id&gt;', views.article_detail, name='article_detail'), path('', views.article_list, name='article_list'),] 相应的，项目下url可改为： 123456789from django.contrib import adminfrom django.urls import include,pathfrom . import viewsurlpatterns = [ path('admin/', admin.site.urls), path('',views.index), path('article/',include('article.urls')),] 使用html模版 为了减少重复html代码的使用，可以使用block块来标记可替代内容，首先在项目根目录下创建templates文件夹，创建base.html并写入以下内容： 123456789101112131415&lt;!-- &#123;% block &lt;别名&gt;%&#125;&#123;% endblock %&#125; --&gt;&lt;!DOCTYPE html&gt;&lt;html lang="zh-cn"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;a href="&#123;% url 'home' %&#125;"&gt;&lt;h3&gt;个人博客网站&lt;/h3&gt;&lt;/a&gt; &lt;/div&gt; &lt;hr&gt; &#123;% block content %&#125;&#123;% endblock %&#125;&lt;/body&gt;&lt;/html&gt; 与之相应地，可以在其他的html文件中，省略这些内容，只需要用extends引用，再到block块中填充即可，例如blog_list.html： 123456789101112131415161718192021&lt;!-- &#123;% extends 'base.html' %&#125; --&gt;&lt;!-- &#123;% block &lt;别名&gt;%&#125;&#123;% endblock %&#125; --&gt;&#123;% extends 'base.html' %&#125;&#123;# 页面标题 #&#125;&#123;% block title %&#125; 我的网站&#123;% endblock %&#125;&#123;# 页面内容 #&#125;&#123;% block content %&#125; &#123;% for blog in blogs %&#125; &lt;a href="&#123;% url 'blog_detail' blog.pk%&#125;"&gt; &lt;h3&gt;&#123;&#123; blog.title &#125;&#125;&lt;/h3&gt; &lt;/a&gt; &lt;p&gt;&#123;&#123; blog.content|truncatechars:30 &#125;&#125;&lt;/p&gt; &#123;% empty %&#125; &lt;p&gt;-- 暂无博客，敬请期待 --&lt;/p&gt; &#123;% endfor %&#125; &lt;p&gt;一共有&#123;&#123; blogs|length&#125;&#125;篇文章&lt;/p&gt;&#123;% endblock %&#125; 然后在项目文件夹中的setting.py中编辑TEMPLATES的DIRS列表，加入os.path.join(BASE_DIR, &#39;templates&#39;)。 使用css 在项目目录下新建static文件夹，写入base.css文件： 123456789101112131415161718* &#123; margin: 0; padding: 0;&#125;div.nav &#123; background-color: #eee; border-bottom: 1px solid #ccc; padding: 10px 5px&#125;div.nav a&#123; text-decoration: none; color:black; padding: 5px 10px;&#125;div.nav a.logo &#123; display: inline-block; font-size: 120%;&#125; 然后在项目文件夹中的setting.py中加入： 123STATICFILES_DIRS = [ os.path.join(BASE_DIR, 'static'),] 引用方法： 1234567&lt;!-- head中写入 --&gt;&lt;link rel="stylesheet" href="/static/base.css"&gt; &lt;!-- 也可以用django自带方法，在html顶部写入 --&gt;&#123;% load staticfiles %&#125;&lt;!-- 再到head中写入 --&gt;&lt;link rel="stylesheet" href="&#123;% static 'base.css'%&#125;"&gt; 使用css框架Bootstrap基础 访问官网，下载新版Bootstrap，保留以下文件，放在项目static的新建的Bootstrap文件夹中： 1234567css bootstrap.min.css bootstrap.min.css.mapfont alljs bootstrap.min.js 参考文档，如果需要导入，可按如下代码： 12345678910111213141516171819&#123;% load staticfiles %&#125;&lt;!DOCTYPE html&gt;&lt;html lang="zh-cn"&gt;&lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;meta http-equiv="X-UA-Compatible" content="IE=edge"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1"&gt; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt; &lt;link rel="stylesheet" href="&#123;% static 'base.css' %&#125;"&gt; &lt;link rel="stylesheet" href="&#123;% static 'bootstrap-3.3.7/css/bootstrap.min.css' %&#125;"&gt; &lt;script type="text/javascript" src="&#123;% static 'jquery-1.12.4.min.js' %&#125;"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="&#123;% static 'bootstrap-3.3.7/js/bootstrap.min.js' %&#125;"&gt;&lt;/script&gt; &#123;% block header_extends %&#125; &lt;!-- 此处可以被其他html文件继承，用于加载css文件 --&gt; &#123;% endblock %&#125;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt; 栅格系统 类前缀从超小到大分别为.col-xs-、.col-sm-、.col-md-、.col-lg-，也可以使用类如.visible-xs-block、.hidden-xs来显示或者隐藏，使用 例如.col-md-offset- 1类可以将列向右侧偏移。 1234&lt;div class="row"&gt; &lt;div class="col-md-8"&gt;.col-md-8&lt;/div&gt; &lt;div class="col-md-4"&gt;.col-md-4&lt;/div&gt;&lt;/div&gt; 分页基础 shell中可以大致了解分页器的功能： 1234567891011&gt;&gt;&gt;from django.core.paginator import Paginator&gt;&gt;&gt;from blog.models import Blog&gt;&gt;&gt;blogs = Blog.objects.all()&gt;&gt;&gt;paginator = Paginator(blogs, 10)# 常用&gt;&gt;&gt;paginator.count&gt;&gt;&gt;paginator.num_pages&gt;&gt;&gt;paginator.page_range# 赋值&gt;&gt;&gt;page1 = paginator.page(1)&gt;&gt;&gt;page1.object_list 修改views.py 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455def blog_list(request): blogs_all_list = Blog.objects.all() paginator = Paginator(blogs_all_list, settings.EACH_PAGE_BLOGS_NUMBER) # 每10篇为1页 page_num = request.GET.get("page", 1) # 获取url页码参数（GET请求） page_of_blogs = paginator.get_page(page_num) current_page_num = page_of_blogs.number #获取当前页码 # 获取当前页码前后各两位的范围 # page_range = list(range(max(current_page_num - 2, 1), current_page_num)) + \ # list(range(current_page_num, min(current_page_num + 2, paginator.num_pages) + 1)) page_range = [x for x in range(current_page_num-2, current_page_num+3) if (x&gt;0 and x&lt;paginator.num_pages + 1)] # 加上首页和尾页以及省略页码标记 if page_range[0] - 1 &gt;= 2: page_range.insert(0,'...') if paginator.num_pages - page_range[-1] &gt;= 2: page_range.append('...') if page_range[0] != 1: page_range.insert(0,1) if page_range[-1] != paginator.num_pages: page_range.append(paginator.num_pages) context = &#123;&#125; context['blogs'] = page_of_blogs.object_list context['page_of_blogs'] = page_of_blogs context['page_range'] = page_range context['blog_types'] = BlogType.objects.all() # context['blogs_count'] = Blog.objects.all().count() return render_to_response('blog/blog_list.html',context)def blogs_with_type(request, blog_type_pk): blog_type = get_object_or_404(BlogType, pk=blog_type_pk) blogs_all_list = Blog.objects.filter(blog_type=blog_type) paginator = Paginator(blogs_all_list, settings.EACH_PAGE_BLOGS_NUMBER) # 每10篇为1页 page_num = request.GET.get("page", 1) # 获取url页码参数（GET请求） page_of_blogs = paginator.get_page(page_num) current_page_num = page_of_blogs.number #获取当前页码 # 获取当前页码前后各两位的范围 # page_range = list(range(max(current_page_num - 2, 1), current_page_num)) + \ # list(range(current_page_num, min(current_page_num + 2, paginator.num_pages) + 1)) page_range = [x for x in range(current_page_num-2, current_page_num+3) if (x&gt;0 and x&lt;paginator.num_pages + 1)] # 加上首页和尾页以及省略页码标记 if page_range[0] - 1 &gt;= 2: page_range.insert(0,'...') if paginator.num_pages - page_range[-1] &gt;= 2: page_range.append('...') if page_range[0] != 1: page_range.insert(0,1) if page_range[-1] != paginator.num_pages: page_range.append(paginator.num_pages) context = &#123;&#125; context['blog_type'] = blog_type context['blogs'] = page_of_blogs.object_list context['page_of_blogs'] = page_of_blogs context['page_range'] = page_range context['blog_types'] = BlogType.objects.all() # context['blogs_count'] = Blog.objects.all().count() return render_to_response('blog/blogs_with_type.html',context) 修改blog_list.html: 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;div class="paginator"&gt; &lt;ul class="pagination"&gt; &lt;!-- 上一页 --&gt; &lt;li&gt; &#123;% if page_of_blogs.has_previous %&#125; &lt;a href="?page=&#123;&#123; page_of_blogs.previous_page_number &#125;&#125;" aria-label="Previous"&gt; &lt;span aria-hidden="true"&gt;&amp;laquo;&lt;/span&gt; &lt;/a&gt; &#123;% else %&#125; &lt;span aria-hidden="true"&gt;&amp;laquo;&lt;/span&gt; &#123;% endif %&#125; &lt;/li&gt; &lt;!-- 全部页码 --&gt; &#123;% for page_num in page_range %&#125; &#123;% if page_num == page_of_blogs.number %&#125; &lt;li class='active'&gt;&lt;span&gt;&#123;&#123; page_num &#125;&#125;&lt;/span&gt;&lt;/li&gt; &lt;!-- &lt;li class='active'&gt;&lt;a href="?page=&#123;&#123; page_num &#125;&#125;"&gt;&#123;&#123; page_num &#125;&#125;&lt;/a&gt;&lt;/li&gt; --&gt; &#123;% else %&#125; &#123;% if page_num == '...' %&#125; &lt;li&gt;&lt;span&gt;&#123;&#123; page_num &#125;&#125;&lt;/span&gt;&lt;/li&gt; &#123;% else %&#125; &lt;li&gt;&lt;a href="?page=&#123;&#123; page_num &#125;&#125;"&gt;&#123;&#123; page_num &#125;&#125;&lt;/a&gt;&lt;/li&gt; &#123;% endif %&#125; &#123;% endif %&#125; &#123;% endfor %&#125; &lt;!-- 下一页 --&gt; &lt;li&gt; &#123;% if page_of_blogs.has_next %&#125; &lt;a href="?page=&#123;&#123; page_of_blogs.next_page_number &#125;&#125;" aria-label="Next"&gt; &lt;span aria-hidden="true"&gt;&amp;raquo;&lt;/span&gt; &lt;/a&gt; &#123;% else %&#125; &lt;span aria-hidden="true"&gt;&amp;raquo;&lt;/span&gt; &#123;% endif %&#125; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt; 共有&#123;&#123; page_of_blogs.paginator.count&#125;&#125;篇博客， 当前第&#123;&#123; page_of_blogs.number &#125;&#125;页，共&#123;&#123; page_of_blogs.paginator.num_pages &#125;&#125;页 &lt;/p&gt;&lt;/div&gt; 上一页/下一页 编辑views.py，其中__gt表示大于，同理lt为小于： 1234567def blog_detail(request,blog_pk): context = &#123;&#125; blog = get_object_or_404(Blog, pk=blog_pk) context['next_blog'] = Blog.objects.filter(created_time__gt=blog.created_time).last() context['previous_blog'] = Blog.objects.filter(created_time__lt=blog.created_time).first() context['blog'] = blog return render_to_response('blog/blog_detail.html',context)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[相似度计算的python实现]]></title>
    <url>%2F2019%2F01%2F03%2F%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%AE%A1%E7%AE%97%E7%9A%84python%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[在数据挖掘中有很多地方要计算相似度，计算相似度有欧几里德距离、曼哈顿距离、皮尔逊相关度、Jaccard系数和Tanimoto系数等等，这里暂时列出以下几种计算方法。 欧几里得距离 欧几里得距离（Euclidean distance）是一个通常采用的距离定义，指在m维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离），在二维和三维空间中的欧氏距离就是两点之间的实际距离。 在Python中，可以调用scikit-learn中现成的轮子实现： 12from sklearn.metrics.pairwise import euclidean_distancesdistance = euclidean_distances(i1,i2) 因为计算是基于各维度特征的绝对数值，所以欧氏距离需要保证各维度指标在相同的刻度级别，比如对身高（cm）和体重（kg）两个单位不同的指标是不适用于欧氏距离的。 此外，欧几里得距离是数据上的直观体现，在处理一些受主观影响很大的评分数据时，效果则不太明显；比如，person1对item1,item2 分别给出了2分，4分的评价;person2则给出了4分，8分的评分。通过分数可以大概看出，二个人口味相同，但是第二个人评价稍高。在逻辑上，是可以给出两用户兴趣相似度很高的结论。如果此时用欧式距离来处理，则不能得到这样的结论。即评价者的评价相对于平均水平偏离很大的时候欧几里德距离不能很好的揭示出真实的相似度。 曼哈顿距离 曼哈顿距离（Manhattan Distance）又叫出租车距离或者马氏距离，是由十九世纪的赫尔曼·闵可夫斯基所创词汇 ，是种使用在几何度量空间的几何学用语，用以标明两个点在标准坐标系上的绝对轴距总和。 对于空间向量(x1,x2,x3,…,xn)和(y1,y2,y3,…,yn)，曼哈顿距离的定义为： 同样可以调用scikit-learn中函数： 12from sklearn.metrics.pairwise import manhattan_distancesdistance = manhattan_distances(i1,i2) 余弦相似度 余弦相似度，是用向量空间中两个向量夹角的余弦值作为衡量两个个体间差异的大小的度量。余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫”余弦相似性”。余弦相似度衡量的是维度间取值方向的一致性，注重维度之间的差异，不注重数值上的差异，而欧氏度量的正是数值上的差异性。 调用scikit-learn中函数: 12from sklearn.metrics.pairwise import cosine_similaritysimilarity = cosine_similarity(i1,i2) 也可以使用cosine_distances函数，他们的关系是：余弦距离= 1 - 余弦相似度。 皮尔逊相关系数 Pearson相关系数是用协方差除以两个变量的标准差得到的，虽然协方差能反映两个随机变量的相关程度（协方差大于0的时候表示两者正相关，小于0的时候表示两者负相关），但其数值上受量纲的影响很大，不能简单地从协方差的数值大小给出变量相关程度的判断。为了消除这种量纲的影响，于是就有了相关系数的概念。 当两个变量的方差都不为零时，相关系数才有意义，相关系数的取值范围为[-1,1]。当相关系数为1时，成为完全正相关；当相关系数为-1时，成为完全负相关；相关系数的绝对值越大，相关性越强；相关系数越接近于0，相关度越弱。 可以使用scipy中现有轮子： 12from scipy.stats import pearsonrcor = pearsonr(i1,i2) 返回为一个元组，第一项为Pearson相关系数，第二项为p-value。 Jaccard系数 Jaccard系数用于比较有限样本集之间的相似性与差异性。当数据集为二元变量时，我们只有两种状态：0或者1，这时候可以使用它来表征相似度。Jaccard系数值越大，样本相似度越高。 在Python中构建函数如下： 1234567891011def getJaccardCoefficient(p1,p2): x1 = p1[p1&gt;0] x2 = p2[p2&gt;0] si = &#123;&#125; for item in list(x1.index): if item in list(x2.index): si[item] = 1 n = len(si) if n == 0: return 0 return n/(len(x1)+len(x2)-n) Tanimoto系数 Tanimoto系数，又称为广义Jaccard系数，Jaccard系数是xy都是二值向量时的特殊情况，在这种情况下Tanimoto系数就等同Jaccard系数。 在Python中构建函数如下： 1234567891011121314def getTanimotoCoefficient(p1,p2): x1 = p1[p1&gt;0] x2 = p2[p2&gt;0] si = &#123;&#125; for item in list(x1.index): if item in list(x2.index): si[item] = 1 n = len(si) if n == 0: return 0 sum1 = sum([pow(it,2) for it in x1]) sum2 = sum([pow(it,2) for it in x2]) sumco = sum([x1[it]*x2[it] for it in si]) return sumco/(sum1+sum2-sumco)]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Machine Learning</tag>
        <tag>Data Mining</tag>
        <tag>Similarity</tag>
        <tag>Euclidean distance</tag>
        <tag>Manhattan distance</tag>
        <tag>Pearson coefficient</tag>
        <tag>Jaccard coefficient</tag>
        <tag>Tanimoto coefficient</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些可能用得上的点]]></title>
    <url>%2F2018%2F12%2F26%2F%E4%B8%80%E4%BA%9B%E5%8F%AF%E8%83%BD%E7%94%A8%E5%BE%97%E4%B8%8A%E7%9A%84%E7%82%B9%2F</url>
    <content type="text"><![CDATA[记录一下以后可能用得上的点。 MOE相关Lipinski的五倍律 满足下面标准中的至少两条，则该化合物的被动吸收能力或者膜渗透性将较差，难以通过口服吸收： Weight：相对分子质量大于500Da logP(o/w)：具有高亲脂性即clgP&gt;5 lip_don：氢键供体数大于5（—OH和—NH之和） lip_acc：氢键受体数大于10（O原子和N原子之和） b_rotN：含有多于5个可旋转键，以限制其构象柔性 此外，moe还有一项lip_violation，以提示Lipinski五倍律违反数。 以多mpu运行 CMD下运行，%MOE%为MOE根目录： 12%MOE%\bin\moe -mpu 2// 数字为调用mpu数目 计算cats描述符 SVL输入： 12db_cats [,3]// 后面为切片，以1为起始 RDKit相关计算Morgan指纹 当radius=2时，即为ECFP4 ，nBits为长度。 123from rdkit import Chemm1 = Chem.MolFromSmiles('Cc1ccccc1')fp1 = Chem.AllChem.GetMorganFingerprintAsBitVect(m1,2,nBits=1024)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Cheminformatics</tag>
        <tag>MOE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[k-近邻算法]]></title>
    <url>%2F2018%2F12%2F25%2Fk-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[最近打算系统的回顾一下机器学习算法，所以以《机器学习实战》为依据，这次就由k-近邻算法开始回顾。 k-近邻算法概述 k-近邻算法（K-Nearest Neighbor ）的工作原理是：存在一个样本数据集合，也称为训练样本集，并且样本集中每个数据都存在标签，即我们知道样本集中每一数据与所属分类对应的关系。输入没有标签的新数据后，将新数据中的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。 以使用k-近邻算法分类爱情片和动作片，有人统计过很多电影的打斗镜头和接吻镜头如下表，假如有一部未看过的电影，以？来表示，如何确定它是爱情片和动作片呢？ 电影名称 打斗镜头 接吻镜头 电影类型 Califoria Man 3 104 爱情片 He’s Not Really into Dudes 2 100 爱情片 Beautigul Woman 1 81 爱情片 Kevin Longblade 101 10 动作片 Robo Slayer 3000 99 5 动作片 Amped II 98 2 动作片 ? 18 90 未知 在KNN中，通过计算对象间距离来作为各个对象之间的非相似性指标，避免了对象之间的匹配问题，在这里距离一般使用欧氏距离或曼哈顿距离： 我们用欧氏距离来得到如下距离值： 电影名称 与未知电影的距离 Califoria Man 20.5 He’s Not Really into Dudes 18.7 Beautigul Woman 19.2 Kevin Longblade 115.3 Robo Slayer 3000 117.4 Amped II 118.9 按照距离递增排序，可以找到k个距离最近的电影。假设k=3，则三个最靠近的电影依次是He’s Not Really into Dudes、Beautigul Woman和Califoria Man。k-近邻算法按照距离最近的三部电影的类型，决定未知电影的类型，而这三部电影全是爱情片，因此我们判定未知电影是爱情片。 准备：使用Python导入数据 首先，创建名为KNN.py的python模块： 1234567import numpy as npimport operatordef createDataSet(): group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]]) labels = ['A','A','B','B'] return group, labels 这里我们准备了4组数据，每组数据有两个我们已知的属性或者特征值。接下来我们将完成分类任务。 实施KNN分类算法 定义函数classify0()如下： 1234567891011121314151617def classify0(inX, dataSet, labels, k): dataSetSize = dataSet.shape[0] #用于计算欧氏距离 #将intX在纵向重复dataSetSize次 diffMat = np.tile(inX, (dataSetSize,1)) - dataSet sqDiffMat = diffMat**2 sqDistances = sqDiffMat.sum(axis=1) distances = sqDistances**0.5 #返回从小到大的索引值 sortedDistIndicies = distances.argsort() classCount=&#123;&#125; for i in range(k): voteIlabel = labels[sortedDistIndicies[i]] classCount[voteIlabel] = classCount.get(voteIlabel,0) + 1 #按第二个元素的次序，对元组进行逆序排序，即从大到小排序，返回发生频率最高的元素标签 sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True) return sortedClassCount[0][0] 至此，我们构建了第一个分类器。 示例：使用k-近邻算法改进约会网站的配对效果 海伦一直使用在线约会网站寻找自己的约会对象，她把自己交往过的对象分为以下三类： 不喜欢的人 魅力一般的人 极具魅力的人 因此，她希望更好地将她匹配的对象分类。 准备数据：从文本文件中解析数据 她把数据存放在文本文件datingTestSet2.txt中，每个样本数据占据一行，主要包含以下3种特征： 每年获得的飞行常客里程数 玩视频游戏所耗时间百分比 每周消费的冰淇淋公升数 创建名为file2matrix的函数，把数据转变为分类器可以接受的格式。 1234567891011121314151617def file2matrix(filename): fr = open(filename) arrayOlines = fr.readlines() # 得到文件行数 numberOfLines = len(arrayOlines) # 创建返回的NumPy矩阵 returnMat = np.zeros((numberOfLines,3)) classLabelVector = [] index = 0 # 解析文件数据到列表 for line in arrayOlines: line = line.strip() listFromLine = line.split('\t') returnMat[index,:] = listFromLine[0:3] classLabelVector.append(int(listFromLine[-1])) index += 1 return returnMat,classLabelVector 接下来图形化展示数据内容。 分析数据：使用Matplotlib创建散点图 定义一个scatterPlot函数进行可视化。 12345678import matplotlibimport matplotlib.pyplot as pltdef scatterPlot(): fig = plt.figure() ax = fig.add_subplot(111) p = ax.scatter(datingDateMat[:,1], datingDateMat[:,2], 15.0*np.array(datingLabels), 15.0*np.array(datingLabels)) plt.show() 得到了玩视频游戏所耗时间百分比和每周消费的冰淇淋公升数的关系散点图： 同理也能得到每年获得的飞行常客里程数和玩视频游戏所耗时间百分比的关系散点图，可以得到更好的展示效果： 可以知道具有不同的爱好的人其类别区域也不同。 准备数据：归一化数值 玩视频游戏所耗时间百分比 每年获得的飞行常客里程数 每周消费的冰淇淋公升数 样本分类 1 0.8 400 0.5 1 2 12 134000 0.9 3 3 0 20000 1.1 2 4 67 32000 0.1 2 上表给出提取的四组数据，要计算样本3和4的距离，使用以下方法： 容易发现，上面方程中数值差值最大的属性对计算结果的影响最大，也就是说，每年获取的飞行常客里程数对于计算结果的影响将远远大于该表其他两个特征的影响。而三种特征是同等重要的，因此需要把数值归一化。 增加函数autoNorm用于归一化： 123456789def autoNorm(dataSet): minVals = dataSet.min(0) maxVals = dataSet.max(0) ranges = maxVals - minVals normDateSet = np.zeros(np.shape(dataSet)) m = dataSet.shape[0] normDateSet = dataSet - np.tile(minVals, (m,1)) normDateSet = normDateSet/np.tile(ranges, (m,1)) return normDateSet, ranges, minVals 在机器学习框架scikit-learn中，有封装好的标准化函数： 1234567891011# 归一化from sklearn.preprocessing import MinMaxScalerss = MinMaxScaler()X = ss.fit_transform(X)# 标准化from sklearn.preprocessing import StandardScalerss = StandardScaler()X = ss.fit_transform(X)#归一化其实就是标准化的一种方式，只不过归一化是将数据映射到了[0,1]这个区间中。#标准化则是将数据按照比例缩放，使之放到一个特定区间中。标准化后的数据的均值＝0，标准差＝1，因而标准化的数据可正可负。 测试算法：作为完整程序验证分类器 创建函数datingClassTest以测试分类器效果： 123456789101112def datingClassTest(): hoRatio = 0.10 datingDataMat,datingLabels = file2matrix('datingTestSet2.txt') normMat, ranges, minVals = autoNorm(datingDataMat) m = normMat.shape[0] numTestVecs = int(m*hoRatio) errorCount = 0.0 for i in range(numTestVecs): classifierResult = classify0(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3) print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, datingLabels[i])) if (classifierResult != datingLabels[i]): errorCount += 1.0 print("the total error rate is: %f" % (errorCount/float(numTestVecs))) 通过分类器可得错误率为5%，结果还不错，也可以改变hoRatio和k来得到不同结果。 这个例子表明我们可以得到较好的分类结果，海伦可以输入未知对象的属性，由分类软件来帮助她判定某一对象的可交往程度：讨厌、一般喜欢、非常喜欢。 示例：手写识别系统 上面的例子使用的数据比较容易理解，如何在人不太容易看懂的数据上使用分类器呢？我们将使用k-近邻分类器用于手写数字识别。 准备数据：将图像转换为测试向量 首先把图像格式化处理为一个向量。即将32×32的二进制文本。如果要使用我们的分类器，就将其变成1×1024的向量。 编写函数实现： 12345678def img2vector(filename): returnVect = np.zeros((1,1024)) fr = open(filename) for i in range(32): lineStr = fr.readline() for j in range(32): returnVect[0,32*i+j] = int(lineStr[j]) return returnVect 测试算法：使用k-近邻算法识别手写数字 使用以下代码测试分类器： 1234567891011121314151617181920212223hwLabels = []trainingFileList = os.listdir('trainingDigits') # 读取训练集m = len(trainingFileList)trainingMat = np.zeros((m,1024))for i in range(m): fileNameStr = trainingFileList[i] fileStr = fileNameStr.split('.')[0] # 从文件名解析分类数字 classNumStr = int(fileStr.split('_')[0]) hwLabels.append(classNumStr) trainingMat[i,:] = img2vector('trainingDigits/%s' % fileNameStr)testFileList = os.listdir('testDigits') # 载入测试集errorCount = 0.0mTest = len(testFileList)for i in range(mTest): fileNameStr = testFileList[i] fileStr = fileNameStr.split('.')[0] classNumStr = int(fileStr.split('_')[0]) vectorUnderTest = img2vector('testDigits/%s' % fileNameStr) classifierResult = classify0(vectorUnderTest, trainingMat, hwLabels, 3) print("the classifier came back with: %d, the real answer is: %d" % (classifierResult, classNumStr)) if (classifierResult != classNumStr): errorCount += 1.0print("\nthe total number of errors is: %d" % errorCount)print("\nthe total error rate is: %f" % (errorCount/float(mTest))) 本函数是将trainingDigits目录中的文件内容存储在列表中，然后得到目录中有多少文件，并将其存储到变量m中。接着，创建m行1024列的训练矩阵，该矩阵的每行数据存储一个图像。我们可以从文件名中解析出分类数字。该目录下的文件按照规则命名，如文件9_45.txt的分类是9，它是数字9的第45个实例。然后我们可以将类代码存储到hwLabels向量中，使用前面讨论的img2vector函数载入图像。在下一步中，我们对testDigits目录中的文件执行相似的操作，不同之处是我们并不将这个目录下的文件载入矩阵中，而是使用classify0()函数测试该目录下的每个文件。由于文件中的值已经在0和1之间，并不需要进行标准化。 通过测试本分类器，发现有相对理想的结果。 实际使用本算法时，算法的执行效率并不高。因为算法需要为每个测试向量做2000次距离计算，每个距离计算包括了1024个维度浮点运算，总计要执行9000次，此外还得为测试向量准备2MB的存储空间。是否存在一种算法减少存储空间和计算时间的开销呢？k决策树就是k-近邻算法的优化版，可以节省大量计算开销。 本章小结 k-近邻算法是分类数据最简单最有效的算法，本章通过两个例子蒋旭了如何使用k-近邻算法构造分类器。k-近邻算法是基于实例的学习，使用算法时我们必须有接近实际数据的训练样本数据。k-近邻算法必须保存全部数据集，如果训练数据集很大，必须使用大量的存储空间。此外由于必须对数据集中的每个数据计算距离值，实际使用时可能非常耗时。 k-近邻算法的另一个缺陷是它无法给出任何数据的基础结构信息，因此我们也无法知晓平均实例样本和典型实例样本具有什么特征。可以通过概率测量方法处理分类问题以解决此问题。 参考资料：《机器学习实战》]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Machine Learning</tag>
        <tag>Data Mining</tag>
        <tag>KNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NS开箱]]></title>
    <url>%2F2018%2F07%2F24%2FNS%E5%BC%80%E7%AE%B1%2F</url>
    <content type="text"><![CDATA[想买NS很久了，之前一直听说NS品控不好，还存在变弯风险。所以想等第二代，不过最近价格回落，正好把steam套了点现，就剁手了NS。感觉近来一直在放飞自我，没好好学习，十分惭愧，希望从今天开始好好复习…… 开箱 大概是周六晚上下的单，等了一天多点到货，盒子很朴素： 拆开就能看到主机和2个Joy-Con： 全家福，还有电源、2个腕带、握把、HDMI连接线和底座： 游戏买了个《异度神剑2》的卡带，以及一个《一起剪吧！剪纸狙击手！》，买完才意识到并没有小伙伴一块玩，肥宅留下了悲伤的眼泪。 上个卡带图： 听说卡带是苦的，并不敢去试…… 留个资料页，欢迎有缘人来加好友： 总结 相比于我的3DS，手感要强不少，但是总感觉按键很松。 充电口在下面，有点反人类。另外贴膜没贴好，果然不应该自己贴膜的……老任的做工确实很烂，希望我的NS不会弯吧~]]></content>
      <categories>
        <category>生活记录</category>
      </categories>
      <tags>
        <tag>Unboxing</tag>
        <tag>Nintendo</tag>
        <tag>Switch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AirPods开箱]]></title>
    <url>%2F2018%2F05%2F29%2FAirPods%E5%BC%80%E7%AE%B1%2F</url>
    <content type="text"><![CDATA[懒癌发作，好久没更博客了，发一篇开箱（伪）凑数吧…… 一直挺想用蓝牙耳机的，之前在索尼的降噪豆和AirPods之间纠结，考虑到对于降噪需求并不是很大，所以最终还是选了AirPods，就是喜欢白色的，颜值即正义。 首先是盒子： 打开后来个全家福，正好之前的原装数据线坏了，可以做个备用。必须吐槽苹果的垃圾原装线，用久了要么就是一面不能充电，要么就是开胶，质量还不如几十块的。 盒子内： 拿出来： 说下使用体会吧，感觉上还是挺好用的，戴着很舒服，不容易掉。和IPhone完美契合，配对很方便，使用中拿下一边耳机自动暂停播放，放回去自动开始。虽然只能设置简单的控制，对我来说基本够用。连接电脑声音有点小，得调很大才行，这点不太好，勉强可以接受吧。至于音质，也就听个响的样子，不能指望有多强了~ 希望不会丢……]]></content>
      <categories>
        <category>生活记录</category>
      </categories>
      <tags>
        <tag>Unboxing</tag>
        <tag>Earphone</tag>
        <tag>Apple</tag>
        <tag>AirPods</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[类似“超强智商”之类的答题游戏作弊思路]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%B1%BB%E4%BC%BC%E2%80%9C%E8%B6%85%E5%BC%BA%E6%99%BA%E5%95%86%E2%80%9D%E4%B9%8B%E7%B1%BB%E7%9A%84%E7%AD%94%E9%A2%98%E6%B8%B8%E6%88%8F%E4%BD%9C%E5%BC%8A%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[今年年初时答题游戏比较火，对于一些比较热门的游戏，已经有不少成熟的辅助程序了。然而这个实验室同学转给我的这个小程序，似乎热度还达不到做辅助的标准，而题目又比较恶心，自己答起来比较费劲，所以在这里探讨一下作弊的思路。 利用图像识别的思路 很容易想到的一个思路就是把手机屏幕投射到屏幕，这里可以用模拟器/ADB/TeamViewer等方案，然后截图，利用tesseract-ocr将图片识别成文字，最后调用百度搜题。 安装必要库就不赘叙了，有需要日后再补。我是采用了模拟器的方案，简单写出代码如下： 12345678910111213141516171819202122import win32gui, win32ui, win32con, win32apifrom PIL import Imageimport pytesseractimport webbrowserdef window_capture(filename): hwnd = 0 hwndDC = win32gui.GetWindowDC(hwnd) mfcDC = win32ui.CreateDCFromHandle(hwndDC) saveDC = mfcDC.CreateCompatibleDC() saveBitMap = win32ui.CreateBitmap() w = 480 h = 120 saveBitMap.CreateCompatibleBitmap(mfcDC,w,h) saveDC.SelectObject(saveBitMap) saveDC.BitBlt((0,0),(w,h),mfcDC,(50,320),win32con.SRCCOPY) saveBitMap.SaveBitmapFile(saveDC,filename)window_capture('cqzs.jpg')text=pytesseract.image_to_string(Image.open('cqzs.jpg'),lang='chi_sim')new_text =''.join(text.split())url = 'http://www.baidu.com/s?wd=%s' % new_textwebbrowser.open(url) 其中w，h为截图框大小参数，还需要根据实际情况调整定位，以便完整截图。 实际使用情况图片识别大致能让人满意，然而效率上有点低，整个过程大概要3-5秒，只剩一半左右的时间答题，所以希望有更好的方案。 利用抓包的思路 通过Fiddler抓包发现，每次12道题以json的形式一次性直接传递过来，因此可以在答题倒计时时就直接把12道题一块搜，这样每道题基本上有10秒时间作答，比上面的方案充裕了不少。 安装的过程略，需要修改FiddlerScript使其输出题目。代码如下： 123456789101112131415161718import jsonimport webbrowserstat = Truewhile stat == True: try: file = open("d:\\python\\temp\\cqzs.txt","r",encoding="utf-8") j = json.loads(file.read()) if 'game' in j['data']: question_list = j['data']['game']['question_list'] for q in question_list: title = q['title'] url = 'http://www.baidu.com/s?wd=%s' % title webbrowser.open(url) stat = False file.close() except: pass 进一步改进方案 这样只是把每道题用百度搜了一下，还需要人工判断，可以考虑用通过词频比对选择答案，或者多平台搜索集合之类的方案。以后有机会再补。 结局 奖品虽然最低只需要通关5次，但是不包邮，强烈怀疑奖品价值够不上邮费。想免邮费最低需要通关25次，考虑到麻烦程度，溜了溜了~]]></content>
      <categories>
        <category>不务正业</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Pytesseract</tag>
        <tag>Fiddler</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将SMILES转成InChiKey]]></title>
    <url>%2F2018%2F04%2F21%2F%E5%B0%86SMILES%E8%BD%AC%E6%88%90InChiKey%2F</url>
    <content type="text"><![CDATA[最近在项目中需要将SMILES转成InChiKey，通常可以在OpenBabelGUI中操作完成，但是对于大量数据在OpenBabelGUI中操作就有些不方便且容易失误。这里记录一下我解决这个问题的过程。 安装相关包 先建立一个虚拟环境，安装RDKit： 1conda create -c rdkit -n my-rdkit-env rdkit 然后在虚拟环境下安装OpenBabel： 1conda install -n my-rdkit-env -c openbabel openbabel 出现的问题 最初想用Pybel实现，然而发现Pybel并不支持输出格式为InChiKey，既然这条路走不通，就换个方案吧。于是想查看OpenBabel的文档看看能不能实现，然而发现这玩意的python接口只是寥寥几言，也没有具体的文档。不过Google到了一个轮子写了如何将SMILES转成InChiKey，代码如下： 1234567import openbabel as obconv = ob.OBConversion()conv.SetInAndOutFormats("smi", "inchi")conv.SetOptions("K", conv.OUTOPTIONS)mol = ob.OBMol()conv.ReadString(mol, "CC(=O)Cl")inchikey = conv.WriteString(mol): 本想着问题解决了，不过试了一下发现并不能用。而且可耻的找不到原因…… 不过也问题不大，RDKit可以把SMILES转成InChi，然后再把InChi变成InChiKey就行了，于是写了个函数实现: 1234567from rdkit import Chemfrom rdkit.Chem.inchi import rdinchidef smiletoinchikey(smile): mol = Chem.MolFromSmiles(smile) inchi = rdinchi.MolToInchi(mol) inchikey = rdinchi.InchiToInchiKey(inchi[0]) return inchikey 然而在处理项目文件时发现，有些SMILES式RDKit不能识别，导致程序出错。如Clc1c([C@@H]2[C@@H]([N+H3])CC(CN3CCC(C(=O)O)CC3)=CC2)ccc(Cl)c1，于是写了个函数利用Pybel将其转成Canonical SMILES。最后还是有一些剩余问题，比如Oc1ccc([C+2]2345[B-2]678[B-3]9%10%11([C-3])[C+]%12%13%14[B-2]%15%169[B-2]26%10[B-2]23%15[B-2]364[B-2]457[B-2]8%11%12[B-2]%1334[B-2]%14%1626)cc1转成Canonical SMILES依然无法读取，又或者O=BOB(OB(OB=O)[O-])[O-]没转换前能读取，转换后不能读取，只能按例外处理。 最后代码如下： 123456789101112131415161718192021222324#!/usr/bin/env python3# -*- coding: utf-8 -*-# @Time : Thu Apr 20 16:12:41 2018# @Author : Catkin# @Website : blog.catkin.moeimport pybelfrom rdkit import Chemfrom rdkit.Chem.inchi import rdinchidef smitosmile(smi): mol = pybel.readstring("smi", smi) smile = mol.write('can') smile = smile.replace('\t\n', '') return smile def smiletoinchikey(smile): mol = Chem.MolFromSmiles(smile) if mol is None: smi = smitosmile(smile) mol = Chem.MolFromSmiles(smi) inchi = rdinchi.MolToInchi(mol) inchikey = rdinchi.InchiToInchiKey(inchi[0]) return inchikey 用OpenBabel同样也可以把SMILES转成Canonical SMILES： 12345678910import openbabel as obdef obsmitosmile(smi): conv = ob.OBConversion() conv.SetInAndOutFormats("smi", "can") conv.SetOptions("K", conv.OUTOPTIONS) mol = ob.OBMol() conv.ReadString(mol, smi) smile = conv.WriteString(mol) smile = smile.replace('\t\n', '') return smile]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>OpenBabel</tag>
        <tag>Pybel</tag>
        <tag>RDKit</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Aero15x开箱]]></title>
    <url>%2F2018%2F04%2F17%2FAero15x%E5%BC%80%E7%AE%B1%2F</url>
    <content type="text"><![CDATA[之前一直在gs65和aero15x中摇摆不定，在已经付了gs65的定金后还是选择了aero15x。主要原因就是aero15x比较好拆，实在不想装个内存、固态或者清灰都跑一趟售后，于是就损失了100定金~ \ (╯-╰) / 16号凌晨下单，等了一天半到手。先来个箱子图： 全部部件，这个适配器真是大，跟块板砖差不多，另外这个光盘是闹哪样，这个本子有光驱吗？自家的AORUS都用U盘了，赢刃还没跟上，真是无力吐槽。 外观，整机是全金属的，感觉做工还算可以，也能单手开合，就是有点指纹收集器的感觉。个人不喜欢太浮夸的外观，这样感觉刚刚好。 下了个娱乐大师，看一眼配置： 之前看别人的拆机内存是芝奇，显示器是LG的，到我变成金士顿和友达，总有点被缩水的感觉…… 跑个分： 由于有后台，跑分比实际水平大概低一点。 来张正面图。 接下来是使用体验：确实和网上说的，有一些小毛病，比如右shift不是很亮，USB接口太紧，然后有时候键盘会双击，强迫症应该会很难受。关键是这些问题去年就有了，到现在也没能解决……至于散热，全靠暴力扇，跑个程序风扇起飞，噪音还是很大的。不过轻薄游戏本要什么自行车，对我来说还是可以接受了。也就不当摸摸党了~]]></content>
      <categories>
        <category>生活记录</category>
      </categories>
      <tags>
        <tag>Unboxing</tag>
        <tag>Gigabyte</tag>
        <tag>Laptop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FP-growth算法]]></title>
    <url>%2F2018%2F02%2F06%2FFP-growth%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[你用过搜索引擎吗？输入一个单词或者一个单词的一部分，搜索引擎就会自动补全查询词项。用户甚至事先都不知道搜索引擎推荐的东西是否存在，反而会去查找推荐词项。那么这些推荐词项是如何被搜索引擎找到的？那是因为研究人员使用了FP-growth算法，它是基于Apriori构建的，但完成相同任务时将数据集存储在一个特定的称作FP树的结构之后发现频繁项集或频繁项对，即常在一起出现的元素项的集合FP树。这是一种比Apriori执行速度更快的算法，能高效地发现频繁项集，但不能用于发现关联规则。 FP-growth算法只需要对数据库进行两次扫描，而Apriori算法对于每个潜在的频繁项集都会扫描数据集判定给定模式是否频繁，因此FP-growth算法的速度比Apriori算法快。在小规模数据上，这不是什么问题，但当处理更大数据集时，就会产生较大问题。FP-growth算法只会扫描数据集两次，它不会生成候选项集，其发现频繁项集的基本过程如下： 构建FP树 从FP树中挖掘频繁项集 FP-growth原理 FP-growth算法将数据存储在一种成为FP树的紧凑数据结构中。FP代表频繁模式（Frequent Pattern）。一颗FP树与计算机科学中其他树结构类似，但它通过链接（link）来连接相似元素，被连起来的元素可以看成一个链表。 下面用一个例子来说明，给出一组数据如下： 事物ID 事物中的元素项 001 r,z,h,j,p 002 z,y,x,w,v,u,t,s 003 z 004 r,x,n,o,s 005 y,r,x,z,q,t,p 006 y,z,x,e,q,s,t,m 由此可以生成一棵FP树： 仔细来看这棵FP树，同搜索树不同，一个元素项可以在一棵FP树中出现多次。FP树会存储项集的出现频率，而每个项集会以路径的方式存储在树中。存在相似元素的集合会共享树的一部分。只有当集合之间完全不同时，树才会分叉。树节点上给出集合中单个元素及其在序列中的出现次数，路径会给出该序列的出现次数。相似项之间的链接，即节点链接（node link），用于快速发现相似项的位置。 上图中，元素项z出现了5次，集合{r, z}出现了1次。于是可以知道：z一定是自己本身或者和其他符号一起出现了4次。再看看其他可能，集合{t, s, y, x, z}出现了2次，集合{t, r, y, x, z}出现了1次。元素项z的右边是5，表示z出现了5次，其中刚才已经给出了4次出现，所以它一定单独出现过1次。005号记录是{y, r, x, z, q, t, p}，那么q、p去哪儿了呢？ 这里使用第11章给出的支持度定义，该指标对应一个最小阈值，低于最小阈值的元素项被认为是不频繁的。若将最小支持度设为3，然后应用频繁项分析算法，就会获得出现3次或3次以上的项集。图中FP树的最小支持度是3，因此p、q并没有出现在树中。 FP-growth算法的工作流程：首先构建FP树，然后利用它来挖掘频繁项集。为了构建FP树，需要对原始数据集扫描两遍。第一遍对所有元素项的出现次数进行计数。记住Apriori原理：如果某元素是不频繁的，那么包含该元素的超集也是不频繁的，所以就不需要考虑超集。数据库的第一遍扫描用来统计出现的频率，第二遍扫描中只考虑那些频繁元素。 构建FP树 首先先用一个容器来保存FP树。 创建FP树的数据结构 创造一个类保存树的每个节点，创建文件fpGrowth.py并加入以下代码： 123456789101112131415161718192021class treeNode : def __init__(self, nameValue, numOccur, parentNode) : # 节点名称 self.name = nameValue self.count = numOccur # 用于链接相似的元素项 self.nodeLink = None # 当前节点的父节点 self.parent = parentNode # 用于存放节点的子节点 self.children = &#123;&#125; # 对count变量增加给定值 def inc(self, numOccur) : self.count += numOccur # 将树以文本的形式显示 def disp(self, ind=1) : print(' '*ind, self.name, ' ', self.count) for child in self.children.values() : child.disp(ind+1) 上面的程序给出了FP树中节点的类定义。类中包含用于存放节点名字的变量和1个计数值，nodeLink变量用于链接相似的元素项（参考上图中的虚线）。类中还使用了父变量parent来指向当前节点的父节点。通常情况并不需要这个变量，因为通常是从上往下迭代访问节点的。如果需要根据给定叶子节点上溯整棵树，这时候就需要指向父节点的指针。最后，类中还包含一个空字典变量，用于存放节点的子节点。 运行一下如下代码： 1234567891011121314&gt;&gt;&gt; import fpGrowth&gt;&gt;&gt; rootNode = fpGrowth.treeNode('pyramid',9,None)# 已创建一个单节点，接下来增加一个子节点&gt;&gt;&gt; rootNode.children['eye'] = fpGrowth.treeNode('eye',13,None)# 显示子节点&gt;&gt;&gt; rootNode.disp() pyramid 9 eye 13# 再添加一个节点&gt;&gt;&gt; rootNode.children['phoenix']=fpGrowth.treeNode('phoenix',3,None)&gt;&gt;&gt; rootNode.disp() pyramid 9 eye 13 phoenix 3 构建FP树 除上图给出的FP树之外，还需要一个头指针表来指向给定类型的第一个实例。利用头指针表，可快速访问FP树中一个给定类型的所有元素。下图给出了一个头指针表的示意图。 这里使用一个字典作为数据结构来保存头指针表。除了存放指针外，头指针表还可以用来保存FP树中每类元素的总数。 第一次遍历数据集会获得每个元素项的出现频率。接着去掉不满足最小支持度的元素项，再来构建FP树。在构建时，读入每个项集并将其添加到一条已经存在的路径中。如果该路径不存在，则创建一条新路径。每个事务就是一个无序集合。假设有集合{z, x, y}和{y, z, r}，那么在FP树中，相同项会只表示一次。为了解决此问题，在将集合添加到树之前，需要对每个集合进行排序。排序基于元素项的绝对出现频率来进行。使用上图中头指针节点值，对前表中数据进行过滤、重排序后的数据显示如下。 事务ID 事务中的元素项 过滤及重排序后的事务 001 r, z, h, j, p z, r 002 z, y, x, w, v, u, t, s z, x, y, s, t 003 z z 004 r, x, n, o, s x, s, r 005 y, r, x, z, q, t, p z, x, y, r, t 006 y, z, x, e, q, s, t, m z, x, y, s, t 在对事务记录过滤和排序之后，就可以构建FP树了。从空集（符号为∅）开始，向其中不断添加频繁项集。过滤、排序后的事务依次添加到树中，如果树中已存在现有元素，则增加现有元素的值；如果现有元素不存在，则向树添加一个分枝。对上表前两条事务进行添加的过程显示如下。 接下来通过代码实现上述过程。在fpGrowth.py加入以下代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# FP树构建函数# 使用数据集以及最小支持度作为参数来构建FP树，树构建过程会遍历数据集两次def createTree(dataSet, minSup=1) : headerTable = &#123;&#125; # 第一次遍历扫描数据集并统计每个元素项出现的频度，这些信息被保存在头指针中 for trans in dataSet : for item in trans : headerTable[item] = headerTable.get(item, 0) + dataSet[trans] # 接着扫描头指针表删除那些出现次数小于minSup的项，由于字典不能在遍历中修改，转成集合 for k in list(headerTable.keys()): if headerTable[k] &lt; minSup : del(headerTable[k]) freqItemSet = set(headerTable.keys()) # 如果所有项都不频繁，无需下一步处理 if len(freqItemSet) == 0 : return None, None # 对头指针表稍加扩展以便可以保存计数值及指向每种类型第一个元素项的指针 for k in headerTable : headerTable[k] = [headerTable[k], None] # 创建只包含空集合的根节点 retTree = treeNode('Null Set', 1, None) for tranSet, count in dataSet.items() : localD = &#123;&#125; # 根据全局频率对每个事务中的元素进行排序 for item in tranSet : if item in freqItemSet : localD[item] = headerTable[item][0] if len(localD) &gt; 0 : orderedItems = [v[0] for v in sorted(localD.items(), key=lambda p : p[1], reverse=True)] # 排序后，调用updateTree()方法 updateTree(orderedItems, retTree, headerTable, count) return retTree, headerTable# 为了让FP树生长，需调用updateTree函数。def updateTree(items, inTree, headerTable, count) : # 该函数首先测试事务中的第一个元素项是否作为子节点存在。 if items[0] in inTree.children : # 如果存在，则更新该元素项的计数 inTree.children[items[0]].inc(count) else : # 如果不存在，则创建一个新的treeNode并将其作为一个子节点添加到树中，这时，头指针表也要更新以指向新的节点。 inTree.children[items[0]] = treeNode(items[0], count, inTree) if headerTable[items[0]][1] == None : headerTable[items[0]][1] = inTree.children[items[0]] else : # 更新头指针表需要调用函数updateHeader updateHeader(headerTable[items[0]][1], inTree.children[items[0]]) # updateTree()完成的最后一件事是不断迭代调用自身，每次调用时会去掉列表中的第一个元素 if len(items) &gt; 1 : updateTree(items[1::], inTree.children[items[0]], headerTable, count)# 确保节点链接指向树中该元素项的每一个实例，从头指针的nodeLink开始，一直沿着nodeLink直到到达链表末尾。# 当处理树的时候，一种自然的反应就是迭代完整每一件事。当以相同方式处理链表时可能会遇到一些问题，# 原因是如果链表很长可能会遇到迭代调用的次数限制def updateHeader(nodeToTest, targetNode) : while (nodeToTest.nodeLink != None) : nodeToTest = nodeToTest.nodeLink nodeToTest.nodeLink = targetNode# 载入数据集def loadSimpDat() : simpDat = [ ['r', 'z', 'h', 'j', 'p' ], ['z', 'y', 'x', 'w', 'v', 'u', 't', 's' ], ['z' ], ['r', 'x', 'n', 'o', 's' ], ['y', 'r', 'x', 'z', 'q', 't', 'p' ], ['y', 'z', 'x', 'e', 'q', 's', 't', 'm' ] ] return simpDat# 从列表向字典的类型转换def createInitSet(dataSet) : retDict = &#123;&#125; for trans in dataSet : retDict[frozenset(trans)] = 1 return retDict 运行结果： 123456789101112131415161718192021222324&gt;&gt;&gt; import fpGrowth&gt;&gt;&gt; simpDat = fpGrowth.loadSimpDat()&gt;&gt;&gt; simpDat[['r', 'z', 'h', 'j', 'p'], ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'], ['z'], ['r', 'x', 'n', 'o', 's'], ['y', 'r', 'x', 'z', 'q', 't', 'p'], ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]&gt;&gt;&gt; initSet = fpGrowth.createInitSet(simpDat)&gt;&gt;&gt; initSet&#123;frozenset(&#123;'j', 'z', 'h', 'p', 'r'&#125;): 1, frozenset(&#123;'u', 's', 'x', 'w', 'y', 'v', 'z', 't'&#125;): 1, frozenset(&#123;'z'&#125;): 1, frozenset(&#123;'s', 'x', 'o', 'n', 'r'&#125;): 1, frozenset(&#123;'q', 'x', 'y', 'z', 't', 'p', 'r'&#125;): 1, frozenset(&#123;'s', 'e', 'q', 'x', 'y', 'z', 'm', 't'&#125;): 1&#125;&gt;&gt;&gt; myFPtree, myHeaderTab = fpGrowth.createTree(initSet, 3)&gt;&gt;&gt; myFPtree.disp() Null Set 1 z 5 r 1 x 3 s 2 y 2 t 2 y 1 t 1 r 1 x 1 s 1 r 1 上面给出的是元素项及其对应的频率计数值，其中每个缩进表示所处的树的深度。 从一棵FP树中挖掘频繁项集 有了FP树之后，就可以抽取频繁项集了。这里的思路与Apriori算法大致类似，首先从单元素项集合开始，然后在此基础上逐步构建更大的集合。当然这里将利用FP树来做实现上述过程，不再需要原始数据集了。从FP树中抽取频繁项集的三个基本步骤如下： 从FP树中获得条件模式基； 利用条件模式基，构建一个条件FP树； 迭代重复步骤1、2，直到树包含一个元素项为止。 重点关注第1步，即寻找条件模式基的过程。之后，为每一条件模式基创建对应的条件FP树。最后需构造少许代码来封装上述两个函数，并从FP树中获得频繁项集。 抽取条件模式基 首先从之前保存在头指针中的单个频繁元素项开始。对于每一个元素项，获得其对应的条件模式(conditional pattern base)。条件模式基是以所查找元素项为结尾的路径集合。每一条路径其实都是一条前缀路径(prefix path)。简而言之，一条前缀路径是介于所查找元素项与树根节点之间的所有内容。 回到图2中，符号r的前缀路径是{x, s}、{z, x, y}和{z}。每条前缀路径都与一个计数值关联。该计数值等于起始元素项的计数值，该计数值给了每条路径上r的数目。下表列出了上例当中每一个频繁项的所有前缀路径： 频繁项 前缀路径 z {}5 r {x, s}1, {z, x, y}1, {z}1 x {z}3, {}1 y {z, x}3 s {z, x, y}2, {x}1 t {z, x, y, s}2, {z, x, y, r}1 前缀路径被用于构建条件FP树，但是暂时先不需要考虑这件事。为了获得这些前缀路径，可以对树进行穷举式搜索，直到获得想要的频繁项为止，或使用一个更有效的方法来加速搜索过程。可以利用先前创建的头指针来得到一种更有效的方法。头指针表包含相同类型元素链表的起始指针。一旦到达了每一个元素项，就可以上溯这棵树直到根节点为止。下面代码给出了如何发现前缀路径，将其添加到文件fpGrowth.py中。 1234567891011121314151617def ascendTree(leafNode, prefixPath) : # 迭代上溯整棵树 if leafNode.parent != None : prefixPath.append(leafNode.name) ascendTree(leafNode.parent, prefixPath)# 遍历链表直到到达结尾。每遇到一个元素项都会调用ascendTree()来上溯FP树，并收集所有遇到的元素项的名称。# 该列表返回之后添加到条件模式基字典condPats中def findPrefixPath(basePat, treeNode) : condPats = &#123;&#125; while treeNode != None : prefixPath = [] ascendTree(treeNode, prefixPath) if len(prefixPath) &gt; 1 : condPats[frozenset(prefixPath[1:])] = treeNode.count treeNode = treeNode.nodeLink return condPats 运行结果 123456&gt;&gt;&gt; fpGrowth.findPrefixPath('x', myHeaderTab['x'][1])&#123;frozenset(&#123;'z'&#125;): 3&#125;&gt;&gt;&gt; fpGrowth.findPrefixPath('z', myHeaderTab['z'][1])&#123;&#125;&gt;&gt;&gt; fpGrowth.findPrefixPath('r', myHeaderTab['r'][1])&#123;frozenset(&#123;'z'&#125;): 1, frozenset(&#123;'s', 'x'&#125;): 1, frozenset(&#123;'z', 't', 'y', 'x'&#125;): 1&#125; 创建条件FP树 对于每个频繁项，都要创建一棵条件FP树。我们会为z、x以及其他频繁项构建条件树。可以使用刚才发现的条件模式基作为输入数据，并通过相同的建树代码来构建这些树。然后，我们会递归地发现频繁项、发现条件模式基，以及发现另外的条件树。举个例子，假定为频繁项 t 创建一个条件FP树，然后对{t, y}、{t, x}、……重复该过程。元素项t的条件FP树的构建过程如下所示。 上图中最初树以空集作为根节点，接着，原始的集合{y, x, s, z}中的集合{y, x, z}被添加进来。因为不满足最小支持度要求，字符s并没有加入进来。类似地，{y, x, z}也从原始集合{y, x, r, z}中添加进来。 元素项s、r是条件模式基的一部分，但它们并不属于条件FP树。单独来看它们都是频繁项，但是在t的条件树中，它们却不是频繁的，也就是说{t, r}、{t, s}是不频繁的。 接下来，对集合{t, z}、{t, x}、{t, y}来挖掘对应的条件树。这会产生更复杂的频繁项集。该过程重复进行，直到条件树中没有元素为止，然后就可以停止了。实现代码很直观，使用一些递归加上之前写的代码即可。具体如下： 12345678910111213141516171819def mineTree(inTree, headerTable, minSup, preFix, freqItemList) : # 对头指针表中元素项按照其出现频率进行排序，默认是从小到大 bigL = [v[0] for v in sorted(headerTable.items(), key=lambda p:p[1][0])] # 默认是从小到大，下面过程是从头指针的底端开始 for basePat in bigL : newFreqSet = preFix.copy() newFreqSet.add(basePat) # 将每个频繁项添加到频繁项集列表freqItemList中 freqItemList.append(newFreqSet) # 使用findPrefixPath()创建条件基 condPattBases = findPrefixPath(basePat, headerTable[basePat][1]) # 将条件基condPattBases作为新数据集传递给createTree()函数 # 这里为函数createTree()添加足够的灵活性，确保它可以被重用于构建条件树 myCondTree, myHead = createTree(condPattBases, minSup) # 如果树中有元素项的话，递归调用mineTree()函数 if myHead != None : print('conditional tree for: ', newFreqSet) myCondTree.disp() mineTree(myCondTree, myHead, minSup, newFreqSet, freqItemList) 效果如下： 123456789101112131415161718192021222324252627282930313233&gt;&gt;&gt; freqItems = []&gt;&gt;&gt; fpGrowth.mineTree(myFPtree, myHeaderTab, 3, set([]), freqItems)conditional tree for: &#123;'s'&#125; Null Set 1 x 3conditional tree for: &#123;'y'&#125; Null Set 1 z 3 x 3conditional tree for: &#123;'y', 'x'&#125; Null Set 1 z 3conditional tree for: &#123;'t'&#125; Null Set 1 z 3 y 3 x 3conditional tree for: &#123;'t', 'y'&#125; Null Set 1 z 3conditional tree for: &#123;'t', 'x'&#125; Null Set 1 y 3 z 3conditional tree for: &#123;'z', 't', 'x'&#125; Null Set 1 y 3conditional tree for: &#123;'x'&#125; Null Set 1 z 3# 检查返回的项集是否与条件树匹配&gt;&gt;&gt; freqItems[&#123;'r'&#125;, &#123;'s'&#125;, &#123;'s', 'x'&#125;, &#123;'y'&#125;, &#123;'y', 'z'&#125;, &#123;'y', 'x'&#125;, &#123;'z', 'y', 'x'&#125;, &#123;'t'&#125;, &#123;'t', 'z'&#125;, &#123;'t', 'y'&#125;, &#123;'t', 'y', 'z'&#125;, &#123;'t', 'x'&#125;, &#123;'t', 'y', 'x'&#125;, &#123;'z', 't', 'x'&#125;, &#123;'z', 't', 'y', 'x'&#125;, &#123;'x'&#125;, &#123;'z', 'x'&#125;, &#123;'z'&#125;] 示例：从新闻网站点击流中挖掘 下列文件kosarak.dat中包含了将近100万条记录。该文件中的每一行包含某个用户浏览过的新闻报道。一些用户只看过一篇报道，而有些用户看过2498篇报道。用户和报道被编码成整数，所以查看频繁项集很难得到更多的东西，但该数据对于展示FP-growth算法的速度十分有效。 数据前几行如下： 12345678910111213141 2 314 5 6 71 89 1011 6 12 13 14 15 161 3 717 1811 6 19 20 21 22 23 241 25 326 311 27 6 3 28 7 29 30 31 32 33 34 35 36 376 2 3839 11 27 1 40 6 41 42 43 44 45 46 47 3 48 7 49 50 51 运用FP-growth算法： 123456789101112131415161718192021222324252627# 导入数据&gt;&gt;&gt; parsedDat = [line.split() for line in open('kosarak.dat').readlines()]# 初始化数据&gt;&gt;&gt; initSet = fpGrowth.createInitSet(parsedDat)# 构建FP树，寻找至少被10万人浏览过的新闻报道&gt;&gt;&gt; myFPtree, myHeaderTab = fpGrowth.createTree(initSet, 100000)# 创建空列表保存频繁项集&gt;&gt;&gt; myFreqList = []&gt;&gt;&gt; fpGrowth.mineTree(myFPtree, myHeaderTab, 100000, set([]), myFreqList)conditional tree for: &#123;'1'&#125; Null Set 1 6 107404conditional tree for: &#123;'3'&#125; Null Set 1 6 186289 11 117401 11 9718conditional tree for: &#123;'11', '3'&#125; Null Set 1 6 117401conditional tree for: &#123;'11'&#125; Null Set 1 6 261773&gt;&gt;&gt; len(myFreqList)9&gt;&gt;&gt; myFreqList[&#123;'1'&#125;, &#123;'1', '6'&#125;, &#123;'3'&#125;, &#123;'11', '3'&#125;, &#123;'11', '6', '3'&#125;, &#123;'6', '3'&#125;, &#123;'11'&#125;, &#123;'11', '6'&#125;, &#123;'6'&#125;] 小结 FP-growth算法是一种用于发现数据集中频繁模式的有效方法。FP-growth算法利用Apriori原则，执行更快。Apriori算法产生候选项集，然后扫描数据集来检查它们是否频繁。由于只对数据集扫描两次，因此FP-growth算法执行更快。在FP-growth算法中，数据集存储在FP树中。FP树构建完成后，可以通过查找元素项的条件基及构建条件FP树来发现频繁项集。该过程不断以更多元素作为条件重复进行，直到FP树只包含一个元素为止。 可以使用FP-growth算法在多种文本文档中查找频繁单词。对Twitter源上的某个话题应用FP-growth算法，可以得到一些有关该话题的摘要信息。频繁项集生成还可以用于购物交易、医学诊断和大气研究等。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Machine Learning</tag>
        <tag>Data Mining</tag>
        <tag>Association Analysis</tag>
        <tag>FP-growth</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录实用的python库]]></title>
    <url>%2F2018%2F02%2F03%2F%E8%AE%B0%E5%BD%95%E5%AE%9E%E7%94%A8%E7%9A%84python%E5%BA%93%2F</url>
    <content type="text"><![CDATA[本文专门用来记录一下python中一些好用方法/库，可以在日常使用中提高效率。 进度条 在爬虫和机器学习等工作中，可能需要有一个进度条能够反馈当前程序运行速度或者进度，可以考虑用以下方法实现： ShowProcess类 在网上找到别人写的一个方法如下： 1234567891011121314151617181920212223242526# 建立一个ShowProcess类class ShowProcess(): i = 0 max_steps = 0 max_arrow = 50 def __init__(self, max_steps): self.max_steps = max_steps self.i = 0 def show_process(self, i=None): if i is not None: self.i = i else: self.i += 1 num_arrow = int(self.i * self.max_arrow / self.max_steps) num_line = self.max_arrow - num_arrow percent = self.i * 100.0 / self.max_steps process_bar = '[' + '&gt;' * num_arrow + '-' * num_line + ']'\ + '%.2f' % percent + '%' print('\r',process_bar,end='',flush=True) def close(self, words='done'): print('') print(words) self.i = 0 使用示例： 12345678910111213if __name__=='__main__': max_steps = 100 process_bar = ShowProcess(max_steps) for i in range(max_steps): process_bar.show_process() time.sleep(0.05) process_bar.close()# 效果如下 &gt;&gt;&gt; [&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;]100.00%&gt;&gt;&gt; done 在命令窗口下使用正常，但是在IDLE和Spyder中显示存在问题，考虑使用其他方法。 tqdm安装1pip install tqdm 使用12345678910111213141516171819202122232425262728293031323334353637383940414243444546# 最基本的用法import timefrom tqdm import tqdmfor i in tqdm(range(9)): time.sleep(0.1)# 效果如下&gt;&gt;&gt; 100%|██████████| 10/10 [00:01&lt;00:00, 9.79it/s]# trange类似于tqdmimport timefrom tqdm import trangefor i in trange(10): time.sleep(0.1)# 效果如下&gt;&gt;&gt; 100%|██████████| 10/10 [00:01&lt;00:00, 9.79it/s]# 传入listimport timefrom tqdm import tqdmpbar = tqdm([1,2,3,4,5,6,7,8,9,10]) for char in pbar: pbar.set_description("Processing %s" % char) time.sleep(0.1)# 效果如下&gt;&gt;&gt; Processing 10: 100%|██████████| 10/10 [00:01&lt;00:00, 9.49it/s] # 手动控制更新import timefrom tqdm import tqdmwith tqdm(total=10) as pbar: for i in range(10): pbar.update(1) time.sleep(0.1)# 效果如下&gt;&gt;&gt; 100%|██████████| 10/10 [00:00&lt;00:00, 10.10it/s]# 也可以这样import timefrom tqdm import tqdmpbar = tqdm(total=10) for i in range(10): pbar.update(1) time.sleep(0.1)pbar.close() # 效果如下&gt;&gt;&gt; 100%|██████████| 10/10 [00:00&lt;00:00, 10.10it/s] 在Spyder下正常了，然而在命令窗口有问题。 重试 进行爬虫的时候，很容易因为网络问题导致失败，这里有2个库可以很轻松地实现这个功能。 retry安装1pip install retry 使用 只需要在函数定义前加上@retry就行了。 1234567891011121314151617from retry import retry@retry()def make_trouble(): '''重试直到成功'''@retry(ZeroDivisionError, tries=3, delay=2)def make_trouble(): '''出现ZeroDivisionError时重试, 重试3次，每次间隔2秒'''@retry((ValueError, TypeError), delay=1, backoff=2)def make_trouble(): '''出现ValueError或TypeError时重试, 每次间隔1, 2, 4, 8, ...秒'''@retry((ValueError, TypeError), delay=1, backoff=2, max_delay=4)def make_trouble(): '''出现ValueError或TypeError时重试, 每次间隔1, 2, 4, 4, ...秒，最高间隔为4秒'''@retry(ValueError, delay=1, jitter=1)def make_trouble(): '''出现ValueError时重试,每次间隔1, 2, 3, 4, ... 秒''' Tenacity 使用类似于retry。同样只需要在函数定义前加上@retry就行了。 安装1pip install tenacity 使用12345678910111213141516171819from tenacity import retry, retry_if_exception_type, wait_fixed, stop_after_attempt, stop_after_delay,@retry()def make_trouble(): '''重试直到成功'''@retry(retry=retry_if_exception_type(ZeroDivisionError), wait=wait_fixed(2), stop=stop_after_attempt(3))def make_trouble(): '''出现ZeroDivisionError时重试, 重试3次，每次间隔2秒'''@retry(stop=(stop_after_delay(10) | stop_after_attempt(5)))def make_trouble(): '''重试10秒或者5次''' @retry(wait=wait_random(min=1, max=2))def make_trouble(): '''重试间隔在随机1-2秒'''@retry(wait=wait_chain(*[wait_fixed(3) for i in range(3)] + [wait_fixed(7) for i in range(2)] + [wait_fixed(9)]))def make_trouble(): '''前三次重试每次间隔3秒，接下来2次间隔7秒，之后重试间隔9秒''' 超时 很多任务特别是多线程时，为了防止程序卡死，需要设定一个超时。 func_timeout 由于windows下signal的支持问题，选择使用第三方包，func_timeout就是一个给函数添加超时的包。 安装1pip install func_timeout 使用123456789101112131415161718192021222324import timefrom func_timeout import func_set_timeout,FunctionTimedOut# 基本用法try: doitReturnValue = func_timeout(5, doit, args=('arg1', 'arg2'))except FunctionTimedOut: print ( "doit('arg1', 'arg2') could not complete within 5 seconds and was terminated.\n")except Exception as e: # 其他Exception# 装饰器用法@func_set_timeout(2)def task(): time.sleep(5)# 效果如下FunctionTimedOut: Function task (args=()) (kwargs=&#123;&#125;) timed out after 2.000000 seconds.# 捕获异常from func_timeout.exceptions import FunctionTimedOuttry: task()except FunctionTimedOut: print('task func_timeout') 此外它还有一个重试的函数FunctionTimedOut，就不赘述了。 异步 待填坑……]]></content>
      <categories>
        <category>心得体会</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Efficiency</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[金缕曲]]></title>
    <url>%2F2018%2F01%2F31%2F%E9%87%91%E7%BC%95%E6%9B%B2%2F</url>
    <content type="text"><![CDATA[搬运的旧文之二： 今日看微博，居然还有人拿汪精卫的诗词才情给他翻案。其中举了汪的《金缕曲·别后平安否》，原词如下： 别后平安否？便相逢、凄凉万事，不堪回首。国破家亡无穷恨，禁得此生消受。又添了离愁万斗。眼底心头如昨日，诉心期夜夜常携手。一腔血，为君剖。泪痕料渍云笺透。倚寒衾循环细读，残灯如豆。留此馀生成底事，空令故人僝僽。愧戴却头颅如旧。跋涉关河知不易，愿孤魂缭护车前后。肠已断，歌难又。 说实在话，这首词还是写的挺好的，难怪陈壁君见词倾心。汪另一首著名的诗便是“慷慨歌燕市，从容做楚囚；引刀成一快，不负少年头。”据说当年作出“砍头不要紧，只要主义真；杀了夏明翰，还有后来人。”的革命烈士夏明翰死前是引用了这首诗的，可惜涉及到了大汉奸汪精卫，只能在教科书上删去此段。钱钟书先生读过汪精卫的诗词也不禁叹到：“扫叶吞花足胜情，鉅公难得此才清。”只可惜，汉奸就是汉奸，若是才华便能给人品洗地，那么秦桧的书法也不错，也该给秦桧翻翻案了。 言归正传，汪的《金缕衣·别后平安否》借鉴了顾贞观的《金缕曲二首》： 季子平安否？便归来，平生万事，那堪回首。行路悠悠谁慰藉，母老家贫子幼。记不起、从前杯酒。魑魅搏人应见惯，总输他、覆雨翻云手。冰与雪，周旋久。泪痕莫滴牛衣透，数天涯，依然骨肉，几家能够？比似红颜多命薄，更不如今还有。只绝塞、苦寒难受。廿载包胥承一诺，盼乌头马角终相救。置此札，君怀袖。 我亦飘零久。十年来，深恩负尽，死生师友。宿昔齐名非忝窃，试看杜陵消瘦，曾不减、夜郎潺僽。薄命长辞知己别，问人生、到此凄凉否？千万恨，为君剖。兄生辛未吾丁丑，共些时，冰霜摧折，早衰蒲柳。词赋从今须少作，留取心魂相守。但愿得、河清人寿。归日急翻行戍稿，把空名料理传身后。言不尽，观顿首。 顺治十四年，顾贞观的好友吴兆骞参加江南乡试中举，却不幸被牵涉入丁酉江南乡试科场案。顺治帝大怒遂于次年将该科已考中的江南举子押解至北京，由福临在中南海瀛台亲自复试，复试合格者保留举人资格，不合格者治罪。两名主考官被斩，17名同考官处绞。 据载，吴兆骞少年得志，放诞不羁，简傲礼法，曾对江东名士汪琬曰：“江东无我，卿当独步”，当是时汪琬年长他七岁，文名早著，所以引得众人侧目。还有个故事是，他在私塾里念书时，常拿桌上同学们除下来的帽子来小便。同学们告诉先生，他竟有回答：“与其放在俗人头上，还不如拿来盛小便。”先生也不由叹息：“此子必以名大惹祸。”吴兆骞之狂可见一斑。 所以有种说法是因为他太狂傲，故意在复试中交了白卷，因而下狱。于顺治十五年，流放宁古塔（位于今黑龙江省）。 在吴兆骞出关之时，好友顾贞观曾发下誓言，要救他归来。（《无锡金匮县志-文苑》载：“兆骞戍宁古塔，贞观洒涕，要言曰：‘必归季子。‘ ”）然而他奔波近二十年，仍然徒劳无功。康熙十五年冬，离居北京千佛寺，于冰雪中感念良友的惨苦无告，为之作《金缕曲》二首寄之以代书信。纳兰性德读过这两首词，泪下数行，说：“河粱生别之诗，山阳死友之传，得此而三！”当即担保援救兆骞，并回赠一首《金缕曲·赠梁汾》。​ 德也狂生耳！偶然间、淄尘京国，乌衣门第。有酒惟浇赵州土，谁会成生此意？不信道、遂成知己。青眼高歌俱未老，向尊前、拭尽英雄泪。君不见，月如水。共君此夜须沉醉。且由他、娥眉谣诼，古今同忌。身世悠悠何足问，冷笑置之而已！寻思起、从头翻悔。一日心期千劫在，后身缘恐结他生里。然诺重，君须记！ 在纳兰父子的帮助下，吴兆骞终于在康熙二十年后归来。自此他已在塞外生活了二十三年。 注1：我见过有说法，顾的两首《金缕曲》是对吴在塞外写的《戊午二月十一日寄顾舍人书》：“塞外苦寒，四时冰雪，鸣镝呼风，哀笳带雪，一身飘寄，双鬓渐星。妇复多病，一男两女，藜藿不充，回念老母，茕然在堂，迢递关河，归省无日……”的回信，但是该信写于康熙十七年，晚于金缕曲成作日，暂不采纳。 注2：吴伟业在吴兆骞出关时作了一首《悲歌赠吴季子》，我也觉得写的挺好的： 白璧青蝇见排诋。一朝束缚去，上书难自理。绝塞千里断行李，送吏泪不止，流人复何倚。彼尚愁不归，我行定已矣。八月龙沙雪花起，橐驼垂腰马没耳，白骨皑皑经战垒，黑河无船渡者几，前忧猛虎后苍，土穴偷生若蝼蚁，大鱼如山不见尾，张耆为风沫为雨，日月倒行入海底，白昼相逢半人鬼。噫嘻乎悲哉!生男聪明慎莫喜，仓颉夜哭良有以，受患只从读书始，君不见，吴季子!]]></content>
      <categories>
        <category>诗词遗珠</category>
      </categories>
      <tags>
        <tag>Literature</tag>
        <tag>Poetry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[临终歌]]></title>
    <url>%2F2018%2F01%2F31%2F%E4%B8%B4%E7%BB%88%E6%AD%8C%2F</url>
    <content type="text"><![CDATA[庆祝博客开通，搬篇旧文凑个数： 大鹏飞兮振八裔，中天摧兮力不济。余风激兮万世，游扶桑兮挂左袂。后人得之传此，仲尼亡兮谁为出涕？ 李白临终歌 李白的好诗有很多，小时候背过的也不少，这里我要说的是《临终歌》。据说是李白死前所作，颇有几分墓志铭的味道——唐代李华于《故翰林学士李君墓铭序》载：“年六十有二不偶，赋临终歌而卒。” 提到大鹏，脑海里自然浮现出了庄子的《逍遥游》：“北冥有鱼，其名为鲲。鲲之大，不知其几千里也。化而为鸟，其名为鹏。鹏之背，不知其几千里也。怒而飞，其翼若垂天之云……”李白自小受道家影响颇深，自然对大鹏也有特别的情感。 年轻时的李白，便作了《大鹏遇希有鸟赋》，赋中李白仿佛化身大鹏，“簸鸿蒙，扇雷霆。斗转而天动，山摇而海倾。”此时的李白尚有“大济苍生，海内清一”的抱负。然而理想与现实终究是有差距的，虽然李白渴望建功立业，却一直不受重用，甚至被玄宗皇帝赐金还山，这时的他依然写下了“大鹏一日同风起，扶摇直上九万里”的诗句，激励自己穿过风浪，东山再起。安史之乱后，李白又受永王李璘叛逆案牵连，流放夜郎。虽然因大赦逃过一劫，但再也没有机会展示抱负了。 同李白的“天生我才必有用”、“吾辈岂是蓬蒿人”、”我本楚狂人，凤歌笑孔丘”等诗句相比，《临终歌》显得尤为悲怆。李白化身的大鹏老了，再也飞不动了，“冠盖满京华，斯人独憔悴”，绝望的大鹏在生命的最后长歌当哭，留下了最后的哀歌。]]></content>
      <categories>
        <category>诗词遗珠</category>
      </categories>
      <tags>
        <tag>Literature</tag>
        <tag>Poetry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apriori算法]]></title>
    <url>%2F2018%2F01%2F30%2FApriori%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[很多人都听说过“尿布和啤酒”的故事：据说，美国中西部的一家连锁店发现，男人们去超市买尿布的同时，往往会顺便给自己购买啤酒。由此，卖场开始把啤酒和尿布摆放在相同区域，让男人可以同时找到这两件商品，从而获得了很好的销售收入。虽然并没有商店真的把这两样东西放在一起，但是很多商家确实将大家经常购买的物品放在一起捆绑销售以鼓励大家购买。那么我们如何在繁杂的数据发现这些隐含关系呢？这就需要关联分析（association analysis），本文所讨论的Apriori便是其中一种关联分析算法。 基本概念 关联分析是一种在大规模数据集中寻找有趣关系的任务。这些关系有两种形式：频繁项集、关联规则。频繁项集（frequent item sets）是经常出现在一块的物品的集合；关联规则（association rules）暗示两种物品之间可能存在很强的关系。 以下是某个杂货店的交易清单： 交易号码 商品 0 豆奶，莴苣 1 莴苣，尿布，葡萄酒，甜菜 2 豆奶，尿布，葡萄酒，橙汁 3 莴苣，豆奶，尿布，葡萄酒 4 莴苣，豆奶，尿布，橙汁 频繁项集：经常出现在一起的物品集合，如｛葡萄酒，尿布，豆奶｝就是一个频繁项集。 支持度（support）：如何有效定义频繁？其中最重要的两个概念是支持度和可信度。一个项集的支持度被定义为数据集中包含该项集的记录所占的比例。还是上面的例子，豆奶在5条交易中出现了4次，因此｛豆奶｝的支持度为4/5，同理可知，｛豆奶，尿布｝的支持度为3/5。我们可以定义一个最小支持度，从而只保留满足最小支持度的项集。 可信度或置信度（confidence）：是针对一条关联规则来定义的。例如：我们要讨论｛尿布｝→｛葡萄酒｝的关联规则，它的可信度被定义为“支持度（｛尿布，葡萄酒｝） / 支持度（｛尿布｝）”。因为｛尿布, 葡萄酒｝的支持度为3/5，｛尿布｝的支持度为4/5，所以“尿布→葡萄酒”的可信度为3/4=0.75。 Apriori原理 假设我们在经营一家商品种类并不多的杂货店，我们对那些经常一起被购买的商品很感兴趣。我们只有4种商品：商品0，商品1，商品2和商品3。那么所有可能被一起购买的商品组合有哪些？下图显示了物品之间所有可能的组合。 如何对一条给定的集合，如{0,3}，来计算其支持度？通常我们遍历每条记录并检查该记录包含0和3，如果记录确实包含两项，那么就增加总计数值。在扫描完每条数据后，使用统计的总数除以总交易记录数，就可以得到支持率。同样地，如果要获得每种可能集合的支持度就要多次重复上述过程。对于包含4种物品的集合，需要遍历数据15次。而随着物品数目的增加，遍历次数会急剧增长。对于包含N中物品的数据集共有2N−1中项集组合，对于只出售100中商品的商店也会有1.26×1030中可能的项集组合。对于现代计算机，需要很长的时间才能完成运算。 Apriori原理可以帮助我们减少感兴趣的项集。Apriori原理是指如果某个项集是频繁的，那么它的所有子集也是频繁的。反过来，如果一个项集是非频繁集，那么它的所有超集也是非频繁的。 上述例子中，已知阴影项集{2，3}是非频繁的。利用这个知识，我们就知道项集{0,2,3} ，{1,2,3}以及{0,1,2,3}也是非频繁的。这也就是说，一旦计算出了{2,3}的支持度，知道它是非频繁的之后，就不需要再计算{0,2,3}、{1,2,3}和{0,1,2,3}的支持度，因为我们知道这些集合不会满足我们的要求。使用该原理就可以避免项集数目的指数增长，从而在合理时间内计算出频繁项集。 Apriori算法 发现频繁项集的过程如上图所示： 由数据集生成候选项集C1（1表示每个候选项仅有一个数据项）；再由C1通过支持度过滤，生成频繁项集L1（1表示每个频繁项仅有一个数据项）。 将L1的数据项两两拼接成C2。 从候选项集C2开始，通过支持度过滤生成L2。L2根据Apriori原理拼接成候选项集C3；C3通过支持度过滤生成L3……直到Lk中仅有一个或没有数据项为止。 回到上面的杂货店例子，令最小支持度为0.4，结果如下图： 值得注意的是L3到C4这一步并没有得到候选项集，这是由于Apriori算法由两部分组成（在这里假定购买商品是有顺序的）。 连接：对K-1项集中的每个项集中的项排序，只有在前K-1项相同时才将这两项合并，形成候选K项集（因为必须形成K项集，所以只有在前K-1项相同，第K项不相同的情况下才合并。） 剪枝：对于候选K项集，要验证所有项集的所有K-1子集是否频繁（是否在K-1项集中），去掉不满足的项集，就形成了K项集。比如C4连接的｛尿布，莴苣，葡萄酒，豆奶｝的子集｛莴苣，葡萄酒，豆奶｝不存在于L3，因此要去掉。 实现Apriori代码 根据以上原理构造数据集扫描的Python代码，其伪代码大致如下： 1234567对数据集中的每条交易记录tran对每个候选项集can : 检查一下can是否是tran的子集 : 如果是，则增加can的计数值对每个候选项集 :如果其支持度不低于最小值，则保留该项集返回所有频繁项集列表 建立辅助函数： 12345678910111213141516171819202122232425262728293031323334353637383940# 创建一个简单的测试数据集def loadDataSet() : return [[1,3,4], [2,3,5], [1,2,3,5], [2,5]]# 构建集合C1，C1是大小为1的所有候选项集的集合。def createC1(dataSet) : # C1是空列表，用来存储所有不重复的项值。如果某个物品项没有在C1中出现，则将其添加到C1中。 # 这里并不是简单地每个物品项，而是添加只包含该物品项的一个列表。Python不能创建只有一个整 # 数的集合，因此这里实现必须使用列表 C1 = [] for transaction in dataSet : for item in transaction : if not [item] in C1 : C1.append([item]) C1.sort() # frozenset是指被“冰冻”的集合，就是说它们是不可改变 return list(map(frozenset,C1)) # D: 数据集# Ck: 候选项集列表# minSupport: 感兴趣集的最小支持度minSupport# 该函数会返回一个包含支持度的字典以备后用def scanD(D, Ck, minSupport) : ssCnt = &#123;&#125; for tid in D : for can in Ck : if can.issubset(tid) : if not can in ssCnt: ssCnt[can]=1 else : ssCnt[can] += 1 numItems = float(len(D)) retList = [] supportData = &#123;&#125; for key in ssCnt : # 计算所有项集的支持度 support = ssCnt[key]/numItems if support &gt;= minSupport : # 在列表的首部插入新的集合 retList.insert(0, key) supportData[key] = support return retList, supportData 保存为apriori.py，运行效果如下： 123456789101112131415161718&gt;&gt;&gt; import apriori# 导入数据集&gt;&gt;&gt; dataSet = apriori.loadDataSet()&gt;&gt;&gt; dataSet[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]# 构建第一个候选项集集合C1&gt;&gt;&gt; C1 = apriori.createC1(dataSet)&gt;&gt;&gt; C1[frozenset([1]), frozenset([2]), frozenset([3]), frozenset([4]), frozenset([5])]# 构建集合表示的数据集D&gt;&gt;&gt; D = list(map(set, dataSet))&gt;&gt;&gt; D[&#123;1, 3, 4&#125;, &#123;2, 3, 5&#125;, &#123;1, 2, 3, 5&#125;, &#123;2, 5&#125;]# 去掉不满足最小支持度的项集，0.5为最小支持度&gt;&gt;&gt; L1, suppData0 = apriori.scanD(D, C1, 0.5)# 下面四个项集构成了L1列表，该列表中每个单物品项集至少出现在50%以上的记录中&gt;&gt;&gt; L1[frozenset([5]), frozenset([2]), frozenset([3]), frozenset([1])] 整个Apriori算法的伪代码如下： 1234当集合中项的个数大于0时 构建一个k个项组成的候选项集的列表 检查数据以确认每个项集都是频繁的 保留频繁项集并构建k+1项组成的候选项集的列表 将如下算法代码加入apriori.py： 1234567891011121314151617181920212223242526272829303132333435363738394041# 创建候选项集Ck# Lk，频繁项集列表# k，项集元素的个数def aprioriGen(Lk, k) : # create Ck # 创建一个空列表 retList = [] # 计算Lk中的元素 lenLk = len(Lk) for i in range(lenLk) : for j in range(i+1, lenLk) : # 当前k-2个项相同时，将两个集合合并 L1 = list(Lk[i])[:k-2] L2 = list(Lk[j])[:k-2] L1.sort() L2.sort() if L1==L2 : # python中集合的并操作对应的操作符为| retList.append(Lk[i] | Lk[j]) return retList# dataSet，数据集# minSupport，支持度# 此函数会生成候选项集的列表def apriori(dataSet, minSupport = 0.5) : C1 = createC1(dataSet) # map函数将set()映射到dataSet列表中的每一项 D = list(map(set, dataSet)) L1, supportData = scanD(D, C1, minSupport) # 将L1放入L列表中 L = [L1] k = 2 # while循环将L2, L3, L4, ... 放入L列表中，直到下一个大的项集为空 while (len(L[k-2]) &gt; 0) : # 调用aprioriGen()创建候选项集Ck Ck = aprioriGen(L[k-2], k) # 扫描数据集，从Ck得到Lk Lk, supK = scanD(D, Ck, minSupport) supportData.update(supK) L.append(Lk) k += 1 return L, supportData 上面的k-2可能会令人困惑，接下来讨论其细节。当利用{0}、{1}、{2}构建{0,1}、{0,2}、{1,2}时，实际上是将单个项组合到一块。现在如果想利用{0,1}、{0,2}、{1,2}来创建三元素项集，应该怎么做？如果将每两个集合合并，就会得到{0,1,2}、{0,1,2}、{0,1,2}。也就是同样的结果集合会重复3次。接下来需要扫描三元素项集列表来得到非重复结果，我们要做的是确保遍历列表的次数最少。现在，如果比较集合{0,1}、{0,2}、{1,2}的第一个元素并只对第一个元素相同的集合求并操作，又会得到什么结果？{0,1,2}，而且只有一次操作，这样就不用遍历列表来寻找非重复值了。 保存后运行效果如下： 1234567891011121314151617181920212223&gt;&gt;&gt; L, supportData = apriori.apriori(dataSet)&gt;&gt;&gt; L[[frozenset([5]), frozenset([2]), frozenset([3]), frozenset([1])], [frozenset([2, 3]), frozenset([3, 5]), frozenset([2, 5]), frozenset([1, 3])], [frozenset([2,3, 5])], []]# L包含满足最小支持度为0.5的频率项集列表，下面看一下具体值：&gt;&gt;&gt; L[0][frozenset([5]), frozenset([2]), frozenset([3]), frozenset([1])]&gt;&gt;&gt; L[1][frozenset([2, 3]), frozenset([3, 5]), frozenset([2, 5]), frozenset([1, 3])]&gt;&gt;&gt; L[2][frozenset([2, 3, 5])]&gt;&gt;&gt; L[3][]# 每个项集都是在函数apriori()中调用函数aprioriGen()来生成的。下面看一下aprioriGen()函数的工作流程：&gt;&gt;&gt; apriori.aprioriGen(L[0], 2)[frozenset([2, 5]), frozenset([3, 5]), frozenset([1, 5]), frozenset([2, 3]), frozenset([1, 2]), frozenset([1, 3])]# 这里的6个集合是候选项集Ck中的元素。其中4个集合在L[1]中，剩下2个集合被函数scanD()过滤掉。# 下面再尝试70%的支持度：&gt;&gt;&gt; L,support = apriori.apriori(dataSet, minSupport=0.7)&gt;&gt;&gt; L[[frozenset([5]), frozenset([2]), frozenset([3])], [frozenset([2, 5])], []] 从频繁项集中挖掘关联规则 关联分析的两个重要目标是发现频繁项集与关联规则。要找到关联规则，首先从一个频繁项集开始，集合中的元素是不重复的，但我们想知道基于这些元素能否获得其他内容。某个元素或者某个元素集合可能会推导出另一个元素。例如，一个频繁项集｛豆奶, 莴苣｝，可能有一条关联规则“豆奶→莴苣”，这意味着如果有人购买了豆奶，那么在统计上他购买莴苣的概率较大。但是这条反过来并不总是成立。换言之，即使“豆奶→莴苣”统计上显著，那么“莴苣→豆奶”也不一定成立。箭头的左边集合称作前件，箭头右边的集合称为后件。 上节我们给出了繁琐项集的量化定义，即它满足最小支持度要求。对于关联规则，我们也有类似量化方法，这种量化标准称为可信度。一条规则P→H的可信度定义为support(P | H) / support(P)。在前面我们已经计算了所有繁琐项集支持度，要想获得可信度，只需要再做一次除法运算。 从一个繁琐项集中可以产生多少条关联规则？下图给出了从项集{0,1,2,3}产生的所有关联规则。为了找到感兴趣的规则，我们先生成一个可能的规则列表，然后测试每条规则可信度。如果可信度不满足最小要求，则去掉该规则。 可以观察到，如果某条规则并不满足最小可信度要求，那么该规则的所有子集也不会满足最小可信度要求。具体而言，如果012→3是一条低可信度规则，则所有其它3为后件的规则都是低可信度。这需要从可信度的概念去理解，Confidence(012→3) = P(3|0,1,2), Confidence(01→23)=P(2,3|0,1)，P(3|0,1,2) &gt;= P(2,3|0,1)。由此可以对关联规则做剪枝处理。 还是以之前的杂货店交易数据为例，我们发现了以下频繁项集： 对于寻找关联规则来说，频繁1项集L1没有用处，因为L1中的每个集合仅有一个数据项，至少有两个数据项才能生成A→B这样的关联规则。取置信度为0.7，最终从L2发掘出10条关联规则： 接下来是L3： 假设有一个L4项集（文中的数据不能生成L4），其挖掘过程如下： 利用此性质来减少测试的规则数目，可以先从一个频繁项集开始，接着创建一个规则列表，其中规则右部只包含一个元素，然后对这些规则测试。接下来合并所有剩余规则来创建一个新的规则列表，其中右部包含两个元素。这种方法称为分级法。打开apriori.py，加入如下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# 关联规则生成函数，此函数调用其他两个函数rulesFromConseq、calcConf# L: 频繁项集列表# supportData: 包含那些频繁项集支持数据的字典# minConf: 最小可信度阈值，默认是0.7# 函数最后要生成一个包含可信度的规则列表，后面可以基于可信度对它们进行排序# 这些规则存放在bigRuleList中。def generateRules(L, supportData, minConf=0.7) : bigRuleList = [] # 遍历L中的每一个频繁项集并对每个频繁项集创建只包含单个元素集合的列表H1， # 因为无法从单元素项集中构建关联规则，所以要从包含两个或者更多元素的项集开始规则构建过程。 # 只获取有两个或更多元素的集合 for i in range(1, len(L)) : for freqSet in L[i] : H1 = [frozenset([item]) for item in freqSet] if i &gt; 1 : # 如果频繁项集的元素数目超过2，那么会考虑对它做进一步的合并，合并通过 # rulesFromConseq来完成 rulesFromConseq(freqSet, H1, supportData, bigRuleList, minConf) else : # 如果项集中只有两个元素，那么需要使用calcConf()来计算可信度值 calcConf(freqSet, H1, supportData, bigRuleList, minConf) return bigRuleList# 对规则进行评估# 目标是计算规则的可信度以及找到满足最小可信度要求的规则# 函数会返回一个满足最小可信度要求的规则列表，空列表prunedH保存这些规则def calcConf(freqSet, H, supportData, brl, minConf=0.7) : prunedH = [] # 遍历H中的所有项集并计算它们的可信度值 for conseq in H : # 可信度计算时使用supportData中的支持度数据 conf = supportData[freqSet] / supportData[freqSet - conseq] # 规则满足最小可信度值，将这些规则输出到屏幕显示 if conf &gt;= minConf : print(freqSet-conseq, '--&gt;', conseq, 'conf:', conf) brl.append((freqSet-conseq, conseq, conf)) prunedH.append(conseq) return prunedH# 用于生成候选规则集合，从最初的项集中生成更多的关联规则# freqSet: 频繁项集# H: 可以出现在规则右部的元素列表def rulesFromConseq(freqSet, H, supportData, brl, minConf=0.7) : # H中频繁项集大小m m = len(H[0]) # 查看该频繁项集是否大到可以移除大小为m的子集 if (len(freqSet) &gt; (m+1)) : # 生成H中元素的无重复组合，结果存储在Hmp1，这也是下一次迭代的H列表 Hmp1 = aprioriGen(H, m+1) # Hmp1包含所有可能的规则，利用calcConf()来测试它们的可信度以确定是否满足要求 Hmp1 = calcConf(freqSet, Hmp1, supportData, brl, minConf) # 如果不止一条规则满足要求，那么使用Hmp1迭代调用函数rulesFromConseq if (len(Hmp1) &gt; 1) : rulesFromConseq(freqSet, Hmp1, supportData, brl, minConf) 检验运行效果： 123456789101112131415161718192021222324252627282930&gt;&gt;&gt; import apriori&gt;&gt;&gt; dataSet = apriori.loadDataSet()&gt;&gt;&gt; dataSet[[1, 3, 4], [2, 3, 5], [1, 2, 3, 5], [2, 5]]# 生成一个最小支持度为0.5的频繁项集的集合&gt;&gt;&gt; L, supportData = apriori.apriori(dataSet, minSupport=0.5)&gt;&gt;&gt; rules = apriori.generateRules(L, supportData, minConf=0.7)frozenset([5]) --&gt; frozenset([2]) conf: 1.0frozenset([2]) --&gt; frozenset([5]) conf: 1.0frozenset([1]) --&gt; frozenset([3]) conf: 1.0&gt;&gt;&gt; rules[(frozenset([5]), frozenset([2]), 1.0), (frozenset([2]), frozenset([5]), 1.0), (frozenset([1]), frozenset([3]), 1.0)]# 得到了3条规则：&#123;5&#125;→&#123;2&#125;、&#123;2&#125;→&#123;5&#125;、&#123;1&#125;→&#123;3&#125;，可见包含2和5的规则可以互换前后件，包含1和3的不行# 接下来降低可信度阈值，可以得到结果如下&gt;&gt;&gt; rules = apriori.generateRules(L, supportData, minConf=0.5)frozenset([3]) --&gt; frozenset([2]) conf: 0.666666666667frozenset([2]) --&gt; frozenset([3]) conf: 0.666666666667frozenset([5]) --&gt; frozenset([3]) conf: 0.666666666667frozenset([3]) --&gt; frozenset([5]) conf: 0.666666666667frozenset([5]) --&gt; frozenset([2]) conf: 1.0frozenset([2]) --&gt; frozenset([5]) conf: 1.0frozenset([3]) --&gt; frozenset([1]) conf: 0.666666666667frozenset([1]) --&gt; frozenset([3]) conf: 1.0frozenset([5]) --&gt; frozenset([2, 3]) conf: 0.666666666667frozenset([3]) --&gt; frozenset([2, 5]) conf: 0.666666666667frozenset([2]) --&gt; frozenset([3, 5]) conf: 0.666666666667&gt;&gt;&gt; rules[(frozenset(&#123;3&#125;), frozenset(&#123;2&#125;), 0.6666666666666666), (frozenset(&#123;2&#125;), frozenset(&#123;3&#125;), 0.6666666666666666), (frozenset(&#123;5&#125;), frozenset(&#123;3&#125;), 0.6666666666666666), (frozenset(&#123;3&#125;), frozenset(&#123;5&#125;), 0.6666666666666666), (frozenset(&#123;5&#125;), frozenset(&#123;2&#125;), 1.0), (frozenset(&#123;2&#125;), frozenset(&#123;5&#125;), 1.0), (frozenset(&#123;3&#125;), frozenset(&#123;1&#125;), 0.6666666666666666), (frozenset(&#123;1&#125;), frozenset(&#123;3&#125;), 1.0), (frozenset(&#123;5&#125;), frozenset(&#123;2, 3&#125;), 0.6666666666666666), (frozenset(&#123;3&#125;), frozenset(&#123;2, 5&#125;), 0.6666666666666666), (frozenset(&#123;2&#125;), frozenset(&#123;3, 5&#125;), 0.6666666666666666)]# 一旦降低可信度阈值，就可以获得更多的规则 Apriori应用 之前我们在小数据上应用了apriori算法，接下来要在更大的真实数据集上测试效果。那么可以使用什么样的数据呢？比如：购物篮分析，搜索引擎的查询词，国会投票，毒蘑菇的相似特征提取等； 示例：发现毒蘑菇的相似特征 从此处下载mushroom.dat，其前几行如下： 12345671 3 9 13 23 25 34 36 38 40 52 54 59 63 67 76 85 86 90 93 98 107 113 2 3 9 14 23 26 34 36 39 40 52 55 59 63 67 76 85 86 90 93 99 108 114 2 4 9 15 23 27 34 36 39 41 52 55 59 63 67 76 85 86 90 93 99 108 115 1 3 10 15 23 25 34 36 38 41 52 54 59 63 67 76 85 86 90 93 98 107 113 2 3 9 16 24 28 34 37 39 40 53 54 59 63 67 76 85 86 90 94 99 109 114 2 3 10 14 23 26 34 36 39 41 52 55 59 63 67 76 85 86 90 93 98 108 114 2 4 9 15 23 26 34 36 39 42 52 55 59 63 67 76 85 86 90 93 98 108 115 第一个特征表示有毒或者可食用，有毒为2，无毒为1。下一个特征是蘑菇伞的形状，有六种可能的值，分别用整数3-8来表示。 为了找到毒蘑菇中存在的公共特征，可以运行Apriori算法来寻找包含特征值为2的频繁项集。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&gt;&gt;&gt; import apriori&gt;&gt;&gt; mushDatSet = [line.split() for line in open('mushroom.dat').readlines()]# 在数据集上运行Apriori算法&gt;&gt;&gt; L, suppData = apriori.apriori(mushDatSet, minSupport=0.3)# 在结果中可以搜索包含有独特征2的频繁项集：&gt;&gt;&gt; for item in L[1] :... if item.intersection('2'): print(item)...frozenset(&#123;'28', '2'&#125;)frozenset(&#123;'2', '53'&#125;)frozenset(&#123;'2', '23'&#125;)frozenset(&#123;'2', '34'&#125;)frozenset(&#123;'2', '36'&#125;)frozenset(&#123;'59', '2'&#125;)frozenset(&#123;'63', '2'&#125;)frozenset(&#123;'67', '2'&#125;)frozenset(&#123;'2', '76'&#125;)frozenset(&#123;'2', '85'&#125;)frozenset(&#123;'2', '86'&#125;)frozenset(&#123;'2', '90'&#125;)frozenset(&#123;'93', '2'&#125;)frozenset(&#123;'2', '39'&#125;)# 对更大项集来重复上述过程&gt;&gt;&gt; for item in L[3] :... if item.intersection('2') : print(item)...frozenset(&#123;'2', '28', '59', '34'&#125;)frozenset(&#123;'2', '28', '59', '85'&#125;)frozenset(&#123;'2', '86', '28', '59'&#125;)frozenset(&#123;'2', '28', '59', '90'&#125;)frozenset(&#123;'2', '28', '59', '39'&#125;)frozenset(&#123;'63', '2', '28', '39'&#125;)frozenset(&#123;'63', '2', '28', '34'&#125;)frozenset(&#123;'63', '2', '28', '59'&#125;)frozenset(&#123;'63', '2', '28', '85'&#125;)frozenset(&#123;'63', '2', '86', '28'&#125;)frozenset(&#123;'2', '28', '85', '34'&#125;)frozenset(&#123;'2', '86', '28', '34'&#125;)frozenset(&#123;'2', '86', '28', '85'&#125;)frozenset(&#123;'34', '2', '28', '90'&#125;)frozenset(&#123;'2', '28', '85', '90'&#125;)frozenset(&#123;'2', '86', '28', '90'&#125;)frozenset(&#123;'2', '28', '34', '39'&#125;)frozenset(&#123;'2', '28', '85', '39'&#125;)frozenset(&#123;'2', '86', '28', '39'&#125;)frozenset(&#123;'2', '28', '90', '39'&#125;)frozenset(&#123;'34', '2', '28', '53'&#125;)frozenset(&#123;'2', '28', '85', '53'&#125;)frozenset(&#123;'2', '86', '28', '53'&#125;)frozenset(&#123;'90', '2', '28', '53'&#125;)frozenset(&#123;'2', '28', '53', '39'&#125;)...... 接下来你需要观察这些特征，以便知道蘑菇的各个方面，如果看到其中任何一个特征，那么这些蘑菇就很有可能有毒。 小结 关联特征是用于发现大数据集元素间有趣关系的一个工具集，可以采用两种方法来量化这些有趣关系。第一种方法是使用频繁项集，它会给出经常在一起出现的元素项。第二种方式是关联规则，每条关联规则意味着元素之前的“如果……那么”关系。 发现元素间不同的组合是个非常耗时的任务，不可避免需要大量昂贵的计算资源，这就需要一些更智能的方法在合适的时间范围内找到频繁项集。其中一个方法是Apriori算法，它使用Apriori原理减少在数据库上进行检查的集合的数目。Apriori原理是说如果一个元素项是不频繁的，那么那些包含该元素的超集也是不频繁的。Apriori算法从单元项集开始，通过组合满足最小支持度要求的项集来形成更大的集合。支持度用来度量一个集合在原始数据中出现的频率。 关联分析可以用在许多不同物品上。商店中的商品以及网站的访问页面是其中比较常见的例子。关联分析也曾用于查看选举人及法官的投票历史。 缺点是每次增加频繁项集的大小，Apriori算法都会重新扫描整个数据集，当数据集很大时，这会显著降低频繁项集发现的速度。 参考资料：《机器学习实战》、《数据挖掘导论》]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Machine Learning</tag>
        <tag>Data Mining</tag>
        <tag>Association Analysis</tag>
        <tag>Apriori</tag>
      </tags>
  </entry>
</search>
